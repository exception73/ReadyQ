




Godspeed - Meta Framework | Godspeed Docs





Skip to main contentGodspeedDocumentationv2.0v2.0v11. Microservices Framework1. Introduction1.1. Overview1.2. Tenets1.3. Design Principles1.4. Guard Rails2. Getting started3. CLI4. Event sources5. Workflows6. DataSources7. Authentication8. Authorization9. Configs and Mappings10. Inline scripting11. VScode extention12. Telemetry2. ElasticGraph ORM3. Web-UI Starter Kit1. Microservices Framework1. Introduction1.1. OverviewVersion: v2.0On this pageGodspeed - Meta FrameworkThis document is meant for technology leaders, architects, and developers. Its purpose is to present the platform's overarching objectives, guiding principles, design elements, components, and functionalities to the target audience.Introduction​Our mission at Godspeed is to bring greater standardization, best practices and ease of engineering to the tech teams of the world. We wish to achieve this as a collaboration by and for the community.  We wish to develop a meta-framework along with tools, integrations, learning content, licensing and marketplace, based on a value system which fosters develop-rights, equity, fairness and wellbeing for all.We want to democratize tech for teams to effortlessly create, maintain, and monitor complex applications with reduced effort, agility, scalability, quality, performance, cost effectiveness and minimization of technical debt and talent hurdle. Our goal is to liberate teams from the burdensome, repetitive tasks, boilerplate, wiring, so that instead of focussing on the how, they retain a razor sharp focus on the what.To achieve this, we're committed to providing teams with the meta-framework, tools, integrations and learning that they need to develop and maintain products, guided by first principles and best practices likeStandardized implementation across languages, frameworks & toolsDecoupled architecture with plug and play integrationsZero boilerplate with pre-built abstractionsSchema and standards driven developmentShift leftCloud agnostic setupNo vendor lock-inAims​Boosting tech team's efficiency​The meta-framework with developer guardrails, generative features and pre-built integrations provides a ready-made feature set, a YAML DSL for important abstractions, simplified project setup, OTEL based telemetry and devops tooling, streamlining the lives of developers and reducing their work and hence the chance of mistakes. This enables them to concentrate on and achieve their primary tasks with minimal effort, time, and cost.The framework includes essential functionalities of a 'modern microservice' by default, allowing developers to concentrate solely on business logic, resulting in significant reduction in workload.
Lower learning curve.​Developers can deliver simple microservice on their first day itself. The standardized guardrails enforce their adoption and learning of best practices and engineering concepts, upskilling on the way as the projects proceed. In most cases, only a few in the organization need in-depth expertise, while others can quickly adapt to the framework through training and collaborate effectively, with support from internal team or from Godspeed.Easy brownfield adoption​Teams can adopt Godspeed by simply including the NPM module or jar in their existing project and installing the CLI. Godspeed ships as a node module. Hence it can be imported in any nodejs , bunjs or springboot project easily or developers can even reuse the existing event soures and data sources without any hassle.Security​The framework can read the environmental variables from a secure source like K8s Vault. It supports JWT, RBAC and ABAC based fine grained authorization. For data at rest, developers can use encryption mechanisms over datastores. Log redaction allows to hide sensitive information from logs.Flexibility​Developer should be able to implement anything they need, or replace existing eventsources or datasources with ease. They should also be able to migrate a project from one language or framework to another with least effort.Scale, performance and monitoring​For scale, we encourage the adoption of horizontal scaling approach based on Kubernetes. Developers can deploy a service on a Kubernetes cluster on any cloud.For performance, we believe the datasources (APIs and DBs) are the bottlenecks most of the time, and hence the framework allows an easy integration of a cache of choice, over the calls to the datasources. An easier way to setup Graphql like subscriptions and dual writes is planned.For monitoring, the framework microservices allows export of APM and BPM signals in OTEL format which is supported by all major observability backend solutions. We provide a pre-configured Grafana dashboard, with correlated logs and traces, and detailed APM out of the box. Using the devops plugin of Godspeed CLI, teams can install the full Grafana stack with Loki, Mimir, Tempo and Minio, on a Kubernetes cluster for scalable telemetry ingestion.Maintainability​The standardized guardrails with clearly defined developer's boundaries, ensure neat, simple & systematic implementations across projects and individual developers with diverse experiences. This avoids technical debt from creeping into the project over time. Further, the decoupled architecture and a neat and modular implementation allows agility in bringing rapid changes as per the ever evolving needs and scenarios.Design Principles​In order to serve the Goals and Tenets of the framework, we have followed certain design principles.Framework architecture​The three main pillars of Godspeed framework: eventsources, datasources, and functions or workflows.Do read more about them in the design principles section.Building blocks of framework:​EventSources: Pluggable event sources of different kinds like, HTTP with Express or Fastify, gRpc or Graphql server, cron, web socket, Message bus with Kafka or RabbitMQ, an event from Salesforce.1.1. Events: Events of async and sync kind are defined in standardized YAML DSL with endpoint, authorization rules and Swagger spec of input and output (as applicable).DataSources: Pluggable datastores or API clients, to send or retrieve data. For ex. MongoDB, Redis, AWS API etcWorkflows or Functions: The events invoke functions or workflows which contain the business logic.Config: The configuration variables as well as their values are defined in yaml files under config/ directory. Some variables are specific to the framework and rest variables can be created as per the business use cases.ENV: Sensitive data, like database URLs, that require concealment are specified in .env files and made available in the rest of the project via GSContext object.Features​Edit this pageNextTenetsIntroductionAimsBoosting tech team's efficiencyLower learning curve.Easy brownfield adoptionSecurityFlexibilityScale, performance and monitoringMaintainabilityDesign PrinciplesFramework architectureBuilding blocks of framework:FeaturesForumDiscordGithubTwitterLinkedIn








Godspeed - Meta Framework | Godspeed Docs





Skip to main contentGodspeedDocumentationv2.0v2.0v11. Microservices Framework1. Introduction1.1. Overview1.2. Tenets1.3. Design Principles1.4. Guard Rails2. Getting started3. CLI4. Event sources5. Workflows6. DataSources7. Authentication8. Authorization9. Configs and Mappings10. Inline scripting11. VScode extention12. Telemetry2. ElasticGraph ORM3. Web-UI Starter Kit1. Microservices Framework1. Introduction1.1. OverviewVersion: v2.0On this pageGodspeed - Meta FrameworkThis document is meant for technology leaders, architects, and developers. Its purpose is to present the platform's overarching objectives, guiding principles, design elements, components, and functionalities to the target audience.Introduction​Our mission at Godspeed is to bring greater standardization, best practices and ease of engineering to the tech teams of the world. We wish to achieve this as a collaboration by and for the community.  We wish to develop a meta-framework along with tools, integrations, learning content, licensing and marketplace, based on a value system which fosters develop-rights, equity, fairness and wellbeing for all.We want to democratize tech for teams to effortlessly create, maintain, and monitor complex applications with reduced effort, agility, scalability, quality, performance, cost effectiveness and minimization of technical debt and talent hurdle. Our goal is to liberate teams from the burdensome, repetitive tasks, boilerplate, wiring, so that instead of focussing on the how, they retain a razor sharp focus on the what.To achieve this, we're committed to providing teams with the meta-framework, tools, integrations and learning that they need to develop and maintain products, guided by first principles and best practices likeStandardized implementation across languages, frameworks & toolsDecoupled architecture with plug and play integrationsZero boilerplate with pre-built abstractionsSchema and standards driven developmentShift leftCloud agnostic setupNo vendor lock-inAims​Boosting tech team's efficiency​The meta-framework with developer guardrails, generative features and pre-built integrations provides a ready-made feature set, a YAML DSL for important abstractions, simplified project setup, OTEL based telemetry and devops tooling, streamlining the lives of developers and reducing their work and hence the chance of mistakes. This enables them to concentrate on and achieve their primary tasks with minimal effort, time, and cost.The framework includes essential functionalities of a 'modern microservice' by default, allowing developers to concentrate solely on business logic, resulting in significant reduction in workload.
Lower learning curve.​Developers can deliver simple microservice on their first day itself. The standardized guardrails enforce their adoption and learning of best practices and engineering concepts, upskilling on the way as the projects proceed. In most cases, only a few in the organization need in-depth expertise, while others can quickly adapt to the framework through training and collaborate effectively, with support from internal team or from Godspeed.Easy brownfield adoption​Teams can adopt Godspeed by simply including the NPM module or jar in their existing project and installing the CLI. Godspeed ships as a node module. Hence it can be imported in any nodejs , bunjs or springboot project easily or developers can even reuse the existing event soures and data sources without any hassle.Security​The framework can read the environmental variables from a secure source like K8s Vault. It supports JWT, RBAC and ABAC based fine grained authorization. For data at rest, developers can use encryption mechanisms over datastores. Log redaction allows to hide sensitive information from logs.Flexibility​Developer should be able to implement anything they need, or replace existing eventsources or datasources with ease. They should also be able to migrate a project from one language or framework to another with least effort.Scale, performance and monitoring​For scale, we encourage the adoption of horizontal scaling approach based on Kubernetes. Developers can deploy a service on a Kubernetes cluster on any cloud.For performance, we believe the datasources (APIs and DBs) are the bottlenecks most of the time, and hence the framework allows an easy integration of a cache of choice, over the calls to the datasources. An easier way to setup Graphql like subscriptions and dual writes is planned.For monitoring, the framework microservices allows export of APM and BPM signals in OTEL format which is supported by all major observability backend solutions. We provide a pre-configured Grafana dashboard, with correlated logs and traces, and detailed APM out of the box. Using the devops plugin of Godspeed CLI, teams can install the full Grafana stack with Loki, Mimir, Tempo and Minio, on a Kubernetes cluster for scalable telemetry ingestion.Maintainability​The standardized guardrails with clearly defined developer's boundaries, ensure neat, simple & systematic implementations across projects and individual developers with diverse experiences. This avoids technical debt from creeping into the project over time. Further, the decoupled architecture and a neat and modular implementation allows agility in bringing rapid changes as per the ever evolving needs and scenarios.Design Principles​In order to serve the Goals and Tenets of the framework, we have followed certain design principles.Framework architecture​The three main pillars of Godspeed framework: eventsources, datasources, and functions or workflows.Do read more about them in the design principles section.Building blocks of framework:​EventSources: Pluggable event sources of different kinds like, HTTP with Express or Fastify, gRpc or Graphql server, cron, web socket, Message bus with Kafka or RabbitMQ, an event from Salesforce.1.1. Events: Events of async and sync kind are defined in standardized YAML DSL with endpoint, authorization rules and Swagger spec of input and output (as applicable).DataSources: Pluggable datastores or API clients, to send or retrieve data. For ex. MongoDB, Redis, AWS API etcWorkflows or Functions: The events invoke functions or workflows which contain the business logic.Config: The configuration variables as well as their values are defined in yaml files under config/ directory. Some variables are specific to the framework and rest variables can be created as per the business use cases.ENV: Sensitive data, like database URLs, that require concealment are specified in .env files and made available in the rest of the project via GSContext object.Features​Edit this pageNextTenetsIntroductionAimsBoosting tech team's efficiencyLower learning curve.Easy brownfield adoptionSecurityFlexibilityScale, performance and monitoringMaintainabilityDesign PrinciplesFramework architectureBuilding blocks of framework:FeaturesForumDiscordGithubTwitterLinkedIn








Godspeed - Meta Framework | Godspeed Docs





Skip to main contentGodspeedDocumentationv2.0v2.0v11. Microservices Framework1. Introduction1.1. Overview1.2. Tenets1.3. Design Principles1.4. Guard Rails2. Getting started3. CLI4. Event sources5. Workflows6. DataSources7. Authentication8. Authorization9. Configs and Mappings10. Inline scripting11. VScode extention12. Telemetry2. ElasticGraph ORM3. Web-UI Starter Kit1. Microservices Framework1. Introduction1.1. OverviewVersion: v2.0On this pageGodspeed - Meta FrameworkThis document is meant for technology leaders, architects, and developers. Its purpose is to present the platform's overarching objectives, guiding principles, design elements, components, and functionalities to the target audience.Introduction​Our mission at Godspeed is to bring greater standardization, best practices and ease of engineering to the tech teams of the world. We wish to achieve this as a collaboration by and for the community.  We wish to develop a meta-framework along with tools, integrations, learning content, licensing and marketplace, based on a value system which fosters develop-rights, equity, fairness and wellbeing for all.We want to democratize tech for teams to effortlessly create, maintain, and monitor complex applications with reduced effort, agility, scalability, quality, performance, cost effectiveness and minimization of technical debt and talent hurdle. Our goal is to liberate teams from the burdensome, repetitive tasks, boilerplate, wiring, so that instead of focussing on the how, they retain a razor sharp focus on the what.To achieve this, we're committed to providing teams with the meta-framework, tools, integrations and learning that they need to develop and maintain products, guided by first principles and best practices likeStandardized implementation across languages, frameworks & toolsDecoupled architecture with plug and play integrationsZero boilerplate with pre-built abstractionsSchema and standards driven developmentShift leftCloud agnostic setupNo vendor lock-inAims​Boosting tech team's efficiency​The meta-framework with developer guardrails, generative features and pre-built integrations provides a ready-made feature set, a YAML DSL for important abstractions, simplified project setup, OTEL based telemetry and devops tooling, streamlining the lives of developers and reducing their work and hence the chance of mistakes. This enables them to concentrate on and achieve their primary tasks with minimal effort, time, and cost.The framework includes essential functionalities of a 'modern microservice' by default, allowing developers to concentrate solely on business logic, resulting in significant reduction in workload.
Lower learning curve.​Developers can deliver simple microservice on their first day itself. The standardized guardrails enforce their adoption and learning of best practices and engineering concepts, upskilling on the way as the projects proceed. In most cases, only a few in the organization need in-depth expertise, while others can quickly adapt to the framework through training and collaborate effectively, with support from internal team or from Godspeed.Easy brownfield adoption​Teams can adopt Godspeed by simply including the NPM module or jar in their existing project and installing the CLI. Godspeed ships as a node module. Hence it can be imported in any nodejs , bunjs or springboot project easily or developers can even reuse the existing event soures and data sources without any hassle.Security​The framework can read the environmental variables from a secure source like K8s Vault. It supports JWT, RBAC and ABAC based fine grained authorization. For data at rest, developers can use encryption mechanisms over datastores. Log redaction allows to hide sensitive information from logs.Flexibility​Developer should be able to implement anything they need, or replace existing eventsources or datasources with ease. They should also be able to migrate a project from one language or framework to another with least effort.Scale, performance and monitoring​For scale, we encourage the adoption of horizontal scaling approach based on Kubernetes. Developers can deploy a service on a Kubernetes cluster on any cloud.For performance, we believe the datasources (APIs and DBs) are the bottlenecks most of the time, and hence the framework allows an easy integration of a cache of choice, over the calls to the datasources. An easier way to setup Graphql like subscriptions and dual writes is planned.For monitoring, the framework microservices allows export of APM and BPM signals in OTEL format which is supported by all major observability backend solutions. We provide a pre-configured Grafana dashboard, with correlated logs and traces, and detailed APM out of the box. Using the devops plugin of Godspeed CLI, teams can install the full Grafana stack with Loki, Mimir, Tempo and Minio, on a Kubernetes cluster for scalable telemetry ingestion.Maintainability​The standardized guardrails with clearly defined developer's boundaries, ensure neat, simple & systematic implementations across projects and individual developers with diverse experiences. This avoids technical debt from creeping into the project over time. Further, the decoupled architecture and a neat and modular implementation allows agility in bringing rapid changes as per the ever evolving needs and scenarios.Design Principles​In order to serve the Goals and Tenets of the framework, we have followed certain design principles.Framework architecture​The three main pillars of Godspeed framework: eventsources, datasources, and functions or workflows.Do read more about them in the design principles section.Building blocks of framework:​EventSources: Pluggable event sources of different kinds like, HTTP with Express or Fastify, gRpc or Graphql server, cron, web socket, Message bus with Kafka or RabbitMQ, an event from Salesforce.1.1. Events: Events of async and sync kind are defined in standardized YAML DSL with endpoint, authorization rules and Swagger spec of input and output (as applicable).DataSources: Pluggable datastores or API clients, to send or retrieve data. For ex. MongoDB, Redis, AWS API etcWorkflows or Functions: The events invoke functions or workflows which contain the business logic.Config: The configuration variables as well as their values are defined in yaml files under config/ directory. Some variables are specific to the framework and rest variables can be created as per the business use cases.ENV: Sensitive data, like database URLs, that require concealment are specified in .env files and made available in the rest of the project via GSContext object.Features​Edit this pageNextTenetsIntroductionAimsBoosting tech team's efficiencyLower learning curve.Easy brownfield adoptionSecurityFlexibilityScale, performance and monitoringMaintainabilityDesign PrinciplesFramework architectureBuilding blocks of framework:FeaturesForumDiscordGithubTwitterLinkedIn








Godspeed - Meta Framework | Godspeed Docs





Skip to main contentGodspeedDocumentationv2.0v2.0v11. Microservices Framework1. Introduction1.1. Overview1.2. Tenets1.3. Design Principles1.4. Guard Rails2. Getting started3. CLI4. Event sources5. Workflows6. DataSources7. Authentication8. Authorization9. Configs and Mappings10. Inline scripting11. VScode extention12. Telemetry2. ElasticGraph ORM3. Web-UI Starter Kit1. Microservices Framework1. Introduction1.1. OverviewVersion: v2.0On this pageGodspeed - Meta FrameworkThis document is meant for technology leaders, architects, and developers. Its purpose is to present the platform's overarching objectives, guiding principles, design elements, components, and functionalities to the target audience.Introduction​Our mission at Godspeed is to bring greater standardization, best practices and ease of engineering to the tech teams of the world. We wish to achieve this as a collaboration by and for the community.  We wish to develop a meta-framework along with tools, integrations, learning content, licensing and marketplace, based on a value system which fosters develop-rights, equity, fairness and wellbeing for all.We want to democratize tech for teams to effortlessly create, maintain, and monitor complex applications with reduced effort, agility, scalability, quality, performance, cost effectiveness and minimization of technical debt and talent hurdle. Our goal is to liberate teams from the burdensome, repetitive tasks, boilerplate, wiring, so that instead of focussing on the how, they retain a razor sharp focus on the what.To achieve this, we're committed to providing teams with the meta-framework, tools, integrations and learning that they need to develop and maintain products, guided by first principles and best practices likeStandardized implementation across languages, frameworks & toolsDecoupled architecture with plug and play integrationsZero boilerplate with pre-built abstractionsSchema and standards driven developmentShift leftCloud agnostic setupNo vendor lock-inAims​Boosting tech team's efficiency​The meta-framework with developer guardrails, generative features and pre-built integrations provides a ready-made feature set, a YAML DSL for important abstractions, simplified project setup, OTEL based telemetry and devops tooling, streamlining the lives of developers and reducing their work and hence the chance of mistakes. This enables them to concentrate on and achieve their primary tasks with minimal effort, time, and cost.The framework includes essential functionalities of a 'modern microservice' by default, allowing developers to concentrate solely on business logic, resulting in significant reduction in workload.
Lower learning curve.​Developers can deliver simple microservice on their first day itself. The standardized guardrails enforce their adoption and learning of best practices and engineering concepts, upskilling on the way as the projects proceed. In most cases, only a few in the organization need in-depth expertise, while others can quickly adapt to the framework through training and collaborate effectively, with support from internal team or from Godspeed.Easy brownfield adoption​Teams can adopt Godspeed by simply including the NPM module or jar in their existing project and installing the CLI. Godspeed ships as a node module. Hence it can be imported in any nodejs , bunjs or springboot project easily or developers can even reuse the existing event soures and data sources without any hassle.Security​The framework can read the environmental variables from a secure source like K8s Vault. It supports JWT, RBAC and ABAC based fine grained authorization. For data at rest, developers can use encryption mechanisms over datastores. Log redaction allows to hide sensitive information from logs.Flexibility​Developer should be able to implement anything they need, or replace existing eventsources or datasources with ease. They should also be able to migrate a project from one language or framework to another with least effort.Scale, performance and monitoring​For scale, we encourage the adoption of horizontal scaling approach based on Kubernetes. Developers can deploy a service on a Kubernetes cluster on any cloud.For performance, we believe the datasources (APIs and DBs) are the bottlenecks most of the time, and hence the framework allows an easy integration of a cache of choice, over the calls to the datasources. An easier way to setup Graphql like subscriptions and dual writes is planned.For monitoring, the framework microservices allows export of APM and BPM signals in OTEL format which is supported by all major observability backend solutions. We provide a pre-configured Grafana dashboard, with correlated logs and traces, and detailed APM out of the box. Using the devops plugin of Godspeed CLI, teams can install the full Grafana stack with Loki, Mimir, Tempo and Minio, on a Kubernetes cluster for scalable telemetry ingestion.Maintainability​The standardized guardrails with clearly defined developer's boundaries, ensure neat, simple & systematic implementations across projects and individual developers with diverse experiences. This avoids technical debt from creeping into the project over time. Further, the decoupled architecture and a neat and modular implementation allows agility in bringing rapid changes as per the ever evolving needs and scenarios.Design Principles​In order to serve the Goals and Tenets of the framework, we have followed certain design principles.Framework architecture​The three main pillars of Godspeed framework: eventsources, datasources, and functions or workflows.Do read more about them in the design principles section.Building blocks of framework:​EventSources: Pluggable event sources of different kinds like, HTTP with Express or Fastify, gRpc or Graphql server, cron, web socket, Message bus with Kafka or RabbitMQ, an event from Salesforce.1.1. Events: Events of async and sync kind are defined in standardized YAML DSL with endpoint, authorization rules and Swagger spec of input and output (as applicable).DataSources: Pluggable datastores or API clients, to send or retrieve data. For ex. MongoDB, Redis, AWS API etcWorkflows or Functions: The events invoke functions or workflows which contain the business logic.Config: The configuration variables as well as their values are defined in yaml files under config/ directory. Some variables are specific to the framework and rest variables can be created as per the business use cases.ENV: Sensitive data, like database URLs, that require concealment are specified in .env files and made available in the rest of the project via GSContext object.Features​Edit this pageNextTenetsIntroductionAimsBoosting tech team's efficiencyLower learning curve.Easy brownfield adoptionSecurityFlexibilityScale, performance and monitoringMaintainabilityDesign PrinciplesFramework architectureBuilding blocks of framework:FeaturesForumDiscordGithubTwitterLinkedIn








Table of Contents | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).Table of ContentsVersion: v1Table of Contents1. Preface
1.1 Introduction
1.2 Goals
1.3 Features
1.4 Tenets
1.5 Design principals
1.6 Framework architecture
1.7 Scenarios and use cases 2. Introduction
2.1 Developer's work 3. Setup
3.1 Getting started
3.1.1 Glossary
3.1.2 Pre-requisites
3.1.3 Steps to get started
3.1.4 Time to start the development 3.2 Project structure
3.2.1 Scaffolding & Project structure 3.3 Configuration
3.3.1 Introduction
3.3.2 Environment variables
3.3.3 Static variables 3.4 Tests
3.5 Auto watch and build
3.6 Debugger in yaml 4. CLI
4.1 Functionality
4.2 Installation
4.3 Options
4.4 Commands: Outside the dev container
4.5 Commands: Inside the dev container 5. Swagger Specs
5.1 CLI command to generate documentation
5.2 Custom Server URL 6. Events
6.1 Event types
6.2 Event schema & examples for supported sources
6.2.1 JSON schema validation
6.2.2 HTTP event
6.2.3 Kafka event 7. Workflows
7.1 The structure of workflows
7.2 The tasks within workflows
7.3 Location and fully qualified name (id)          of workflows and functions
7.4 Referencing a workflow within an event or another workflow
7.5 Use of Coffee/JS for scripting 7.6 Inbuilt functions
7.6.1 com.gs.http
7.6.2 com.gs.kafka
7.6.3 com.gs.datastore
7.6.4 com.gs.elasticgraph
7.6.5 com.gs.transform
7.6.6 com.gs.series
7.6.7 com.gs.parallel
7.6.8 com.gs.switch
7.6.9 com.gs.each_sequential
7.6.10 com.gs.each_parallel
7.6.11 com.gs.return
7.6.12 com.gs.log
7.6.13 com.gs.dynamic_fn
7.6.14 com.gs.aws
7.6.15 com.gs.redis
7.6.16 com.gs.if, com.gs.elif, com.gs.else 7.7 Developer written functions
7.8 Headers defined at workflow level 7.9 File Upload feature
7.9.1 Workflow spec to upload files with same file key
7.9.2 Workflow spec to upload multiple files with different file keys
7.9.3 Workflow spec to upload file directly from URL 8. Datasources
8.1 Introduction
8.1.1 Datasource types 8.2 Datasources
8.2.1 Before and after hooks to datasource calls 8.3 API datasource
8.3.1 API datasource schema defined externally
8.3.2 API datasource schema defined within the yaml file
8.3.3 Headers defined at datasource level
8.3.4 Headers defined at task level
8.3.5 Example usage 8.4 Datastore as datasource
8.4.1 Schema specification
8.4.2 CLI Commands
8.4.3 Prisma Datastore Setup
8.4.4 Auto generating CRUD APIs from data store models
8.4.5 Sample datastore CRUD task 8.5 Kafka as datasource
8.5.1 Example spec 8.6 Elasticgraph as datasource
8.6.1 Folder Structure
8.6.2 Datasource DSL
8.6.3 Configuration files for elasticgraph
8.6.4 Elasticgraph Setup
8.6.5 Auto generating CRUD APIs for elasticgraph 8.7 Extensible datasources
8.7.1 Datasource definition
8.7.2 Example spec for the event
8.7.3 Example spec for the workflow 8.7 AWS as datasource
8.7.1 Example spec
8.7.2 com.gs.aws workflow 8.9 Redis as datasource
8.9.1 Example spec 8.10 RabbitMQ as datasource
8.10.1 Example spec 9. Caching
9.1 Specifications
9.1.1 Datasource spec for redis
9.1.2 Configuration
9.1.3 Workflow spec 10. Mappings
10.1 Project structure
10.2 Sample mappings
10.3 Use mappings constants in other mapping files 11. Plugins
11.1 Project structure
11.2 Sample plugins
11.3 Sample workflow using plugins 12. Authentication & Authorization
12.1 Authentication
12.1.1 JWT Configuration
12.1.2 Event spec
12.1.3 Generate JWT
12.1.4 Datasource authentication 12.2 Authorization
12.2.1 Workflow DSL
12.2.2 Sample DB query call authorization 13. Telemetry
13.1 Introduction
13.1.1 Architecture 13.2 Goals
13.3 Configuration
13.3.1 OTEL exporter endpoint
13.3.2 OTEL service name 13.3.3 Logging
13.3.3.1 Log level
13.3.3.2 Log fields masking
13.3.3.3 Log format
13.3.3.4 Add custom identifiers in logs 13.4 Custom metrics, traces and logs (BPM)         
13.4.1 DSL spec for custom metrics
13.4.2 DSL spec for custom trace
13.4.3 DSL spec for custom logs 13.5 Observability Stack
13.6 Recommended model for telemetry signals 14. Custom Middleware
14.1 How to add custom middleware in Godspeed 15. Roadmap 16. FAQ
16.1 What is the learning curve of the microservice framework?
16.2 What is the development process and quality metrics?
16.3 How can we adopt new versions of used technology easily and fast? For example, the new Postgres release.
16.4 How easy is it to add new technology in place of an existing one, or add something absolutely new and unique (not existing in the framework)         ?
16.5 Which databases are currently supported? What is the roadmap for future support?
16.6 Does the API handle DB transactions?
16.7 How can apps be decoupled or loosely coupled with DBs?
16.8 When using Godspeed service alongside SpringBoot, what will be the impact on performance with another hop, versus direct connection with DB from Spring Boot?
16.9 What is the strategic advantage of making DB queries through Godspeed?
16.10 How to achieve multi-tenancy in DBs, for a single application?
16.11 How can we start adopting the Godspeed framework?
16.12 How to move out of the Godspeed framework? Can we have a two door exit? I.e. Can we move out of technology and data both?
16.13 How will we prevent unified CRUD API from limiting or choking us?
16.14 What kind of API standards does the framework support?
16.15 Why Rest first approach ? Why not Graphql first approach?
16.16 How are we doing testing given there is quite a bit of custom DSL in the framework. How do we ensure the correctness?
16.17 How will the upgrades and migrations be done to the framework?
16.18 How CRUD APIs will support the paid as well as the non paid features of databases such as MongoDB. For example: MongoDB free vs paid versions will support different features.
16.19 How to ship new models easily?Edit this pageNextAbout GodspeedForumDiscordGithubTwitterLinkedIn








Table of Contents | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).Table of ContentsVersion: v1Table of Contents1. Preface
1.1 Introduction
1.2 Goals
1.3 Features
1.4 Tenets
1.5 Design principals
1.6 Framework architecture
1.7 Scenarios and use cases 2. Introduction
2.1 Developer's work 3. Setup
3.1 Getting started
3.1.1 Glossary
3.1.2 Pre-requisites
3.1.3 Steps to get started
3.1.4 Time to start the development 3.2 Project structure
3.2.1 Scaffolding & Project structure 3.3 Configuration
3.3.1 Introduction
3.3.2 Environment variables
3.3.3 Static variables 3.4 Tests
3.5 Auto watch and build
3.6 Debugger in yaml 4. CLI
4.1 Functionality
4.2 Installation
4.3 Options
4.4 Commands: Outside the dev container
4.5 Commands: Inside the dev container 5. Swagger Specs
5.1 CLI command to generate documentation
5.2 Custom Server URL 6. Events
6.1 Event types
6.2 Event schema & examples for supported sources
6.2.1 JSON schema validation
6.2.2 HTTP event
6.2.3 Kafka event 7. Workflows
7.1 The structure of workflows
7.2 The tasks within workflows
7.3 Location and fully qualified name (id)          of workflows and functions
7.4 Referencing a workflow within an event or another workflow
7.5 Use of Coffee/JS for scripting 7.6 Inbuilt functions
7.6.1 com.gs.http
7.6.2 com.gs.kafka
7.6.3 com.gs.datastore
7.6.4 com.gs.elasticgraph
7.6.5 com.gs.transform
7.6.6 com.gs.series
7.6.7 com.gs.parallel
7.6.8 com.gs.switch
7.6.9 com.gs.each_sequential
7.6.10 com.gs.each_parallel
7.6.11 com.gs.return
7.6.12 com.gs.log
7.6.13 com.gs.dynamic_fn
7.6.14 com.gs.aws
7.6.15 com.gs.redis
7.6.16 com.gs.if, com.gs.elif, com.gs.else 7.7 Developer written functions
7.8 Headers defined at workflow level 7.9 File Upload feature
7.9.1 Workflow spec to upload files with same file key
7.9.2 Workflow spec to upload multiple files with different file keys
7.9.3 Workflow spec to upload file directly from URL 8. Datasources
8.1 Introduction
8.1.1 Datasource types 8.2 Datasources
8.2.1 Before and after hooks to datasource calls 8.3 API datasource
8.3.1 API datasource schema defined externally
8.3.2 API datasource schema defined within the yaml file
8.3.3 Headers defined at datasource level
8.3.4 Headers defined at task level
8.3.5 Example usage 8.4 Datastore as datasource
8.4.1 Schema specification
8.4.2 CLI Commands
8.4.3 Prisma Datastore Setup
8.4.4 Auto generating CRUD APIs from data store models
8.4.5 Sample datastore CRUD task 8.5 Kafka as datasource
8.5.1 Example spec 8.6 Elasticgraph as datasource
8.6.1 Folder Structure
8.6.2 Datasource DSL
8.6.3 Configuration files for elasticgraph
8.6.4 Elasticgraph Setup
8.6.5 Auto generating CRUD APIs for elasticgraph 8.7 Extensible datasources
8.7.1 Datasource definition
8.7.2 Example spec for the event
8.7.3 Example spec for the workflow 8.7 AWS as datasource
8.7.1 Example spec
8.7.2 com.gs.aws workflow 8.9 Redis as datasource
8.9.1 Example spec 8.10 RabbitMQ as datasource
8.10.1 Example spec 9. Caching
9.1 Specifications
9.1.1 Datasource spec for redis
9.1.2 Configuration
9.1.3 Workflow spec 10. Mappings
10.1 Project structure
10.2 Sample mappings
10.3 Use mappings constants in other mapping files 11. Plugins
11.1 Project structure
11.2 Sample plugins
11.3 Sample workflow using plugins 12. Authentication & Authorization
12.1 Authentication
12.1.1 JWT Configuration
12.1.2 Event spec
12.1.3 Generate JWT
12.1.4 Datasource authentication 12.2 Authorization
12.2.1 Workflow DSL
12.2.2 Sample DB query call authorization 13. Telemetry
13.1 Introduction
13.1.1 Architecture 13.2 Goals
13.3 Configuration
13.3.1 OTEL exporter endpoint
13.3.2 OTEL service name 13.3.3 Logging
13.3.3.1 Log level
13.3.3.2 Log fields masking
13.3.3.3 Log format
13.3.3.4 Add custom identifiers in logs 13.4 Custom metrics, traces and logs (BPM)         
13.4.1 DSL spec for custom metrics
13.4.2 DSL spec for custom trace
13.4.3 DSL spec for custom logs 13.5 Observability Stack
13.6 Recommended model for telemetry signals 14. Custom Middleware
14.1 How to add custom middleware in Godspeed 15. Roadmap 16. FAQ
16.1 What is the learning curve of the microservice framework?
16.2 What is the development process and quality metrics?
16.3 How can we adopt new versions of used technology easily and fast? For example, the new Postgres release.
16.4 How easy is it to add new technology in place of an existing one, or add something absolutely new and unique (not existing in the framework)         ?
16.5 Which databases are currently supported? What is the roadmap for future support?
16.6 Does the API handle DB transactions?
16.7 How can apps be decoupled or loosely coupled with DBs?
16.8 When using Godspeed service alongside SpringBoot, what will be the impact on performance with another hop, versus direct connection with DB from Spring Boot?
16.9 What is the strategic advantage of making DB queries through Godspeed?
16.10 How to achieve multi-tenancy in DBs, for a single application?
16.11 How can we start adopting the Godspeed framework?
16.12 How to move out of the Godspeed framework? Can we have a two door exit? I.e. Can we move out of technology and data both?
16.13 How will we prevent unified CRUD API from limiting or choking us?
16.14 What kind of API standards does the framework support?
16.15 Why Rest first approach ? Why not Graphql first approach?
16.16 How are we doing testing given there is quite a bit of custom DSL in the framework. How do we ensure the correctness?
16.17 How will the upgrades and migrations be done to the framework?
16.18 How CRUD APIs will support the paid as well as the non paid features of databases such as MongoDB. For example: MongoDB free vs paid versions will support different features.
16.19 How to ship new models easily?Edit this pageNextAbout GodspeedForumDiscordGithubTwitterLinkedIn








About Godspeed | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).1. PrefaceVersion: v1On this pageGodSpeed – A Microservice frameworkThis document is intended for stakeholders, tech leaders, architects & developers. It will provide high level goals, tenets, design principles, components & features of the platform for the intended audience.
1.1 Introduction​Godspeed is aimed at empowering teams to develop, maintain and observe microservices based backends, with high velocity, scalability, quality and performance.
 We want development (and hence also QA) teams to bypass all the repeatable and reusable work involved in building modern distributed backends with domain driven design, multi-tenancy, microservices and serverless functions. We want the developers to be able to speedily develop microservices in days, instead of months.For the same, we are trying to provide everything that a team needs to create and operate modern microservices. It will be configuration/templating driven, plug & play, extensible by nature and cloud independent. There will be no vendor lock-in, either with Godspeed or any vendor used. It will give developers choice and control over the kind of tools, DBs and cloud providers they wish to use, while following standards and unified interfaces.This framework is being systematically developed by Mindgrep over the last years, across various projects by extracting abstractions and reusable components. It is actively being customized/expanded/improved with new adaptations.1.2 Goals​THE GOALS OF THE FRAMEWORK ARE AIMED TO MAKE BUSINESS AGILE BY EMPOWERING THE PRODUCT & DEVELOPMENT TEAMS TO DELIVER EXCELLENT SOLUTIONS VERY FAST.Developer friendly​Godspeed provides low code implementation, YAML based DSL, prebuilt feature set and easy project setup, making like of developers easy. Thus empowering them to focus and accomplish their core work with the least amount of effort, time & cost.Enhancing developer productivity​The framework provides fundamental functionalities of “a modern microservice” out of the box so that developer only needs to focus on business logic (80% reduction in work).
Smaller, micro teams and lesser learning curve​Module owners can start shipping microservices within a week's ramp-up time. If at all, only a couple of members in the ogranization need to know the nitty gritty. Rest can just train to use the framework, and deliver with their help,or ours.Security​The framework can read the environmental variables from a secure source like K8s Vault. For data in transit and data at rest, we use encryption mechanisms. Also, the framework supports JWT Authentication. Further, all hits to other APIs are secured via security schemas specified in their Open API Specification (OAS 3). Fine grained authorization at API and datasources level is in the roadmap. Read moreEasy and fast migrations​Migrate existing data models to Godspeed via database introspection. Autogenerate CRUD APIs based on the data models. Migrate existing API based on its introspection, to create Godspeed compliant events - planned. Now, all that remains for developers, is simply to migrate the business logic.1.3 Features​1.4 Tenets​Don't repeat yourself​Developer does not need to do anything at the levels lower than the schema (events, datasources) and business logic. All that, including project setup with required docker containers, is handled by the framework. The developers need not to repeat any work from api to api or project to project.Easy to extend & customize​Pluggable interfaces allow new integrations without changing code. For example, replacing datastores, APM/BPM tools, analytics engines, cache, email provider, file storage, CRM etc. should ideally require no change in the application code.Standards driven​Use standards in designing the system. For example, events using CouldEvents. Observability using OpenTelemetry.1.5 Design principals​Three fundamental abstractions​The three fundamental abstractions in the Godspeed are events (sync/async), workflows (business logic) and datasources (APIs/datastores). Read moreUnified Observability For APM and BPM​We will follow OpenTelemetry (OTEL) SDKs to collect and observe telemetry data, including application performance monitoring. This will be integrable with a plethora of open source or commercial tools of choice that integrate with the standard OTEL protocol. Read more1.6 Framework architecture​The three main dimensions of Godspeed framework: events, workflows and datasources.1.7 Scenarios and use cases​Use cases include any kind of microservice, CRUD microservice, wrapper service, search and suggest service, backend for frontend service, orchestration service, domain gateway service, etc.Edit this pagePreviousTable of ContentsNextIntroduction1.1 Introduction1.2 GoalsDeveloper friendlyEnhancing developer productivitySmaller, micro teams and lesser learning curveSecurityEasy and fast migrations1.3 Features1.4 TenetsDon't repeat yourselfEasy to extend & customizeStandards driven1.5 Design principalsThree fundamental abstractionsUnified Observability For APM and BPM1.6 Framework architecture1.7 Scenarios and use casesForumDiscordGithubTwitterLinkedIn








About Godspeed | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).1. PrefaceVersion: v1On this pageGodSpeed – A Microservice frameworkThis document is intended for stakeholders, tech leaders, architects & developers. It will provide high level goals, tenets, design principles, components & features of the platform for the intended audience.
1.1 Introduction​Godspeed is aimed at empowering teams to develop, maintain and observe microservices based backends, with high velocity, scalability, quality and performance.
 We want development (and hence also QA) teams to bypass all the repeatable and reusable work involved in building modern distributed backends with domain driven design, multi-tenancy, microservices and serverless functions. We want the developers to be able to speedily develop microservices in days, instead of months.For the same, we are trying to provide everything that a team needs to create and operate modern microservices. It will be configuration/templating driven, plug & play, extensible by nature and cloud independent. There will be no vendor lock-in, either with Godspeed or any vendor used. It will give developers choice and control over the kind of tools, DBs and cloud providers they wish to use, while following standards and unified interfaces.This framework is being systematically developed by Mindgrep over the last years, across various projects by extracting abstractions and reusable components. It is actively being customized/expanded/improved with new adaptations.1.2 Goals​THE GOALS OF THE FRAMEWORK ARE AIMED TO MAKE BUSINESS AGILE BY EMPOWERING THE PRODUCT & DEVELOPMENT TEAMS TO DELIVER EXCELLENT SOLUTIONS VERY FAST.Developer friendly​Godspeed provides low code implementation, YAML based DSL, prebuilt feature set and easy project setup, making like of developers easy. Thus empowering them to focus and accomplish their core work with the least amount of effort, time & cost.Enhancing developer productivity​The framework provides fundamental functionalities of “a modern microservice” out of the box so that developer only needs to focus on business logic (80% reduction in work).
Smaller, micro teams and lesser learning curve​Module owners can start shipping microservices within a week's ramp-up time. If at all, only a couple of members in the ogranization need to know the nitty gritty. Rest can just train to use the framework, and deliver with their help,or ours.Security​The framework can read the environmental variables from a secure source like K8s Vault. For data in transit and data at rest, we use encryption mechanisms. Also, the framework supports JWT Authentication. Further, all hits to other APIs are secured via security schemas specified in their Open API Specification (OAS 3). Fine grained authorization at API and datasources level is in the roadmap. Read moreEasy and fast migrations​Migrate existing data models to Godspeed via database introspection. Autogenerate CRUD APIs based on the data models. Migrate existing API based on its introspection, to create Godspeed compliant events - planned. Now, all that remains for developers, is simply to migrate the business logic.1.3 Features​1.4 Tenets​Don't repeat yourself​Developer does not need to do anything at the levels lower than the schema (events, datasources) and business logic. All that, including project setup with required docker containers, is handled by the framework. The developers need not to repeat any work from api to api or project to project.Easy to extend & customize​Pluggable interfaces allow new integrations without changing code. For example, replacing datastores, APM/BPM tools, analytics engines, cache, email provider, file storage, CRM etc. should ideally require no change in the application code.Standards driven​Use standards in designing the system. For example, events using CouldEvents. Observability using OpenTelemetry.1.5 Design principals​Three fundamental abstractions​The three fundamental abstractions in the Godspeed are events (sync/async), workflows (business logic) and datasources (APIs/datastores). Read moreUnified Observability For APM and BPM​We will follow OpenTelemetry (OTEL) SDKs to collect and observe telemetry data, including application performance monitoring. This will be integrable with a plethora of open source or commercial tools of choice that integrate with the standard OTEL protocol. Read more1.6 Framework architecture​The three main dimensions of Godspeed framework: events, workflows and datasources.1.7 Scenarios and use cases​Use cases include any kind of microservice, CRUD microservice, wrapper service, search and suggest service, backend for frontend service, orchestration service, domain gateway service, etc.Edit this pagePreviousTable of ContentsNextIntroduction1.1 Introduction1.2 GoalsDeveloper friendlyEnhancing developer productivitySmaller, micro teams and lesser learning curveSecurityEasy and fast migrations1.3 Features1.4 TenetsDon't repeat yourselfEasy to extend & customizeStandards driven1.5 Design principalsThree fundamental abstractionsUnified Observability For APM and BPM1.6 Framework architecture1.7 Scenarios and use casesForumDiscordGithubTwitterLinkedIn








Introduction | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).2. IntroductionVersion: v1On this pageIntroductionEvery microservice in the Godspeed framework has three fundamental abstractions, and the developer needs to work with just these three.Events: Events trigger workflows. Events are generated by event sources like REST endpoints, gRPC, message bus, webhooks, websockets, S3, and more...Workflows: Workflows are triggered by events. They not only perform business logic but also provide orchestration over datasources and microservices, and data/API federation. They will use datasources to store or retrieve data, join across various datasources, transform data, emit events and send responses. The framework provides a YAML dsl with some inbuilt workflows. If YAML does not suffice for any particular case, developers can currently put JS/TS workflows alongside YAML workflows and use them. Coming in future: Support for other languages.Datasources: Datasources are locations where data can be stored or read from. For example API datasource (another microservice or third party), datastores (RDBMS, document, key-value), file system, S3 storage, etc. A microservice can use multiple datasources. The framework provides abstractions for Authn/Authz making it easy for the developer to express the same in a low code manner. These abstractions allow the developer to focus purely on their business logic. 99.9% - 100% of typical functionality needed by the developer is covered by the framework's YAML-based DSL. Devs can forget about the low-level stuff they typically need to do - which accounts for 90% of the work in typical app dev scenario. The framework aims to handle all the low level functionality and saves developer's effort to do the same. For example creating controllers for endpoints, endpoint authentication/authorization, input validation, auto-telemetry with distributed context, setting up DB client and authorizing DB access, authentication of third party API, key management, creating Swagger docs or Postman collection, creating basic test suite based on documentation, etc.There is a standard project structure which will give the developer a kickstart to their project and also reference code/declarations, for the kind of stuff they can do using the framework.2.1 Developer's work​The developer will use the CLI provided by the framework to setup a new microservice project and start developing. (S)he will configure the events, datasources, and workflows for the required functionality, along with mappings, environment variables, and common configurations, like for telemetry. To configure the datasources, For datastores: they will either define the db schema or autogenerate it from the existing database using the CLI. For APIs: they will need to define the APIs OpenAPI schema or provide the url for the same. Salient Features​NoteSome of the features mentioned here are in the product roadmap and planned for upcoming releases.Schema driven developmentThe developer has to specify the API and data schema to start the development.YAML based DSL and configurationsWe have YAML based DSL which makes it much easier and succinct to express policies, business logic, and configurations. Code is shorter and easier to comprehend than programming, even for new learners. This DSL can be further customized by developers to add custom requirements. Multi datastore supportThe same model configuration & unified CRUD API (including full-text search and autosuggest) will provide interfaces with multiple kinds of datastores (SQL or NoSQL). The API is aimed to provide validation, relationship management, transactions, denormalization, and multilingual support. Each integration will support the possible functionality as per the nature of the store.  Data validationThe framework provides validation of third party API requests & responses, datastore queries, and its own API endpoints request and response. The developer only needs to specify the schema of third party API, own microservice API, and datastore model. Rest is taken care of by the framework. In case of more complex validation scenarios, where customer journeys may require conditional validation of incoming requests based on some attributes (in the database or the query {i.e. subject, object, environment, payload}), the developer can add such rules to the application logic as part of the workflows.AuthenticationThe microservice framework authenticates every incoming request and extracts the user role and other info, for further processing, based on a valid JWT token. An IAM provider like ORY Kratos can be integrated into the platform for providing identity service. It will generate a JWT token which will include user id, information, and roles. This token is consumed by the microservices for user validation.Authorization (Planned)Each microservice will do the job of authorization for any request. Developers will write authorization rules for every microservice in simple configuration files. This will cover not only API endpoint access but also fine grained data access from datastores. This will integrate with third party Authz services in a pluggable way, with abstractions. Distributed transactions (Planned)Each domain’s orchestrator is able to use the Saga pattern to ensure distributed transactions across multiple microservices.Autogenerated documentationThe framework provides autogenerated documentation using CLI.Autogenerated CRUD API (Planned)The framework provides autogenereated CRUD APIs from database model. Generated API's can be extended by the developers as per their needs.Autogenerated test suite The framework provides autogenerated test suite for APIs using CLI. Multiple languages supportIn case YAML is not enough for a corner case, developers can write custom business logic in any language. If written in JS/TS, they can place the code within the same microservice project. Other language support will also work in the same way, and is planned for the future.ObservabilityThe framework provides automatic observability support with correlation, for modern distributed systems, via the OpenTelemetry spec. For the same, it will work in conjunction with the microservice mesh used. The developer can extend that to include customized observability. This can integrate with any tools that support OpenTelemetry.LoggingThe inbuilt logging mechanism will log both sync request/response cycle or async events, for both success and failure scenarios. MonitoringThe framework allows the developer to monitor custom business metrics, along with application level metrics like latency, success, and failures. TracingEvery incoming sync & async request will carry trace information in its headers. The same is propagated further through the microservice framework when it makes a sync or async hit to another service. Edit this pagePreviousAbout GodspeedNext3.1 Getting started2.1 Developer's workSalient FeaturesForumDiscordGithubTwitterLinkedIn








Introduction | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).2. IntroductionVersion: v1On this pageIntroductionEvery microservice in the Godspeed framework has three fundamental abstractions, and the developer needs to work with just these three.Events: Events trigger workflows. Events are generated by event sources like REST endpoints, gRPC, message bus, webhooks, websockets, S3, and more...Workflows: Workflows are triggered by events. They not only perform business logic but also provide orchestration over datasources and microservices, and data/API federation. They will use datasources to store or retrieve data, join across various datasources, transform data, emit events and send responses. The framework provides a YAML dsl with some inbuilt workflows. If YAML does not suffice for any particular case, developers can currently put JS/TS workflows alongside YAML workflows and use them. Coming in future: Support for other languages.Datasources: Datasources are locations where data can be stored or read from. For example API datasource (another microservice or third party), datastores (RDBMS, document, key-value), file system, S3 storage, etc. A microservice can use multiple datasources. The framework provides abstractions for Authn/Authz making it easy for the developer to express the same in a low code manner. These abstractions allow the developer to focus purely on their business logic. 99.9% - 100% of typical functionality needed by the developer is covered by the framework's YAML-based DSL. Devs can forget about the low-level stuff they typically need to do - which accounts for 90% of the work in typical app dev scenario. The framework aims to handle all the low level functionality and saves developer's effort to do the same. For example creating controllers for endpoints, endpoint authentication/authorization, input validation, auto-telemetry with distributed context, setting up DB client and authorizing DB access, authentication of third party API, key management, creating Swagger docs or Postman collection, creating basic test suite based on documentation, etc.There is a standard project structure which will give the developer a kickstart to their project and also reference code/declarations, for the kind of stuff they can do using the framework.2.1 Developer's work​The developer will use the CLI provided by the framework to setup a new microservice project and start developing. (S)he will configure the events, datasources, and workflows for the required functionality, along with mappings, environment variables, and common configurations, like for telemetry. To configure the datasources, For datastores: they will either define the db schema or autogenerate it from the existing database using the CLI. For APIs: they will need to define the APIs OpenAPI schema or provide the url for the same. Salient Features​NoteSome of the features mentioned here are in the product roadmap and planned for upcoming releases.Schema driven developmentThe developer has to specify the API and data schema to start the development.YAML based DSL and configurationsWe have YAML based DSL which makes it much easier and succinct to express policies, business logic, and configurations. Code is shorter and easier to comprehend than programming, even for new learners. This DSL can be further customized by developers to add custom requirements. Multi datastore supportThe same model configuration & unified CRUD API (including full-text search and autosuggest) will provide interfaces with multiple kinds of datastores (SQL or NoSQL). The API is aimed to provide validation, relationship management, transactions, denormalization, and multilingual support. Each integration will support the possible functionality as per the nature of the store.  Data validationThe framework provides validation of third party API requests & responses, datastore queries, and its own API endpoints request and response. The developer only needs to specify the schema of third party API, own microservice API, and datastore model. Rest is taken care of by the framework. In case of more complex validation scenarios, where customer journeys may require conditional validation of incoming requests based on some attributes (in the database or the query {i.e. subject, object, environment, payload}), the developer can add such rules to the application logic as part of the workflows.AuthenticationThe microservice framework authenticates every incoming request and extracts the user role and other info, for further processing, based on a valid JWT token. An IAM provider like ORY Kratos can be integrated into the platform for providing identity service. It will generate a JWT token which will include user id, information, and roles. This token is consumed by the microservices for user validation.Authorization (Planned)Each microservice will do the job of authorization for any request. Developers will write authorization rules for every microservice in simple configuration files. This will cover not only API endpoint access but also fine grained data access from datastores. This will integrate with third party Authz services in a pluggable way, with abstractions. Distributed transactions (Planned)Each domain’s orchestrator is able to use the Saga pattern to ensure distributed transactions across multiple microservices.Autogenerated documentationThe framework provides autogenerated documentation using CLI.Autogenerated CRUD API (Planned)The framework provides autogenereated CRUD APIs from database model. Generated API's can be extended by the developers as per their needs.Autogenerated test suite The framework provides autogenerated test suite for APIs using CLI. Multiple languages supportIn case YAML is not enough for a corner case, developers can write custom business logic in any language. If written in JS/TS, they can place the code within the same microservice project. Other language support will also work in the same way, and is planned for the future.ObservabilityThe framework provides automatic observability support with correlation, for modern distributed systems, via the OpenTelemetry spec. For the same, it will work in conjunction with the microservice mesh used. The developer can extend that to include customized observability. This can integrate with any tools that support OpenTelemetry.LoggingThe inbuilt logging mechanism will log both sync request/response cycle or async events, for both success and failure scenarios. MonitoringThe framework allows the developer to monitor custom business metrics, along with application level metrics like latency, success, and failures. TracingEvery incoming sync & async request will carry trace information in its headers. The same is propagated further through the microservice framework when it makes a sync or async hit to another service. Edit this pagePreviousAbout GodspeedNext3.1 Getting started2.1 Developer's workSalient FeaturesForumDiscordGithubTwitterLinkedIn








3.1 Getting started | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup3.1 Getting started3.2 Project structure3.3 Configuration3.4 Tests3.5 Auto watch and build3.6 Debugger in Yaml4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).3. Setup3.1 Getting startedVersion: v1On this pageGetting startedHereby is a step by step guide on running your first project. The setup is independent of the OS you are running it on.infoYou can also refer to tutorial on Getting Started with Godspeed.3.1.1 Glossary​gs_service: The framework code version. During this setup, you will be asked to select the version of gs_service.
Remote containers/Dev containers: Refer VSCode Remote containers for more information.3.1.2 Pre-requisites​Please ensure you have the following in your machineNVM, with Node LTS installed (Currently 16+)Visual Studio Code LTS, with the following plugins installed:Remote ContainersRun on Save Refer Run On SaveGodspeed Extension PackDocker-desktop should be up and running.On Linux systems, please ensure that docker compose plugin is installed. You can verify it by executing docker compose version command. Refer Install Compose plugin for more information.Git Hardware recommendations 
RAM: 8GB
Hard Disk: SSDtipDepending your setup, you may need to run the above command using administrator privilegesOn Windows machines, sometimes Docker-desktop doesn't start. Make sure you have WSL installed with Ubuntu 18.04, for Docker to work fine.3.1.3 Steps to get started​Step1: Install the Godspeed CLI​npm install -g @mindgrep/godspeedStep 2: Setting up a project on your local machine​noteIf you are creating a new project then follow section 2.1
ORIf you are setting up a project from any existing git repository then follow section 2.22.1 Create a new project​godspeed create my_test_projectDuring the setup, you will be asked which datastores you need. Also whether you need Kafka. Say yes or no, depending on your requirements.By default, latest version is selected for gs_service. You should select either latest or any highest semantic version available in the list.2.2 Setting up a project from an existing GIT repository​Clone the git repository on your local machine.cd <your git repo>godspeed updateDuring the setup, you will be asked which datastores you need. Also whether you need Kafka. Say yes or no, depending on your requirements.By default, latest version is selected for gs_service. You should select either latest or any highest semantic version available in the list.Step3: cd to your project​cd <your project directory>Step4: Start Visual Studio from the project directory​code .Step 5: Open in Dev container​Again click on the dev container tray icon. If this is your first time, click on Open folder in Dev Container . Else for every other time, click on Re-open in Dev ContainerStep 6: Building the project​  godspeed buildStep 7:​Godspeed framework relies on Prisma ORM to interact with databases. And for Prisma to work there should be prisma client should be generated. Sometimes godspeed build don't generate that, If that is the case, Client should be generated manually using below command.To verify if prisma client is generated od not, Look for generated-client folder in src/datasources. If it is not there. Run below command.  godspeed prisma generate --schema=<path/to/prisma/schema>In order to sync your models to the db, run the command below  godspeed prisma push --schema=<path/to/prisma/schema>Step 8: Start the service for local development in watch mode​  godspeed servetipYou can use godspeed gen-crud-api to autogenerate CRUD apis for your prisma file.tipWith the dev container running, we have auto watch and auto build enabled when you make changes to your project files. You don't need to run build manually everytime you make changes.3.1.4 Time to start the development​If you have successfully reached here, then it is time to start the development of your project!Edit this pagePreviousIntroductionNext3.2 Project structure3.1.1 Glossary3.1.2 Pre-requisites3.1.3 Steps to get startedStep1: Install the Godspeed CLIStep 2: Setting up a project on your local machine2.1 Create a new project2.2 Setting up a project from an existing GIT repositoryStep3: cd to your projectStep4: Start Visual Studio from the project directoryStep 5: Open in Dev containerStep 6: Building the projectStep 7:Step 8: Start the service for local development in watch mode3.1.4 Time to start the developmentForumDiscordGithubTwitterLinkedIn








3.1 Getting started | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup3.1 Getting started3.2 Project structure3.3 Configuration3.4 Tests3.5 Auto watch and build3.6 Debugger in Yaml4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).3. Setup3.1 Getting startedVersion: v1On this pageGetting startedHereby is a step by step guide on running your first project. The setup is independent of the OS you are running it on.infoYou can also refer to tutorial on Getting Started with Godspeed.3.1.1 Glossary​gs_service: The framework code version. During this setup, you will be asked to select the version of gs_service.
Remote containers/Dev containers: Refer VSCode Remote containers for more information.3.1.2 Pre-requisites​Please ensure you have the following in your machineNVM, with Node LTS installed (Currently 16+)Visual Studio Code LTS, with the following plugins installed:Remote ContainersRun on Save Refer Run On SaveGodspeed Extension PackDocker-desktop should be up and running.On Linux systems, please ensure that docker compose plugin is installed. You can verify it by executing docker compose version command. Refer Install Compose plugin for more information.Git Hardware recommendations 
RAM: 8GB
Hard Disk: SSDtipDepending your setup, you may need to run the above command using administrator privilegesOn Windows machines, sometimes Docker-desktop doesn't start. Make sure you have WSL installed with Ubuntu 18.04, for Docker to work fine.3.1.3 Steps to get started​Step1: Install the Godspeed CLI​npm install -g @mindgrep/godspeedStep 2: Setting up a project on your local machine​noteIf you are creating a new project then follow section 2.1
ORIf you are setting up a project from any existing git repository then follow section 2.22.1 Create a new project​godspeed create my_test_projectDuring the setup, you will be asked which datastores you need. Also whether you need Kafka. Say yes or no, depending on your requirements.By default, latest version is selected for gs_service. You should select either latest or any highest semantic version available in the list.2.2 Setting up a project from an existing GIT repository​Clone the git repository on your local machine.cd <your git repo>godspeed updateDuring the setup, you will be asked which datastores you need. Also whether you need Kafka. Say yes or no, depending on your requirements.By default, latest version is selected for gs_service. You should select either latest or any highest semantic version available in the list.Step3: cd to your project​cd <your project directory>Step4: Start Visual Studio from the project directory​code .Step 5: Open in Dev container​Again click on the dev container tray icon. If this is your first time, click on Open folder in Dev Container . Else for every other time, click on Re-open in Dev ContainerStep 6: Building the project​  godspeed buildStep 7:​Godspeed framework relies on Prisma ORM to interact with databases. And for Prisma to work there should be prisma client should be generated. Sometimes godspeed build don't generate that, If that is the case, Client should be generated manually using below command.To verify if prisma client is generated od not, Look for generated-client folder in src/datasources. If it is not there. Run below command.  godspeed prisma generate --schema=<path/to/prisma/schema>In order to sync your models to the db, run the command below  godspeed prisma push --schema=<path/to/prisma/schema>Step 8: Start the service for local development in watch mode​  godspeed servetipYou can use godspeed gen-crud-api to autogenerate CRUD apis for your prisma file.tipWith the dev container running, we have auto watch and auto build enabled when you make changes to your project files. You don't need to run build manually everytime you make changes.3.1.4 Time to start the development​If you have successfully reached here, then it is time to start the development of your project!Edit this pagePreviousIntroductionNext3.2 Project structure3.1.1 Glossary3.1.2 Pre-requisites3.1.3 Steps to get startedStep1: Install the Godspeed CLIStep 2: Setting up a project on your local machine2.1 Create a new project2.2 Setting up a project from an existing GIT repositoryStep3: cd to your projectStep4: Start Visual Studio from the project directoryStep 5: Open in Dev containerStep 6: Building the projectStep 7:Step 8: Start the service for local development in watch mode3.1.4 Time to start the developmentForumDiscordGithubTwitterLinkedIn








3.2 Project structure | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup3.1 Getting started3.2 Project structure3.3 Configuration3.4 Tests3.5 Auto watch and build3.6 Debugger in Yaml4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).3. Setup3.2 Project structureVersion: v1On this pageIntroductionThe project root folder gets created in current folder under the projectName which is used in godspeed create command using godspeed CLI. The project contains two folders: src/ and config/. Click here for more information on godspeed create command.3.2.1 Scaffolding & Project structure​Project Structure with no examples​The project contains blank structure with no examples/templates when it is created using godspeed create -n command option. Refer command here for more information.  .├── config│   ├── custom-environment-variables.yaml│   ├── default.yaml│   ├── index.yaml│   └── telemetry├── package.json└── src    ├── datasources    ├── events    ├── functions    └── mappingsProject Structure with examples​The project contains following heirarchy with examples when it is created without using godspeed create -n command option. Refer command here for more information.  .├── config│   ├── custom-environment-variables.yaml│   ├── default.yaml│   ├── index.yaml│   └── telemetry│       └── index.yaml├── package.json└── src    ├── datasources    │   └── httpbin.yaml    ├── events    │   ├── call_another_workflow.yaml    │   ├── document.yaml    │   ├── helloworld.yaml    │   ├── httpbin_anything.yaml    │   ├── run_tasks_in_parallel.yaml    │   ├── sum.yaml    │   └── switch_case.yaml    ├── functions    │   └── com    │       └── biz    │           ├── call_another_wf.yaml    │           ├── documents    │           │   └── upload_file.yaml    │           ├── helloworld.yaml    │           ├── httpbin_anything.yaml    │           ├── run_tasks_in_parallel.yaml    │           ├── sub_wf.yaml    │           ├── sum.js    │           ├── sum_workflow.yaml    │           └── switch_case.yaml    └── mappings        └── index.yamlEdit this pagePrevious3.1 Getting startedNext3.3.1 Introduction3.2.1 Scaffolding & Project structureProject Structure with no examplesProject Structure with examplesForumDiscordGithubTwitterLinkedIn








3.2 Project structure | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup3.1 Getting started3.2 Project structure3.3 Configuration3.4 Tests3.5 Auto watch and build3.6 Debugger in Yaml4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).3. Setup3.2 Project structureVersion: v1On this pageIntroductionThe project root folder gets created in current folder under the projectName which is used in godspeed create command using godspeed CLI. The project contains two folders: src/ and config/. Click here for more information on godspeed create command.3.2.1 Scaffolding & Project structure​Project Structure with no examples​The project contains blank structure with no examples/templates when it is created using godspeed create -n command option. Refer command here for more information.  .├── config│   ├── custom-environment-variables.yaml│   ├── default.yaml│   ├── index.yaml│   └── telemetry├── package.json└── src    ├── datasources    ├── events    ├── functions    └── mappingsProject Structure with examples​The project contains following heirarchy with examples when it is created without using godspeed create -n command option. Refer command here for more information.  .├── config│   ├── custom-environment-variables.yaml│   ├── default.yaml│   ├── index.yaml│   └── telemetry│       └── index.yaml├── package.json└── src    ├── datasources    │   └── httpbin.yaml    ├── events    │   ├── call_another_workflow.yaml    │   ├── document.yaml    │   ├── helloworld.yaml    │   ├── httpbin_anything.yaml    │   ├── run_tasks_in_parallel.yaml    │   ├── sum.yaml    │   └── switch_case.yaml    ├── functions    │   └── com    │       └── biz    │           ├── call_another_wf.yaml    │           ├── documents    │           │   └── upload_file.yaml    │           ├── helloworld.yaml    │           ├── httpbin_anything.yaml    │           ├── run_tasks_in_parallel.yaml    │           ├── sub_wf.yaml    │           ├── sum.js    │           ├── sum_workflow.yaml    │           └── switch_case.yaml    └── mappings        └── index.yamlEdit this pagePrevious3.1 Getting startedNext3.3.1 Introduction3.2.1 Scaffolding & Project structureProject Structure with no examplesProject Structure with examplesForumDiscordGithubTwitterLinkedIn








3.3.1 Introduction | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup3.1 Getting started3.2 Project structure3.3 Configuration3.3.1 Introduction3.3.2 Environment variables3.3.3 Static variables3.3.4 Custom SwaggerSpec Documentation3.4 Tests3.5 Auto watch and build3.6 Debugger in Yaml4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).3. Setup3.3 Configuration3.3.1 IntroductionVersion: v1On this page3.3.1 IntroductionThe configuration variables as well as their values are defined in yaml files under config/ directory. These variables can be replaced as per the business use cases. The default directory structure is given as below:├── config│   ├── custom-environment-variables.yaml│   ├── default.yamlFile Naming and Load Order​The configuration files under config/ directory can have specific naming conventions and load order. Please refer File Name and Load Order for more information.Edit this pagePrevious3.2 Project structureNext3.3.2 Environment variablesFile Naming and Load OrderForumDiscordGithubTwitterLinkedIn








3.3.1 Introduction | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup3.1 Getting started3.2 Project structure3.3 Configuration3.3.1 Introduction3.3.2 Environment variables3.3.3 Static variables3.3.4 Custom SwaggerSpec Documentation3.4 Tests3.5 Auto watch and build3.6 Debugger in Yaml4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).3. Setup3.3 Configuration3.3.1 IntroductionVersion: v1On this page3.3.1 IntroductionThe configuration variables as well as their values are defined in yaml files under config/ directory. These variables can be replaced as per the business use cases. The default directory structure is given as below:├── config│   ├── custom-environment-variables.yaml│   ├── default.yamlFile Naming and Load Order​The configuration files under config/ directory can have specific naming conventions and load order. Please refer File Name and Load Order for more information.Edit this pagePrevious3.2 Project structureNext3.3.2 Environment variablesFile Naming and Load OrderForumDiscordGithubTwitterLinkedIn








3.3.2 Environment variables | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup3.1 Getting started3.2 Project structure3.3 Configuration3.3.1 Introduction3.3.2 Environment variables3.3.3 Static variables3.3.4 Custom SwaggerSpec Documentation3.4 Tests3.5 Auto watch and build3.6 Debugger in Yaml4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).3. Setup3.3 Configuration3.3.2 Environment variablesVersion: v1On this pageEnvironment variablesThe environment variables are defined in yaml files under config/custom-environment-variables.yaml file. The default directory structure is given as below:├── config│   ├── custom-environment-variables.yamlnoteAny configuration which includes secrets or passwords is recommended to be defined using environment variables only.custom-environment-variables.yaml​This is a sample for custom environment variables where these variables gets values from environment variables set in the environment. my_datasource:  base_url: MY_DATASOURCE_BASE_URL  api_key: MY_DATASOURCE_API_KEY  api_token: MY_DATASOURCE_API_TOKENkafka:  brokers:    __name: KAFKA_BROKERS    __format: json  client_id: KAFKA_CLIENT_IDjwt:  issuer: JWT_ISS  audience: JWT_AUD  secretOrKey: JWT_SECRETprisma_secret: PRISMA_SECRETFor example, MY_DATASOURCE_BASE_URL is defined as an environment variable. To specify its value, you need to export this variable in the environment as given below:$ export MY_DATASOURCE_BASE_URL=https://httpbin.org/After exporting the environment variable, you can access this variable in your project by using scripting <% config.my_datasource.base_url %>Edit this pagePrevious3.3.1 IntroductionNext3.3.3 Static variablescustom-environment-variables.yamlForumDiscordGithubTwitterLinkedIn








3.3.2 Environment variables | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup3.1 Getting started3.2 Project structure3.3 Configuration3.3.1 Introduction3.3.2 Environment variables3.3.3 Static variables3.3.4 Custom SwaggerSpec Documentation3.4 Tests3.5 Auto watch and build3.6 Debugger in Yaml4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).3. Setup3.3 Configuration3.3.2 Environment variablesVersion: v1On this pageEnvironment variablesThe environment variables are defined in yaml files under config/custom-environment-variables.yaml file. The default directory structure is given as below:├── config│   ├── custom-environment-variables.yamlnoteAny configuration which includes secrets or passwords is recommended to be defined using environment variables only.custom-environment-variables.yaml​This is a sample for custom environment variables where these variables gets values from environment variables set in the environment. my_datasource:  base_url: MY_DATASOURCE_BASE_URL  api_key: MY_DATASOURCE_API_KEY  api_token: MY_DATASOURCE_API_TOKENkafka:  brokers:    __name: KAFKA_BROKERS    __format: json  client_id: KAFKA_CLIENT_IDjwt:  issuer: JWT_ISS  audience: JWT_AUD  secretOrKey: JWT_SECRETprisma_secret: PRISMA_SECRETFor example, MY_DATASOURCE_BASE_URL is defined as an environment variable. To specify its value, you need to export this variable in the environment as given below:$ export MY_DATASOURCE_BASE_URL=https://httpbin.org/After exporting the environment variable, you can access this variable in your project by using scripting <% config.my_datasource.base_url %>Edit this pagePrevious3.3.1 IntroductionNext3.3.3 Static variablescustom-environment-variables.yamlForumDiscordGithubTwitterLinkedIn








3.3.3 Static variables | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup3.1 Getting started3.2 Project structure3.3 Configuration3.3.1 Introduction3.3.2 Environment variables3.3.3 Static variables3.3.4 Custom SwaggerSpec Documentation3.4 Tests3.5 Auto watch and build3.6 Debugger in Yaml4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).3. Setup3.3 Configuration3.3.3 Static variablesVersion: v1On this pageStatic variablesThe static variables as well as their values are defined in yaml files under config/ directory. These variables can be replaced as per the business use cases. The default directory structure is given as below:├── config│   ├── default.yamlnoteAny configuration which includes secrets or passwords is recommended to be defined using environment variables only. Avoid using static variables for secrets and passwords.default.yaml​This file contains some predefined variables. Below is a sample file which defines the static variables used in Godspeed.log_level: debuglang: coffeeredact: [] # fields to hide. Sample: ['ns', 'req.headers']server_url: https://api.example.com:8443/v1/apihttpbin: # sample api datasource url  base_url: https://httpbin.orgrequest_body_limit: 50mbfile_size_limit : 50mblog_level is the minimum log level to log. Log messages with a lower limit will not get logged. The default value is 'info'.
The available levels are 'fatal', 'error', 'warn', 'info', 'debug', 'trace' or 'silent'.
lang is the language used for scripting in the workflows. The default value is 'coffee'.
The available values are 'coffee' or 'js'. Refer Coffee/JS scripting for more information.
redact is the list of fields, the values for which, you want to hide from the logs. The default value is blank. Refer Logs field masking for more information.
server_url is the custom server url which you want to use as Servers in swagger specs/auto generated documentation. Refer Custom Server URLrequest_body_limit This variable sets the limit for the request body size. It checks if config.request_body_limit is defined in the application's configuration. If it is, the value from the configuration is used; otherwise, it defaults to 50 1024  1024 bytes (50 megabytes).file_size_limit This variable sets the limit for the file size. Similar to request_body_limit, it checks if config.file_size_limit is defined in the configuration. If it is, the value from the configuration is used; otherwise, it defaults to 50  1024  1024 bytes (50 megabytes).Edit this pagePrevious3.3.2 Environment variablesNext3.3.4 Custom SwaggerSpec Documentationdefault.yamlForumDiscordGithubTwitterLinkedIn








3.3.3 Static variables | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup3.1 Getting started3.2 Project structure3.3 Configuration3.3.1 Introduction3.3.2 Environment variables3.3.3 Static variables3.3.4 Custom SwaggerSpec Documentation3.4 Tests3.5 Auto watch and build3.6 Debugger in Yaml4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).3. Setup3.3 Configuration3.3.3 Static variablesVersion: v1On this pageStatic variablesThe static variables as well as their values are defined in yaml files under config/ directory. These variables can be replaced as per the business use cases. The default directory structure is given as below:├── config│   ├── default.yamlnoteAny configuration which includes secrets or passwords is recommended to be defined using environment variables only. Avoid using static variables for secrets and passwords.default.yaml​This file contains some predefined variables. Below is a sample file which defines the static variables used in Godspeed.log_level: debuglang: coffeeredact: [] # fields to hide. Sample: ['ns', 'req.headers']server_url: https://api.example.com:8443/v1/apihttpbin: # sample api datasource url  base_url: https://httpbin.orgrequest_body_limit: 50mbfile_size_limit : 50mblog_level is the minimum log level to log. Log messages with a lower limit will not get logged. The default value is 'info'.
The available levels are 'fatal', 'error', 'warn', 'info', 'debug', 'trace' or 'silent'.
lang is the language used for scripting in the workflows. The default value is 'coffee'.
The available values are 'coffee' or 'js'. Refer Coffee/JS scripting for more information.
redact is the list of fields, the values for which, you want to hide from the logs. The default value is blank. Refer Logs field masking for more information.
server_url is the custom server url which you want to use as Servers in swagger specs/auto generated documentation. Refer Custom Server URLrequest_body_limit This variable sets the limit for the request body size. It checks if config.request_body_limit is defined in the application's configuration. If it is, the value from the configuration is used; otherwise, it defaults to 50 1024  1024 bytes (50 megabytes).file_size_limit This variable sets the limit for the file size. Similar to request_body_limit, it checks if config.file_size_limit is defined in the configuration. If it is, the value from the configuration is used; otherwise, it defaults to 50  1024  1024 bytes (50 megabytes).Edit this pagePrevious3.3.2 Environment variablesNext3.3.4 Custom SwaggerSpec Documentationdefault.yamlForumDiscordGithubTwitterLinkedIn








3.3.4 Custom SwaggerSpec Documentation | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup3.1 Getting started3.2 Project structure3.3 Configuration3.3.1 Introduction3.3.2 Environment variables3.3.3 Static variables3.3.4 Custom SwaggerSpec Documentation3.4 Tests3.5 Auto watch and build3.6 Debugger in Yaml4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).3. Setup3.3 Configuration3.3.4 Custom SwaggerSpec DocumentationVersion: v1On this pageAPI DocumentationThis documentation provides details about the API for the Custom Swagger Specification.Swagger Specifications​You can customize the Swagger specifications for this API by creating a JSON file named swagger.json in the /config directory of your project. If the swagger.json file is not present, the default Swagger specification will be used.Custom Swagger Specifications​To define custom Swagger specifications, create a JSON file named swagger.json in the /config directory with the following content:{"info": {  "title": "Sample Pet Store App",  "summary": "A pet store manager.",  "description": "This is a sample server for a pet store.",  "termsOfService": "https://example.com/terms/",  "contact": {    "name": "API Support",    "url": "https://www.example.com/support",    "email": "support@example.com"  },  "license": {    "name": "Apache 2.0",    "url": "https://www.apache.org/licenses/LICENSE-2.0.html"  },  "version": "1.0.1"}}Edit this pagePrevious3.3.3 Static variablesNext3.4 TestsSwagger SpecificationsCustom Swagger SpecificationsForumDiscordGithubTwitterLinkedIn








3.3.4 Custom SwaggerSpec Documentation | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup3.1 Getting started3.2 Project structure3.3 Configuration3.3.1 Introduction3.3.2 Environment variables3.3.3 Static variables3.3.4 Custom SwaggerSpec Documentation3.4 Tests3.5 Auto watch and build3.6 Debugger in Yaml4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).3. Setup3.3 Configuration3.3.4 Custom SwaggerSpec DocumentationVersion: v1On this pageAPI DocumentationThis documentation provides details about the API for the Custom Swagger Specification.Swagger Specifications​You can customize the Swagger specifications for this API by creating a JSON file named swagger.json in the /config directory of your project. If the swagger.json file is not present, the default Swagger specification will be used.Custom Swagger Specifications​To define custom Swagger specifications, create a JSON file named swagger.json in the /config directory with the following content:{"info": {  "title": "Sample Pet Store App",  "summary": "A pet store manager.",  "description": "This is a sample server for a pet store.",  "termsOfService": "https://example.com/terms/",  "contact": {    "name": "API Support",    "url": "https://www.example.com/support",    "email": "support@example.com"  },  "license": {    "name": "Apache 2.0",    "url": "https://www.apache.org/licenses/LICENSE-2.0.html"  },  "version": "1.0.1"}}Edit this pagePrevious3.3.3 Static variablesNext3.4 TestsSwagger SpecificationsCustom Swagger SpecificationsForumDiscordGithubTwitterLinkedIn








3.4 Tests | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup3.1 Getting started3.2 Project structure3.3 Configuration3.4 Tests3.5 Auto watch and build3.6 Debugger in Yaml4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).3. Setup3.4 TestsVersion: v1IntroductionGodspeed provides a facility to auto-generate and run test suite using CLI.  Click on auto-generate test suite for more information on generating the test suite and run test suite for more information on running the test suite.Edit this pagePrevious3.3.4 Custom SwaggerSpec DocumentationNext3.5 Auto watch and buildForumDiscordGithubTwitterLinkedIn








3.4 Tests | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup3.1 Getting started3.2 Project structure3.3 Configuration3.4 Tests3.5 Auto watch and build3.6 Debugger in Yaml4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).3. Setup3.4 TestsVersion: v1IntroductionGodspeed provides a facility to auto-generate and run test suite using CLI.  Click on auto-generate test suite for more information on generating the test suite and run test suite for more information on running the test suite.Edit this pagePrevious3.3.4 Custom SwaggerSpec DocumentationNext3.5 Auto watch and buildForumDiscordGithubTwitterLinkedIn








3.5 Auto watch and build | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup3.1 Getting started3.2 Project structure3.3 Configuration3.4 Tests3.5 Auto watch and build3.6 Debugger in Yaml4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).3. Setup3.5 Auto watch and buildVersion: v1Auto watch and buildThe framework provides auto watch/build feature to detect the changes in you project files. This feature is only applicable when you are working inside dev container.notePlease make sure VS code 'Run On Save' plugin is installed in your dev container environment.Here is the list of files which are being watched inside the dev container.src/**/*.yaml|yml|js|jsonsrc/**/*.tssrc/**/*.prismasrc/**/*.toml *.prisma files
These files are being watched for Datastore as datasourcesDuring any datastore setup via Prisma in the dev container, you don't need to setup anything explicitily, the watch feature automatically takes care of setting up the datastores. Refer Prisma Datastore Setup for more information. *.toml files
These files are being watched for configuration files of Elasticgraph as datasource. If there is any change in *.toml file then auto watch reindexes all the elasticgraph datasources configuration inside src/datasources/eg_config/ directory.Edit this pagePrevious3.4 TestsNext3.6 Debugger in YamlForumDiscordGithubTwitterLinkedIn








3.5 Auto watch and build | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup3.1 Getting started3.2 Project structure3.3 Configuration3.4 Tests3.5 Auto watch and build3.6 Debugger in Yaml4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).3. Setup3.5 Auto watch and buildVersion: v1Auto watch and buildThe framework provides auto watch/build feature to detect the changes in you project files. This feature is only applicable when you are working inside dev container.notePlease make sure VS code 'Run On Save' plugin is installed in your dev container environment.Here is the list of files which are being watched inside the dev container.src/**/*.yaml|yml|js|jsonsrc/**/*.tssrc/**/*.prismasrc/**/*.toml *.prisma files
These files are being watched for Datastore as datasourcesDuring any datastore setup via Prisma in the dev container, you don't need to setup anything explicitily, the watch feature automatically takes care of setting up the datastores. Refer Prisma Datastore Setup for more information. *.toml files
These files are being watched for configuration files of Elasticgraph as datasource. If there is any change in *.toml file then auto watch reindexes all the elasticgraph datasources configuration inside src/datasources/eg_config/ directory.Edit this pagePrevious3.4 TestsNext3.6 Debugger in YamlForumDiscordGithubTwitterLinkedIn








3.6 Debugger in Yaml | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup3.1 Getting started3.2 Project structure3.3 Configuration3.4 Tests3.5 Auto watch and build3.6 Debugger in Yaml4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).3. Setup3.6 Debugger in YamlVersion: v1On this pageDebugger in yamlThe framework provides debugger feature in yaml workflows. steps to use debugger feature:​Start by creating a new project and running npm install to install the necessary dependencies.Utilize the "godspeed build" command to build your project efficiently.Access the JavaScript debugger and open the YAML file. You can now set breakpoints within the YAML file by placing debugger points.Navigate to the "Run and Debug" section, where you'll find the "Launch Program" option. Click on it and open the Debug Console in the terminal.With your project running, observe the Swagger UI at localhost:{port}/api-docs.Open Swagger and make an API call where you've set debugger points.As a result, the program will pause at the debugger point, allowing you to inspect and debug the code.Give it a try and explore the debugging capabilities in your project.Check out the provided video for a more in-depth understanding of the debugger feature and give it a try in your project. Edit this pagePrevious3.5 Auto watch and buildNextIntroduction to Godspeed CLIsteps to use debugger feature:ForumDiscordGithubTwitterLinkedIn








3.6 Debugger in Yaml | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup3.1 Getting started3.2 Project structure3.3 Configuration3.4 Tests3.5 Auto watch and build3.6 Debugger in Yaml4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).3. Setup3.6 Debugger in YamlVersion: v1On this pageDebugger in yamlThe framework provides debugger feature in yaml workflows. steps to use debugger feature:​Start by creating a new project and running npm install to install the necessary dependencies.Utilize the "godspeed build" command to build your project efficiently.Access the JavaScript debugger and open the YAML file. You can now set breakpoints within the YAML file by placing debugger points.Navigate to the "Run and Debug" section, where you'll find the "Launch Program" option. Click on it and open the Debug Console in the terminal.With your project running, observe the Swagger UI at localhost:{port}/api-docs.Open Swagger and make an API call where you've set debugger points.As a result, the program will pause at the debugger point, allowing you to inspect and debug the code.Give it a try and explore the debugging capabilities in your project.Check out the provided video for a more in-depth understanding of the debugger feature and give it a try in your project. Edit this pagePrevious3.5 Auto watch and buildNextIntroduction to Godspeed CLIsteps to use debugger feature:ForumDiscordGithubTwitterLinkedIn








Introduction to Godspeed CLI | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).4. CLIVersion: v1On this pageGodspeed CLIThe CLI is the primary way to interact with your Godspeed project from the command line. It provides a bunch of useful functionalities during the project development lifecycle.4.1 Functionality​Outside the dev container​Creating a new project environment with dev container setup, which includes the folder structure, all the databases, message bus, cache, etc.Open up an existing project in the dev container, add/update a container in the dev environment, based on updated settings.List the versions of gs_service.Change the version of gs_service.Inside the dev container​All Prisma commands including DB push, pull or migration.OAS 3 documentation file generation.Test suite/Postman collection generation.Running test suite.4.2 Installation​npm install -g @mindgrep/godspeedOnce Godspeed CLI is installed, the godspeed command can be called from command line. When called without arguments, it displays its help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.3 Options​--version (-v)​The --version option outputs information about your current godspeed version.$ godspeed -v                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          0.0.26--help (-h)​The --help option displays help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.4 Commands: Outside the dev container​create​The create command creates project structure for any microservice. When called without arguments, it creates project structure with examples.$ godspeed create my_service                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          projectDir:  /home/gurjot/cli-test/my_service projectTemplateDir undefinedproject createdDo you need mongodb? [y/n] [default: n] nDo you need postgresdb? [y/n] [default: n] yPlease enter name of the postgres database [default: test] Do you need kafka? [y/n] [default: n] nDo you need elastisearch? [y/n] [default: n] nPlease enter host port on which you want to run your service [default: 3000] 3100Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13Enter your version [default: latest] 1.0.13Selected version 1.0.13. . . . . . . . Options​$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <existing_project_directory>  existing project template dir  -h, --help                            display help for commandupdate​The update can be executed in the following cases:If you want to launch an existing project (i.e. copied from local/cloned from repo) instead of creating a new one, then execute godspeed update command before launching the project.If you want to reloads the containers with updated project settings. For example, if you have not selected any database during the project creation and you want to include any database in the project later on, then execute godspeed update with the required settings.If there is any change in gs_service image of standard tags (e.g. latest, stable) and you want to fetch the latest code for the same tag, then execute godspeed updatecommand. It fetches the new docker image itself.Please note that the command should be executed from inside the project root directory.noteWhenever you update your project using godspeed update and open the project in VScode dev container after update, then it is mandatory to do godspeed build inside dev container for the first time.$ godspeed update                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Do you need postgresdb? [y/n] [default: n] Do you need kafka? [y/n] [default: n] Do you need elastisearch? [y/n] [default: n] Please enter host port on which you want to run your service [default: 3000] Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.21.0.31.0.4devstableEnter your version [default: latest] Selected version latestRemoving dev_test_devcontainer_node_1                ... . . . . . . . . . .Step 1/9 : FROM adminmindgrep/gs_service:latestlatest: Pulling from adminmindgrep/gs_service824b15f81d65: Already exists325d38bcb229: Already existsd6d638bf61bf: Already exists55daac95cedf: Already exists4c701498752d: Already existsa48b0ae49665: Pulling fs layer4c393fb6deac: Pulling fs layer4f4fb700ef54: Pulling fs layer8992963a9530: Pulling fs layer4f4fb700ef54: Verifying Checksum4f4fb700ef54: Download complete4c393fb6deac: Verifying Checksum4c393fb6deac: Download complete8992963a9530: Verifying Checksum8992963a9530: Download completea48b0ae49665: Verifying Checksuma48b0ae49665: Download completea48b0ae49665: Pull complete4c393fb6deac: Pull complete4f4fb700ef54: Pull complete8992963a9530: Pull completeDigest: sha256:7195b3c921f1278153c911e6e77cbcfb385a84c435bfcb7b8272ffcf9a3278eeStatus: Downloaded newer image for adminmindgrep/gs_service:latest ---> 988917710d1aStep 2/9 : ARG USERNAME=node ---> Running in c70404bb4f3eRemoving intermediate container c70404bb4f3e ---> 47a7406b2473Step 3/9 : ARG USER_UID=1000 ---> Running in 51e68336d8d8Removing intermediate container 51e68336d8d8 ---> ce913f6898bbStep 4/9 : ARG USER_GID=$USER_UID ---> Running in 7cf1c1f2a3ecRemoving intermediate container 7cf1c1f2a3ec ---> 91f045b32e0fStep 5/9 : USER root ---> Running in f338d755a032Removing intermediate container f338d755a032 ---> fa9898eb4c23Step 6/9 : RUN sudo groupmod --gid $USER_GID $USERNAME     && usermod --uid $USER_UID --gid $USER_GID $USERNAME     && chown -R $USER_UID:$USER_GID /workspace/development ---> Running in eba3659fb919Removing intermediate container eba3659fb919 ---> 414f34560b0dStep 7/9 : USER node ---> Running in 23818c5f4882Removing intermediate container 23818c5f4882 ---> 1bd65323ae91Step 8/9 : RUN sudo npm i -g @mindgrep/godspeed ---> Running in a66cb062390d. . . . . . . . . . godspeed update dev_test is done.versions​The versions command lists all the versions available of gs_service.$ godspeed versions                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13version​The version command helps to change the version of gs_service for any microservice. Execute the command from inside the project root directory.$ godspeed version 1.0.13                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Generating prisma modulesStarting test1_devcontainer_postgres_1 ... Starting test1_devcontainer_postgres_1 ... doneCreating test1_devcontainer_node_run   ... Creating test1_devcontainer_node_run   ... doneEnvironment variables loaded from .env. . . . . . . . . .help​The help command displays help and usage for any command.$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <projectTemplateDir>  local project template dir  -h, --help                            display help for command4.5 Commands: Inside the dev container​prisma​You can run all the prisma commands in your project root directory inside the dev container. This command is useful for db migration and introspection. Read more here. $ godspeed prisma <prisma command with args>build​You can build the complete project using this command. It is the first command which you need to run whenever you open your project in VScode Dev container. Refer Open in Dev containergodspeed builddev​You can run your project using dev command.godspeed servegen-api-docs​You can get OAS 3 documentation generated automatically by executing this command in your project root directory inside the dev container.$ godspeed gen-api-docs                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529346164] INFO (GS-logger/7684 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529346190] DEBUG (GS-logger/7684 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529346289] INFO (GS-logger/7684 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Postman collection​step1: After executing $ godspeed gen-api-docs
go to docs under app and right click on api-doc.yaml file and download itstep2: In postman import the downloaded file in collection(collection->import->files->select-file.yaml-> import ) and test your apigen-test-suite​You can get test suite/postman collection generated automatically by executing this command in your project root directory inside the dev container. Now, you can import the collection in postman directly. godspeed gen-test-suite                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-test-suite> npm run gen-api-docs && mkdir -p tests && openapi2postmanv2 -s docs/api-doc.yaml -o tests/test-suite.json -p -O folderStrategy=Tags,includeAuthInfoInExample=false> proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529443249] INFO (GS-logger/8145 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529443273] DEBUG (GS-logger/8145 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529443374] INFO (GS-logger/8145 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Input file:  /workspace/development/app/docs/api-doc.yamlWriting to file:  true /workspace/development/app/tests/test-suite.json { result: true, output: [ { type: 'collection', data: [Object] } ] }Conversion successful, collection written to filegen-crud-api​You can get CRUD API generated automatically for datastores and elasticgraph datasources by executing this command in your project root directory inside the dev container.$ godspeed gen-crud-api                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > eg_test@1.0.0 gen-crud-api> npx godspeed-crud-api-generatorSelect datasource / schema to generate CRUD APIs(x) elasticgraph.yaml( ) For all( ) Canceltest​You can run the test suite generated in above command from the following two ways:Postman: Import the collection in postman and run the test suite.CLI: You can use below command to run the test suite from CLI.Please make sure your service is up and running before running the test suite. godspeed test                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 test> newman run tests/test-suite.jsonnewmanGodspeed: Sample Microservice→ Call another (sub) workflow from main workflow  POST http://localhost:3000/another_workflow?bank_id=<string> [200 OK, 630B, 2.6s]. . . . . . . . help​The help command displays help and usage for any command. Click here to know more4.6 Generating Elasticgraph model from prisma schema​generate-elasticgraph-model​You can convert the prisma schema to elasticgraph model by executing this commmand in your project root directory inside the dev container.$ godspeed generate-elasticgraph-model                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed generate-elasticgraph-model [egClientName]Enter the input path  : Enter the output path :Elasticgraph model generatednote[egClientName] (optional): Specifies the name of the Elasticgraph client to be generated. If not provided, the default name eg-model will be used.If the specified input path does not exist, the CLI will display an error message.If the specified output path does not exist, the folder will be generated with [egClientName].Edit this pagePrevious3.6 Debugger in YamlNext5. Swagger Specs4.1 FunctionalityOutside the dev containerInside the dev container4.2 Installation4.3 Options--version (-v)--help (-h)4.4 Commands: Outside the dev containercreateupdateversionsversionhelp4.5 Commands: Inside the dev containerprismabuilddevgen-api-docsPostman collectiongen-test-suitegen-crud-apitesthelp4.6 Generating Elasticgraph model from prisma schemagenerate-elasticgraph-modelForumDiscordGithubTwitterLinkedIn








Introduction to Godspeed CLI | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).4. CLIVersion: v1On this pageGodspeed CLIThe CLI is the primary way to interact with your Godspeed project from the command line. It provides a bunch of useful functionalities during the project development lifecycle.4.1 Functionality​Outside the dev container​Creating a new project environment with dev container setup, which includes the folder structure, all the databases, message bus, cache, etc.Open up an existing project in the dev container, add/update a container in the dev environment, based on updated settings.List the versions of gs_service.Change the version of gs_service.Inside the dev container​All Prisma commands including DB push, pull or migration.OAS 3 documentation file generation.Test suite/Postman collection generation.Running test suite.4.2 Installation​npm install -g @mindgrep/godspeedOnce Godspeed CLI is installed, the godspeed command can be called from command line. When called without arguments, it displays its help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.3 Options​--version (-v)​The --version option outputs information about your current godspeed version.$ godspeed -v                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          0.0.26--help (-h)​The --help option displays help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.4 Commands: Outside the dev container​create​The create command creates project structure for any microservice. When called without arguments, it creates project structure with examples.$ godspeed create my_service                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          projectDir:  /home/gurjot/cli-test/my_service projectTemplateDir undefinedproject createdDo you need mongodb? [y/n] [default: n] nDo you need postgresdb? [y/n] [default: n] yPlease enter name of the postgres database [default: test] Do you need kafka? [y/n] [default: n] nDo you need elastisearch? [y/n] [default: n] nPlease enter host port on which you want to run your service [default: 3000] 3100Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13Enter your version [default: latest] 1.0.13Selected version 1.0.13. . . . . . . . Options​$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <existing_project_directory>  existing project template dir  -h, --help                            display help for commandupdate​The update can be executed in the following cases:If you want to launch an existing project (i.e. copied from local/cloned from repo) instead of creating a new one, then execute godspeed update command before launching the project.If you want to reloads the containers with updated project settings. For example, if you have not selected any database during the project creation and you want to include any database in the project later on, then execute godspeed update with the required settings.If there is any change in gs_service image of standard tags (e.g. latest, stable) and you want to fetch the latest code for the same tag, then execute godspeed updatecommand. It fetches the new docker image itself.Please note that the command should be executed from inside the project root directory.noteWhenever you update your project using godspeed update and open the project in VScode dev container after update, then it is mandatory to do godspeed build inside dev container for the first time.$ godspeed update                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Do you need postgresdb? [y/n] [default: n] Do you need kafka? [y/n] [default: n] Do you need elastisearch? [y/n] [default: n] Please enter host port on which you want to run your service [default: 3000] Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.21.0.31.0.4devstableEnter your version [default: latest] Selected version latestRemoving dev_test_devcontainer_node_1                ... . . . . . . . . . .Step 1/9 : FROM adminmindgrep/gs_service:latestlatest: Pulling from adminmindgrep/gs_service824b15f81d65: Already exists325d38bcb229: Already existsd6d638bf61bf: Already exists55daac95cedf: Already exists4c701498752d: Already existsa48b0ae49665: Pulling fs layer4c393fb6deac: Pulling fs layer4f4fb700ef54: Pulling fs layer8992963a9530: Pulling fs layer4f4fb700ef54: Verifying Checksum4f4fb700ef54: Download complete4c393fb6deac: Verifying Checksum4c393fb6deac: Download complete8992963a9530: Verifying Checksum8992963a9530: Download completea48b0ae49665: Verifying Checksuma48b0ae49665: Download completea48b0ae49665: Pull complete4c393fb6deac: Pull complete4f4fb700ef54: Pull complete8992963a9530: Pull completeDigest: sha256:7195b3c921f1278153c911e6e77cbcfb385a84c435bfcb7b8272ffcf9a3278eeStatus: Downloaded newer image for adminmindgrep/gs_service:latest ---> 988917710d1aStep 2/9 : ARG USERNAME=node ---> Running in c70404bb4f3eRemoving intermediate container c70404bb4f3e ---> 47a7406b2473Step 3/9 : ARG USER_UID=1000 ---> Running in 51e68336d8d8Removing intermediate container 51e68336d8d8 ---> ce913f6898bbStep 4/9 : ARG USER_GID=$USER_UID ---> Running in 7cf1c1f2a3ecRemoving intermediate container 7cf1c1f2a3ec ---> 91f045b32e0fStep 5/9 : USER root ---> Running in f338d755a032Removing intermediate container f338d755a032 ---> fa9898eb4c23Step 6/9 : RUN sudo groupmod --gid $USER_GID $USERNAME     && usermod --uid $USER_UID --gid $USER_GID $USERNAME     && chown -R $USER_UID:$USER_GID /workspace/development ---> Running in eba3659fb919Removing intermediate container eba3659fb919 ---> 414f34560b0dStep 7/9 : USER node ---> Running in 23818c5f4882Removing intermediate container 23818c5f4882 ---> 1bd65323ae91Step 8/9 : RUN sudo npm i -g @mindgrep/godspeed ---> Running in a66cb062390d. . . . . . . . . . godspeed update dev_test is done.versions​The versions command lists all the versions available of gs_service.$ godspeed versions                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13version​The version command helps to change the version of gs_service for any microservice. Execute the command from inside the project root directory.$ godspeed version 1.0.13                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Generating prisma modulesStarting test1_devcontainer_postgres_1 ... Starting test1_devcontainer_postgres_1 ... doneCreating test1_devcontainer_node_run   ... Creating test1_devcontainer_node_run   ... doneEnvironment variables loaded from .env. . . . . . . . . .help​The help command displays help and usage for any command.$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <projectTemplateDir>  local project template dir  -h, --help                            display help for command4.5 Commands: Inside the dev container​prisma​You can run all the prisma commands in your project root directory inside the dev container. This command is useful for db migration and introspection. Read more here. $ godspeed prisma <prisma command with args>build​You can build the complete project using this command. It is the first command which you need to run whenever you open your project in VScode Dev container. Refer Open in Dev containergodspeed builddev​You can run your project using dev command.godspeed servegen-api-docs​You can get OAS 3 documentation generated automatically by executing this command in your project root directory inside the dev container.$ godspeed gen-api-docs                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529346164] INFO (GS-logger/7684 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529346190] DEBUG (GS-logger/7684 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529346289] INFO (GS-logger/7684 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Postman collection​step1: After executing $ godspeed gen-api-docs
go to docs under app and right click on api-doc.yaml file and download itstep2: In postman import the downloaded file in collection(collection->import->files->select-file.yaml-> import ) and test your apigen-test-suite​You can get test suite/postman collection generated automatically by executing this command in your project root directory inside the dev container. Now, you can import the collection in postman directly. godspeed gen-test-suite                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-test-suite> npm run gen-api-docs && mkdir -p tests && openapi2postmanv2 -s docs/api-doc.yaml -o tests/test-suite.json -p -O folderStrategy=Tags,includeAuthInfoInExample=false> proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529443249] INFO (GS-logger/8145 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529443273] DEBUG (GS-logger/8145 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529443374] INFO (GS-logger/8145 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Input file:  /workspace/development/app/docs/api-doc.yamlWriting to file:  true /workspace/development/app/tests/test-suite.json { result: true, output: [ { type: 'collection', data: [Object] } ] }Conversion successful, collection written to filegen-crud-api​You can get CRUD API generated automatically for datastores and elasticgraph datasources by executing this command in your project root directory inside the dev container.$ godspeed gen-crud-api                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > eg_test@1.0.0 gen-crud-api> npx godspeed-crud-api-generatorSelect datasource / schema to generate CRUD APIs(x) elasticgraph.yaml( ) For all( ) Canceltest​You can run the test suite generated in above command from the following two ways:Postman: Import the collection in postman and run the test suite.CLI: You can use below command to run the test suite from CLI.Please make sure your service is up and running before running the test suite. godspeed test                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 test> newman run tests/test-suite.jsonnewmanGodspeed: Sample Microservice→ Call another (sub) workflow from main workflow  POST http://localhost:3000/another_workflow?bank_id=<string> [200 OK, 630B, 2.6s]. . . . . . . . help​The help command displays help and usage for any command. Click here to know more4.6 Generating Elasticgraph model from prisma schema​generate-elasticgraph-model​You can convert the prisma schema to elasticgraph model by executing this commmand in your project root directory inside the dev container.$ godspeed generate-elasticgraph-model                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed generate-elasticgraph-model [egClientName]Enter the input path  : Enter the output path :Elasticgraph model generatednote[egClientName] (optional): Specifies the name of the Elasticgraph client to be generated. If not provided, the default name eg-model will be used.If the specified input path does not exist, the CLI will display an error message.If the specified output path does not exist, the folder will be generated with [egClientName].Edit this pagePrevious3.6 Debugger in YamlNext5. Swagger Specs4.1 FunctionalityOutside the dev containerInside the dev container4.2 Installation4.3 Options--version (-v)--help (-h)4.4 Commands: Outside the dev containercreateupdateversionsversionhelp4.5 Commands: Inside the dev containerprismabuilddevgen-api-docsPostman collectiongen-test-suitegen-crud-apitesthelp4.6 Generating Elasticgraph model from prisma schemagenerate-elasticgraph-modelForumDiscordGithubTwitterLinkedIn








5. Swagger Specs | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).5. Swagger SpecsVersion: v1On this pageIntroductionYou can access autogenerated Swagger API specifications at <domain name>/api-docs url.
For example, http://localhost:3000/api-docsGodspeed also provides a facility to auto-generate OAS 3 documentation using CLI. 5.1 CLI command to generate documentation​You can generate OAS3 documentation using godspeed gen-api-docs CLI command.5.2 Custom Server URL​You can add custom server URL for API documentation in static configuration
By adding the custom server url, your autogenerated documentation or swagger specs will have this url set in the Servers.server_url: https://api.example.com:8443/v1/apiFor example,
Edit this pagePreviousIntroduction to Godspeed CLINextEvents5.1 CLI command to generate documentation5.2 Custom Server URLForumDiscordGithubTwitterLinkedIn








5. Swagger Specs | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).5. Swagger SpecsVersion: v1On this pageIntroductionYou can access autogenerated Swagger API specifications at <domain name>/api-docs url.
For example, http://localhost:3000/api-docsGodspeed also provides a facility to auto-generate OAS 3 documentation using CLI. 5.1 CLI command to generate documentation​You can generate OAS3 documentation using godspeed gen-api-docs CLI command.5.2 Custom Server URL​You can add custom server URL for API documentation in static configuration
By adding the custom server url, your autogenerated documentation or swagger specs will have this url set in the Servers.server_url: https://api.example.com:8443/v1/apiFor example,
Edit this pagePreviousIntroduction to Godspeed CLINextEvents5.1 CLI command to generate documentation5.2 Custom Server URLForumDiscordGithubTwitterLinkedIn








Events | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).6. EventsVersion: v1On this pageEventsA microservice can be configured to consume events from variety of event sources, like HTTP, GraphQl, S3 etc. The event schema, for each event source, closely follows the OpenAPI specification. It includesThe name/topic/URL of the eventThe event source and other information for the source (for ex. group_id in case of Kafka events)The event handler workflowValidation (input and output)Examples of input and outputThe response of the event is flexible for the developer to change as per the requirement.6.1 Event types​Currently supportedhttp.{method_type} For example, post or getKafkaSalesforcecronWebhookS3RabbitMQ6.2 Event schema & examples for supported sources​All event declarations are stored in the src/events folder, in YAML files.6.2.1 JSON schema validation​The framework provides request and response schema validation out of the box.Request schema validation​Sample spec for request schema.body:  content:    application/json:      schema:        type: 'object'        required: []        properties:          dob:            type: 'string'            format : 'date'            pattern : "[0-9]{4}-[0-9]{2}-[0-9]{2}"If request schema validation fails, then status code 400 is returned.Response schema validation​Sample spec for response schema.responses: #Output data defined as per the OpenAPI spec  200:    description:    content:      application/json: # For ex. application/json application/xml        schema:          type: object          properties:            application_id:              type: string          additionalProperties: false          required: [application_id]        examples: # <string, ExampleObject>          example1:            summary:            description:            value:              application_id: PRM20478956N            external_value:If response schema validation fails, then status code 500 is returned.6.2.2 HTTP event​For an HTTP event, the headers, query, params and body data are captured in a standard format, and made available in the inputs object for use in the workflows. The inputs (event) object has following properties:- query: `<%inputs.query.var_name%>` # present in case of http events- params: `<%inputs.params.path_param%>` # present in case of http events- headers: `<%inputs.headers.some_header_key%>` # present in case of http events- body: `<%inputs.body.key%>` # Present for all events except for http events which don't have a body. For ex. http.get- files: `<%input.files%>` # Any files uploaded via HTTP event. Not present in other kind of eventsExample spec for HTTP event​ /v1/loan-application/:lender_loan_application_id/kyc/ckyc/initiate.http.post: #Adding .http.post after  #the endpoint exposes the endpoint as REST via the POST method (in this example)  fn: com.biz.kyc.ckyc.ckyc_initiate #The event handler written in ckyc_initiate.yml, and  # kept in src/workflows/com/biz/kyc/ckyc folder (in this example)  on_validation_error: com.jfs.handle_validation_error # The validation error handler if event's json schema validation gets failed and  # kept in src/workflows/com/jfs/ folder (in this example)  body:    required: true    content:      application/json:        schema:          type: 'object'          required: []          properties:            dob:  { type : 'string', format : 'date', pattern : "[0-9]{4}-[0-9]{2}-[0-9]{2}" }            meta:              type: 'object'  params:  - name: lender_loan_application_id    in: params # same as open api spec: one of cookie, path, query, header    required: true    allow_empty_value: false    schema:      type: string  responses: #Output data defined as per the OpenAPI spec    200:      description:      required: # default value is false      content:        application/json: # For ex. application/json application/xml          schema:            type: object            properties:              application_id:                type: string            additionalProperties: false            required: [application_id]          examples: # <string, ExampleObject>            example1:              summary:              description:              value:                application_id: PRM20478956N              external_value:          encoding:    400:      description:      required: # default value is false      content:        application/json: # For ex. application/json application/xml          schema:            type: object            properties:              lender_response_code:                type: string          examples: # <string, ExampleObject>            example1:              summary:              description:              value:                lender_response_code: E001              external_value:          encoding:Example workflow consuming an HTTP event​  summary: Simply returning query & body data of an http.post event  id: some_unique_id  tasks:    - id: step1      fn: com.gs.return      args: <%inputs.body%> # Evaluation of dynamic values happens via <% %>. The type of scripting can be coffee/js.      # Here we are returning the body of the HTTP post event.Example workflow (on_validation_error handler) handling json schema validation error​  summary: Handle json scehma validation error  id: error_handler  tasks:    - id: erorr_step1      fn: com.gs.kafka      args:        datasource: kafka1        data: # publish the event and validation error to kafka on a topic          value:            event: <% inputs.event %>            validation_error: <% inputs.validation_error %>        config:          topic: kafka_error_handle          method: publish6.2.3 Kafka event​A kafka event is specified as {topic_name}.{datasourceName}.{group_id} in the kafka event specification.The group_id represents identifier for all the consumers of the group. Only one consumer of the group will consume a message. This is useful for microservices, when a single services runs in multiple K8s pods. Each pod is part of the same group. This ensures the message is eventually consumed by any one of the pods.The message body of a kafka event is captured and represented as inputs.body for consumption in the handler workflow.Datasource for kafka​The datasources for kafka are defined in src/datasources. Refer Kafka as datasource for more information.Example spec for kafka event​kafka-consumer1.kafka1.kafka_proj: # This event will be triggered whenever  # a new message arrives on the topic_name  id: /kafkaWebhook  fn: com.jfs.publish_kafka #The event handler written in publish_kafka.yml, and  # kept in src/workflows/com/jfs folder (in this example)  on_validation_error: com.jfs.handle_validation_error # The validation error handler if event's json schema validation gets failed and  # kept in src/workflows/com/jfs folder (in this example)  body:    description: The body of the query    content:      application/json: # For ex. application/json application/xml        schema:          type: object          properties:            name:              type: string          required: [name]Example workflow consuming a kafka event​  summary: Handle kafka event  id: some_unique_id  tasks:    - id: step1      summary: Publish an event with this data      fn: com.gs.kafka      args: # similar to Axios format        datasource: kafka1        config:          method: publish          topic: publish-producer1        data:          value: <% inputs %>      # Here we are publishing an event data to another topicRefer com.gs.kafka native function to publish an event on kafka.6.2.4 Salesforce event​A salesforce event is specified as {topic_name}.salesforce.{datasource_name}topic_nameis salaesforce event topic
datasource_name is name of the salesforcedatasource filenamePrerequisite:For using salesforce, You need to enable redis datasource. You can enable rediswhile creating a new godspeed project or run godspeed update on an existing project.in config/default.yamladd a property as caching: redis. Where redis is datasource name. If your redis type datasource name is redis1.yaml, then caching: redis1 will be the correct configuration.Example of salesforcedatasource, eg: src/datasources/salaeforce.yamltype: salesforceconnection:    # Please Check  https:#jsforce.github.io/document/    #1. Username and Password Login    # you can change loginUrl to connect to sandbox or prerelease env.    # loginUrl : 'https:#test.salesforce.com'    #2. Username and Password Login (OAuth2 Resource Owner Password Credential)    oauth2:        # you can change loginUrl to connect to sandbox or prerelease env.        # loginUrl : 'https:#test.salesforce.com',        clientId : '<your Salesforce OAuth2 client ID is here>'        clientSecret : '<your Salesforce OAuth2 client secret is here>'        redirectUri : '<callback URI is here>'    #3. Session ID    serverUrl : '<your Salesforce server URL (e.g. https:#na1.salesforce.com) is here>'    sessionId : '<your Salesforce session ID is here>'    #4. Access Token    instanceUrl : '<your Salesforce server URL (e.g. https:#na1.salesforce.com) is here>'    accessToken : '<your Salesforrce OAuth2 access token is here>'    #5. Access Token with Refresh Token    oauth2:        clientId : '<your Salesforce OAuth2 client ID is here>'        clientSecret : '<your Salesforce OAuth2 client secret is here>'        redirectUri : '<your Salesforce OAuth2 redirect URI is here>'    instanceUrl : '<your Salesforce server URL (e.g. https:#na1.salesforce.com) is here>'    accessToken : '<your Salesforrce OAuth2 access token is here>'    refreshToken : '<your Salesforce OAuth2 refresh token is here>'username: <% config.salesforce_username %>password: <% config.salesforce_password %>Example of salesforce event:{topic_name}.salesforce.{datasourceName}id: /salesforcetopicfn: com.jfs.handle_title_eventson_validation_error: com.jfs.handle_validation_errorbody:  description: The body of the query  content:    application/json:      schema:        type: object        properties:          name:            type: string        required: [name]6.2.5 CRON event​A CRON event will allow you to run events at scheduled time / interval. A CRON event is specified as {schedule_expression.cron.timezone}schedule_expression You can refer crontab to generate schedule.timezone Refer this wikipedia to get the timezone format.Here is an example of a CRON event which run every minute.every_minute_cron.yaml"* * * * *.cron.Asia/Kolkata": fn: com.every_minuteand corresponding function iscom/every_minute.yaml summary: this workflow will be running every minute tasks:   - id: print     description: print every     fn: com.gs.log     args:       level: info       data: HELLO from CRON6.2.6 RabbitMQ event​A RabbitMQ event is specified as {queue_name}.{datasourceName} in the RabbitMQ event specification.The message body of a RabbitMQ event is captured and represented as inputs.body for consumption in the handler workflow.Datasource for RabbitMQ​The datasources for RabbitMQ are defined in src/datasources. Refer RabbitMQ as datasource for more information.Example spec for RabbitMQ event​queue_name.rabbitmq: # This event will be triggered whenever  # a new message arrives on the queue_name  id: /rabbitmqEvent  fn: com.jfs.publish_rabbitmq #The event handler written in publish_rabbitmq.yml, and  # kept in src/workflows/com/jfs folder (in this example)  on_validation_error: com.jfs.handle_validation_error # The validation error handler if event's json schema validation gets failed and  # kept in src/workflows/com/jfs folder (in this example)  body:    description: The body of the query    content:      application/json: # For ex. application/json application/xml        schema:          type: object          properties:            name:              type: string          required: [name]Example workflow consuming and publishing a RabbitMQ event​summary: rabbitMQ message publishingid: rabbitMQ_messagetasks:   - id: publish_rabbitmq    fn: com.gs.rabbitmq.publish    args:      datasource: rabbitMq      exchange: TestOne      config:        method: publish      data: <% inputs %>      # Here we are publishing an event data to another queue6.2.6 Soap event​Datasource for Soap​The datasources for Soap are defined in src/datasources. Refer Soap as datasource for more information.Example spec for Soap event​'/wsdltest.http.get': # event id. Will include path params. For ex. com.abc.do_kyc/{bank_id}/process/{user_id}  fn: soap  summary: add soap  description: print sum  produces:    - application/json  parameters:    - name: status      in: query      schema:        type: string  responses:    '200':      description: Returns the greeting.      schema:        type: string    '400':      description: Invalid status valueExample spec for Soap workflow​summary: Returning sumid: soap_sumtasks:    - id: step1       description: Return sum      fn: com.gs.soap      args: # similar to Axios format        datasource: soap        config:          method: Subtract        data:           intA: 1          intB: 2Edit this pagePrevious5. Swagger SpecsNextWorkflows6.1 Event types6.2 Event schema & examples for supported sources6.2.1 JSON schema validationRequest schema validationResponse schema validation6.2.2 HTTP eventExample spec for HTTP eventExample workflow consuming an HTTP eventExample workflow (on_validation_error handler) handling json schema validation error6.2.3 Kafka eventDatasource for kafkaExample spec for kafka eventExample workflow consuming a kafka event6.2.4 Salesforce event6.2.5 CRON event6.2.6 RabbitMQ eventDatasource for RabbitMQExample spec for RabbitMQ eventExample workflow consuming and publishing a RabbitMQ event6.2.6 Soap eventDatasource for SoapExample spec for Soap eventExample spec for Soap workflowForumDiscordGithubTwitterLinkedIn








Events | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).6. EventsVersion: v1On this pageEventsA microservice can be configured to consume events from variety of event sources, like HTTP, GraphQl, S3 etc. The event schema, for each event source, closely follows the OpenAPI specification. It includesThe name/topic/URL of the eventThe event source and other information for the source (for ex. group_id in case of Kafka events)The event handler workflowValidation (input and output)Examples of input and outputThe response of the event is flexible for the developer to change as per the requirement.6.1 Event types​Currently supportedhttp.{method_type} For example, post or getKafkaSalesforcecronWebhookS3RabbitMQ6.2 Event schema & examples for supported sources​All event declarations are stored in the src/events folder, in YAML files.6.2.1 JSON schema validation​The framework provides request and response schema validation out of the box.Request schema validation​Sample spec for request schema.body:  content:    application/json:      schema:        type: 'object'        required: []        properties:          dob:            type: 'string'            format : 'date'            pattern : "[0-9]{4}-[0-9]{2}-[0-9]{2}"If request schema validation fails, then status code 400 is returned.Response schema validation​Sample spec for response schema.responses: #Output data defined as per the OpenAPI spec  200:    description:    content:      application/json: # For ex. application/json application/xml        schema:          type: object          properties:            application_id:              type: string          additionalProperties: false          required: [application_id]        examples: # <string, ExampleObject>          example1:            summary:            description:            value:              application_id: PRM20478956N            external_value:If response schema validation fails, then status code 500 is returned.6.2.2 HTTP event​For an HTTP event, the headers, query, params and body data are captured in a standard format, and made available in the inputs object for use in the workflows. The inputs (event) object has following properties:- query: `<%inputs.query.var_name%>` # present in case of http events- params: `<%inputs.params.path_param%>` # present in case of http events- headers: `<%inputs.headers.some_header_key%>` # present in case of http events- body: `<%inputs.body.key%>` # Present for all events except for http events which don't have a body. For ex. http.get- files: `<%input.files%>` # Any files uploaded via HTTP event. Not present in other kind of eventsExample spec for HTTP event​ /v1/loan-application/:lender_loan_application_id/kyc/ckyc/initiate.http.post: #Adding .http.post after  #the endpoint exposes the endpoint as REST via the POST method (in this example)  fn: com.biz.kyc.ckyc.ckyc_initiate #The event handler written in ckyc_initiate.yml, and  # kept in src/workflows/com/biz/kyc/ckyc folder (in this example)  on_validation_error: com.jfs.handle_validation_error # The validation error handler if event's json schema validation gets failed and  # kept in src/workflows/com/jfs/ folder (in this example)  body:    required: true    content:      application/json:        schema:          type: 'object'          required: []          properties:            dob:  { type : 'string', format : 'date', pattern : "[0-9]{4}-[0-9]{2}-[0-9]{2}" }            meta:              type: 'object'  params:  - name: lender_loan_application_id    in: params # same as open api spec: one of cookie, path, query, header    required: true    allow_empty_value: false    schema:      type: string  responses: #Output data defined as per the OpenAPI spec    200:      description:      required: # default value is false      content:        application/json: # For ex. application/json application/xml          schema:            type: object            properties:              application_id:                type: string            additionalProperties: false            required: [application_id]          examples: # <string, ExampleObject>            example1:              summary:              description:              value:                application_id: PRM20478956N              external_value:          encoding:    400:      description:      required: # default value is false      content:        application/json: # For ex. application/json application/xml          schema:            type: object            properties:              lender_response_code:                type: string          examples: # <string, ExampleObject>            example1:              summary:              description:              value:                lender_response_code: E001              external_value:          encoding:Example workflow consuming an HTTP event​  summary: Simply returning query & body data of an http.post event  id: some_unique_id  tasks:    - id: step1      fn: com.gs.return      args: <%inputs.body%> # Evaluation of dynamic values happens via <% %>. The type of scripting can be coffee/js.      # Here we are returning the body of the HTTP post event.Example workflow (on_validation_error handler) handling json schema validation error​  summary: Handle json scehma validation error  id: error_handler  tasks:    - id: erorr_step1      fn: com.gs.kafka      args:        datasource: kafka1        data: # publish the event and validation error to kafka on a topic          value:            event: <% inputs.event %>            validation_error: <% inputs.validation_error %>        config:          topic: kafka_error_handle          method: publish6.2.3 Kafka event​A kafka event is specified as {topic_name}.{datasourceName}.{group_id} in the kafka event specification.The group_id represents identifier for all the consumers of the group. Only one consumer of the group will consume a message. This is useful for microservices, when a single services runs in multiple K8s pods. Each pod is part of the same group. This ensures the message is eventually consumed by any one of the pods.The message body of a kafka event is captured and represented as inputs.body for consumption in the handler workflow.Datasource for kafka​The datasources for kafka are defined in src/datasources. Refer Kafka as datasource for more information.Example spec for kafka event​kafka-consumer1.kafka1.kafka_proj: # This event will be triggered whenever  # a new message arrives on the topic_name  id: /kafkaWebhook  fn: com.jfs.publish_kafka #The event handler written in publish_kafka.yml, and  # kept in src/workflows/com/jfs folder (in this example)  on_validation_error: com.jfs.handle_validation_error # The validation error handler if event's json schema validation gets failed and  # kept in src/workflows/com/jfs folder (in this example)  body:    description: The body of the query    content:      application/json: # For ex. application/json application/xml        schema:          type: object          properties:            name:              type: string          required: [name]Example workflow consuming a kafka event​  summary: Handle kafka event  id: some_unique_id  tasks:    - id: step1      summary: Publish an event with this data      fn: com.gs.kafka      args: # similar to Axios format        datasource: kafka1        config:          method: publish          topic: publish-producer1        data:          value: <% inputs %>      # Here we are publishing an event data to another topicRefer com.gs.kafka native function to publish an event on kafka.6.2.4 Salesforce event​A salesforce event is specified as {topic_name}.salesforce.{datasource_name}topic_nameis salaesforce event topic
datasource_name is name of the salesforcedatasource filenamePrerequisite:For using salesforce, You need to enable redis datasource. You can enable rediswhile creating a new godspeed project or run godspeed update on an existing project.in config/default.yamladd a property as caching: redis. Where redis is datasource name. If your redis type datasource name is redis1.yaml, then caching: redis1 will be the correct configuration.Example of salesforcedatasource, eg: src/datasources/salaeforce.yamltype: salesforceconnection:    # Please Check  https:#jsforce.github.io/document/    #1. Username and Password Login    # you can change loginUrl to connect to sandbox or prerelease env.    # loginUrl : 'https:#test.salesforce.com'    #2. Username and Password Login (OAuth2 Resource Owner Password Credential)    oauth2:        # you can change loginUrl to connect to sandbox or prerelease env.        # loginUrl : 'https:#test.salesforce.com',        clientId : '<your Salesforce OAuth2 client ID is here>'        clientSecret : '<your Salesforce OAuth2 client secret is here>'        redirectUri : '<callback URI is here>'    #3. Session ID    serverUrl : '<your Salesforce server URL (e.g. https:#na1.salesforce.com) is here>'    sessionId : '<your Salesforce session ID is here>'    #4. Access Token    instanceUrl : '<your Salesforce server URL (e.g. https:#na1.salesforce.com) is here>'    accessToken : '<your Salesforrce OAuth2 access token is here>'    #5. Access Token with Refresh Token    oauth2:        clientId : '<your Salesforce OAuth2 client ID is here>'        clientSecret : '<your Salesforce OAuth2 client secret is here>'        redirectUri : '<your Salesforce OAuth2 redirect URI is here>'    instanceUrl : '<your Salesforce server URL (e.g. https:#na1.salesforce.com) is here>'    accessToken : '<your Salesforrce OAuth2 access token is here>'    refreshToken : '<your Salesforce OAuth2 refresh token is here>'username: <% config.salesforce_username %>password: <% config.salesforce_password %>Example of salesforce event:{topic_name}.salesforce.{datasourceName}id: /salesforcetopicfn: com.jfs.handle_title_eventson_validation_error: com.jfs.handle_validation_errorbody:  description: The body of the query  content:    application/json:      schema:        type: object        properties:          name:            type: string        required: [name]6.2.5 CRON event​A CRON event will allow you to run events at scheduled time / interval. A CRON event is specified as {schedule_expression.cron.timezone}schedule_expression You can refer crontab to generate schedule.timezone Refer this wikipedia to get the timezone format.Here is an example of a CRON event which run every minute.every_minute_cron.yaml"* * * * *.cron.Asia/Kolkata": fn: com.every_minuteand corresponding function iscom/every_minute.yaml summary: this workflow will be running every minute tasks:   - id: print     description: print every     fn: com.gs.log     args:       level: info       data: HELLO from CRON6.2.6 RabbitMQ event​A RabbitMQ event is specified as {queue_name}.{datasourceName} in the RabbitMQ event specification.The message body of a RabbitMQ event is captured and represented as inputs.body for consumption in the handler workflow.Datasource for RabbitMQ​The datasources for RabbitMQ are defined in src/datasources. Refer RabbitMQ as datasource for more information.Example spec for RabbitMQ event​queue_name.rabbitmq: # This event will be triggered whenever  # a new message arrives on the queue_name  id: /rabbitmqEvent  fn: com.jfs.publish_rabbitmq #The event handler written in publish_rabbitmq.yml, and  # kept in src/workflows/com/jfs folder (in this example)  on_validation_error: com.jfs.handle_validation_error # The validation error handler if event's json schema validation gets failed and  # kept in src/workflows/com/jfs folder (in this example)  body:    description: The body of the query    content:      application/json: # For ex. application/json application/xml        schema:          type: object          properties:            name:              type: string          required: [name]Example workflow consuming and publishing a RabbitMQ event​summary: rabbitMQ message publishingid: rabbitMQ_messagetasks:   - id: publish_rabbitmq    fn: com.gs.rabbitmq.publish    args:      datasource: rabbitMq      exchange: TestOne      config:        method: publish      data: <% inputs %>      # Here we are publishing an event data to another queue6.2.6 Soap event​Datasource for Soap​The datasources for Soap are defined in src/datasources. Refer Soap as datasource for more information.Example spec for Soap event​'/wsdltest.http.get': # event id. Will include path params. For ex. com.abc.do_kyc/{bank_id}/process/{user_id}  fn: soap  summary: add soap  description: print sum  produces:    - application/json  parameters:    - name: status      in: query      schema:        type: string  responses:    '200':      description: Returns the greeting.      schema:        type: string    '400':      description: Invalid status valueExample spec for Soap workflow​summary: Returning sumid: soap_sumtasks:    - id: step1       description: Return sum      fn: com.gs.soap      args: # similar to Axios format        datasource: soap        config:          method: Subtract        data:           intA: 1          intB: 2Edit this pagePrevious5. Swagger SpecsNextWorkflows6.1 Event types6.2 Event schema & examples for supported sources6.2.1 JSON schema validationRequest schema validationResponse schema validation6.2.2 HTTP eventExample spec for HTTP eventExample workflow consuming an HTTP eventExample workflow (on_validation_error handler) handling json schema validation error6.2.3 Kafka eventDatasource for kafkaExample spec for kafka eventExample workflow consuming a kafka event6.2.4 Salesforce event6.2.5 CRON event6.2.6 RabbitMQ eventDatasource for RabbitMQExample spec for RabbitMQ eventExample workflow consuming and publishing a RabbitMQ event6.2.6 Soap eventDatasource for SoapExample spec for Soap eventExample spec for Soap workflowForumDiscordGithubTwitterLinkedIn








Workflows | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).7. WorkflowsVersion: v1On this pageWorkflowsWorkflows is where the actual computation and flow orchestration happens. The framework supports a YAML based DSL to write workflows and tasks containing the business logic. These workflows can be attached to the events as their handlers, or called from within another workflow.The framework exposes CoffeeScript/JS based expressions for evaluation of dynamic variables or transformation of data from inputs of event, or outputs of previous tasks.Default language for transformations (coffee/js) can be configured in configuration7.1 The structure of workflows​A workflow has the following attributessummary - the titledescription - more detailsid - Recommended for better logging visibilityon_error - Default error handling if any tasks fails. tasks - the tasks (workflows or sub-workflows) to be run in series (sequence, or one by one). The tasks invoke other workflows written in YAML or JS/TS. Other languages support is planned.summary: Hello worlddescription: Hello world example which invokes the com.gs.return workflowid: hello_world # needed for better logging visibilityon_error:  continue: false  log_attributes:  # You can add specific log attributes when an error happens in a task.        error_message: <% outputs.transform_error.message %>        error_type: 'your custom error type'  response:    success: false    code: 500    data: "Default error"tasks: # tasks to be run in sequence (default is sequence)  - id: step1 ## id of this task. Its output will be accessible  # to subsequent tasks at `outputs.step1_switch` location. Like in step2 below.    fn: com.gs.return    args: 'Hello World!' # com.gs.return takes its return value as `args`. Hence the args key.7.2 The tasks within workflows​A workflow has one or more tasks associated with it.
A task has the following attributesid - Needed for better logging visibility. It is compulsory for a task. Importantly, this is also used to access the output of this task in subsequent tasks in the outputs.{task_id} path, as shown in example below.summary - the titledescription - more detailsfn - The handler to be run in this task. It can be one of the framework functions, control functions (like parallel, sequential, switch), developer written functions, or another workflow.You can also use scripting in dynamic evaluation of a function name as given in below example. Refer Coffee/JS scripting for more information.summary: Call an API and transform thetasks:    - id: transform_fn_step1      description: find fn name      fn: com.gs.transform      args: |        <js%          if (inputs.body.fn == 'sum') {            return 'com.jfs.sum_workflow'          } else {            return 'com.jfs.helloworld'          }        %>    - id: call_fn_step2      description: call fn returned in transform_fn_step1      fn: <% outputs.transform_fn_step1.data %>      args:        name: <% inputs.body.name %>args - Every handler fn has its own argument structure, which is kept in the args key. For example,  id: httpbin_step1  fn: com.gs.http  args:    datasource: httpbin    config:      url : /v1/loan-application/<% inputs.params.lender_loan_application_id %>/agreement/esign/initiate      method: post      headers: <% inputs.headers %>on_error - What to do if this task fails?  on_error: #You can find sample usage of this in the examples below. Just search on_error in this page.    continue: false # Whether the next task should be executed, in case this task fails. by default continue is true.    response: <%Coffee/JS expression%> | String # If specified, the output of `response` is returned as the output of this task. If not specified, the error output is the default output of the failed task.    log_attributes:  # You can add specific log attributes when an error happens in a task.      error_message: <% outputs.transform_error.message %>      error_type: 'your custom error type'     tasks: # If specified, the tasks are executed in series/sequence. The output of the last task in these tasks is the default output of the failed task.      - id: transform_error        fn: com.gs.transform        args: <% outputs.httpbin_step1 %>      - id: publish_error        fn: com.gs.kafka        args:          datasource: kafka1          data:            value: <% outputs.transform_error.message %>          config:            topic: publish-producer1The only exception to this is control functions like series, parallel, switch, which don't take the args, for the sake of more readability.retry - Retry logic helps to handle transient failures, internal server errors, and network errors with support for constant, exponential and random types. Currently applied only for com.gs.http workflow.  retry:    max_attempts: 5    type: constant    interval: PT15m  retry:    max_attempts: 5    type: exponential    interval: PT15s  retry:    max_attempts: 5    type: random    min_interval: PT5s    max_interval: PT10sThe output of task & external function​The output of every task and function can be expected in the following format within other tasksuccess: true/false. Default value is truecode:  standard HTTP response codes[1xx, 2xx, 3xx, 4xx, 5xx] Default value is 200message: any string explaining the response. Optionaldata: the actual data returned from the task/function. OptionalNoteIf a task or external JS function returns a value which is not in this JSON structure then framework assumes the output is the data itself & wraps it in this JSON structure with default values.The output of any previously executed task is accesible in following manner outputs.step1.codeExample of multiple task with arguments​summary: Workflow with switch-case and transform taskid: example_switch_functionality_iddescription: |  Run two tasks in series. Both take different arguments. First one is switch case task.  Second is transform task which consumes the output of step1 and shapes the final output of this workflow.tasks: # tasks to be run in sequence (default is sequence)  - id: step1_switch ## id of this switch task. Its output will be accessible    # to subsequent tasks at `outputs.step1_switch` location. Like in step2 below.    fn: com.gs.switch # Switch workflow takes `value` and `cases` as arguments. The cases object specifies another task for every case.    value: <%inputs.body.condition%> # Evaluation of dynamic values happens via <% %>    cases:      FIRST:        id: 1st        fn: com.gs.return        args: "'case - 1'"      SECOND:        id: 2nd        fn: com.gs.return        args: "'case - 2'"      THIRD:        id: 3rd        fn: com.gs.return        args: "'case - 3'"    defaults:      id: default      fn: com.gs.return      args: <%inputs.body.default_return_val%> #coffee/js script for dyanmic evaluation. Wrapped in <% %>. Same as that used elsewhere in workflows for dynamic calculations and variable substitutions. For ex. as used in com.gs.transform and com.gs.return  - id: step2    fn: com.gs.transform    args: | #coffee for dyanmic evaluation. Wrapped in <% %>        <coffee% {          code: 200,              data: outputs['1st']        } %>7.3 Location and fully qualified name (id) of workflows and functions​All the workflows and functions are to be kept in the src/functions folder. Their directory tree path, followed by the file name becomes the workflow's fully qualified name or id, by which it can be referenced in the events or within other workflows.The JS function shown below will be available in workflows under the F.Q.N. com.biz.custom_function. Similarly, com.biz.create_hdfc_account, com.biz.create_parallel etc. are accessible as handlers from within other workflow tasks or events. 7.4 Referencing a workflow within an event or another workflow​A workflow task references and invokes other workflows written in either YAML or JS/TS, via the fn key. In future, other languages will also be supported.
An event definition references the handler yaml workflows by their fully qualified name, via the same fn key.7.5 Use of Coffee/JS for scripting​The framework provides coffee/js forTransformations in com.gs.transform and com.gs.returnDynamic evaluation or workflow or task variables, event variables, datasource variables.You will find its code in <% %> within various examples in this page below.Define language at global level​Default language for transformations (coffee/js) is configured in static configurationDefine language at workflow level​Global configuration for language is overridden by defining specific language inside <coffee/js% %>. For example,    - id: httpbinCof_step2      fn: com.gs.transform      args: |          <coffee% if outputs.httpbinCof_step1.data.json.code == 200 then {              code: 200,              success: true,              data: outputs.httpbinCof_step1.data.json,              headers: outputs.httpbinCof_step1.data.headers          } else {              code: 500,              success: false,              message: 'error in httpbinCof_step1'          } %>    - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: upload documents      fn: com.gs.http      args:        datasource: httpbin        params:        data: |          <js% {            [inputs.body.entity_type + 'id']: inputs.body.entity_id,            _.omit(inputs.body, ['entity_type', 'entity_id'])}          %>Built-in Javascript modules​You can use build-in javascript modules in inline scripting. Only synchronous methods of build-in modules are allowed in inline scripting. For example,summary: upload s3tasks:  - id: step1    description: upload s3    fn: com.gs.aws    args:      datasource: aws_s3      params:  # fs is used directly in scripting in Body        - Bucket: 'godspeedbucket'          Key: 'file4.yml'          Body: <% fs.createReadStream(inputs.files[0].tempFilePath) %>      config:        service: S3        method: putObject7.6 Inbuilt functions​The framework provides the following inbuilt functions7.6.1 com.gs.http​Send HTTP events to other APIs in Axios compatible format.Example 1  summary: agreement esign  id: agreement_esign  tasks:    - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: agreement esign      fn: com.gs.http      params: # query params to be sent in the request        id: 123      args:        datasource: httpbin        config:          url : /v1/loan-application/<% inputs.params.lender_loan_application_id %>/agreement/esign/initiate          method: post      retry:        max_attempts: 5        type: constant        interval: PT15M      on_error:        continue: true    - id: step2      fn: com.gs.transform      args: |          <%if outputs.step1.data.success then outputs.step1.data else {              code: outputs.step1.code,              success : false,              data: {                error_data: outputs.step1.data['error'],                uuid: outputs.step1.data.uuid,                status_code_error: outputs.step1.data.status_code_error,                event: outputs.step1.data.event              }          }%>Example 2  summary: upload documents  id: upload_documents  tasks:    - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: upload documents      fn: com.gs.http      args:        datasource: httpbin        params:        data: |          <js% {            [inputs.body.entity_type + 'id']: inputs.body.entity_id,            _.omit(inputs.body, ['entity_type', 'entity_id'])}          %>        file_key: files        files: <% inputs.files %>        config:          url : /v1/documents          method: post      retry:        max_attempts: 5        type: constant        interval: PT15M      on_error:        continue: false        response: <%'Some error happened in saving' + inputs.body.entity_type%>    - id: step2      fn: com.gs.transform      args: <% delete outputs.step1.headers; outputs.step1 %>7.6.2 com.gs.kafka​Publish events on Kafka.  summary: Publishing incoming event data to a Kafka topic  id: push_to_kafka  tasks:    - id: step1      summary: Publish an event with input event's data, adding to_process = true      fn: com.gs.kafka      args: # similar to Axios format        datasource: kafka1        config:          method: publish          topic: kyc_initiate_recieved          group_id: kyc_domain        data: # Refer https://kafka.js.org/docs/producing#message-structure for information on data attributes.          value: <% inputs %> # Your message content. Evaluation of dynamic values happens via <% %>. The type of scripting is coffee.          key: # Optional - Used for partitioning.          partition: # Optional - Which partition to send the message to.          timestamp: # Optional - The timestamp of when the message was created.          headers: # Optional - Metadata to associate with your message.Refer https://kafka.js.org/docs/producing#message-structure for information on data attributes.7.6.3 com.gs.datastore​The datastore function allows CRUD access to any supported datastore in a format extending Prisma API.summary: Create and read datatasks:  - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key    description: Create entity from REST input data (POST request)    fn: com.gs.datastore    args:      datasource: mongo # Which ds to use.      data: <% inputs.body + {extra_field: its_value} %>      config:        method: <% inputs.params.entity_type %>.create  - id: step2 # the response of this will be accessible within the parent step key, under the step1 sub key    description: test again    fn: com.gs.datastore    args:      datasource: mongo # Adding this knows which ds/model we are talking about here.      config: # Similar approach as Axios        method: <% inputs.params.entity_type %>.findMany7.6.4 com.gs.elasticgraph​The elasticgraph function allows CRUD access to elasticsearch datastore.summary: egtasks:  - id: create_entity1    description: create_entity1    fn: com.gs.elasticgraph    args:      datasource: elasticgraph1      data:        index: <% inputs.params.entity_type + 's' %>        type: '_doc'        body: <% inputs.body %>      config:        method: index    on_error:      continue: false7.6.5 com.gs.transform​This function allows to transform data from one format to another using coffee/js scripting.  summary: Parallel Multiplexing create loan for hdfc api calls  tasks:    - id: parallel      fn: com.gs.parallel      tasks:        - id: 1st          fn: com.gs.return          args: |            'parallel task1'        - id: 2nd          fn: com.gs.return          args: |            'parallel task2'    - id: step2      fn: com.gs.transform      args:        code: 200        data: <% outputs.step1_switch.data %>7.6.6 com.gs.series​control flow functionExecutes the tasks in series.By default every top level workflow executes its task in series. But when invoking subworkflows if you need, you can explicitly use series workflow. Its syntax is same as parallel.  summary: Parallel Multiplexing create loan for hdfc api calls  tasks:    - id: parallel      fn: com.gs.series      tasks:        - id: 1st          fn: com.gs.return          args: |            'parallel task1'        - id: 2nd          fn: com.gs.return          args: |            'parallel task2'    - id: step2      fn: com.gs.transform      args: |        <coffee% {          code: 200,          data: outputs['1st']        } %>7.6.7 com.gs.parallel​control flow functionExecutes the child tasks in parallel.id: return4tasks:  - id: parallel    fn: com.gs.parallel    tasks:      - id: 1st        fn: com.gs.return        args: |          'parallel task1'      - id: 2nd        fn: com.gs.return        args: |          'parallel task2'  - id: output_task    fn: com.gs.return    args: <% outputs.parallel.data %>Output[  {    "code": 200,    "success": true,    "data": "parallel task1"  },  {    "code": 200,    "success": true,    "data": "parallel task2"  }]7.6.8 com.gs.switch​control flow functionThe classic switch-case flow executionThe args of switch-flow are value and cases. value takes a coffee/js expression to be evaluated during runtime. Every case has a task associated with it. The task can invoke another function or a workflow.  summary: create loan application for lender  tasks:      - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key        description: create account in the bank        fn: com.gs.switch        value: <%inputs.headers['lender']%>        cases:          httpbin:            - id: 1st              fn: com.biz.loan_application.httpbin_create_loan_application              args: <%inputs%>7.6.9 com.gs.each_sequential​control flow functionThe classic for-each flow executionThe args is list of values in value field along with associated tasks. For each value in value tasks are executed sequentially. The final output each_sequential is the array of status of the last executed task of each iteration.  summary: For each sample  description: Here we transform the response of for loop  tasks:    - id: each_sequential_step1      description: for each      fn: com.gs.each_sequential      value: [1, 2, 3, 4]      tasks:        - id: each_task1          fn: com.gs.transform          args: <% 'each_task1 ' + task_value %>    - id: each_sequential_step2      description: return the response      fn: com.gs.transform      args: <% outputs.each_sequential_step1 %>on_error handling
You can add on_error at task level as well as at each_sequential loop level.See the below example,If a task gets failed for any task_value then control goes to on_error defined at task level. On continue false, it breaks the loop else it continues the next tasks.If all the tasks are failed in loop then the control goes to on_error defined at loop level.noteon_error at loop level only gets executed when all the tasks are failed. If even one task gets successful then it won't get executed.  summary: For each sample  description: Here we transform the response of for loop  tasks:    - id: each_sequential_step1      description: for each      fn: com.gs.each_sequential      value: [1, 2, 3, 4]      tasks:        - id: each_task1          fn: com.gs.transform          args: <% 'each_task1 ' + task_value %>          on_error: # on_error at task level            continue: false            response: <%Coffee/JS expression%> | String      on_error: # on_error at loop level        continue: true        response: <%Coffee/JS expression%> | String    - id: each_sequential_step2      description: return the response      fn: com.gs.transform      args: <% outputs.each_sequential_step1 %>7.6.10 com.gs.each_parallel​The args is list of values in value field along with associated tasks. For each value in value tasks are executed in parallel. The final output each_parallel is the array of status of the last executed task of each iteration.  summary: For each sample  description: Here we transform the response of for loop  tasks:    - id: each_parallel_step1      description: for each      fn: com.gs.each_parallel      value: [1, 2, 3, 4]      tasks:        - id: each_task1          fn: com.gs.transform          args: <% 'each_task1 ' + task_value %>    - id: each_parallel_step2      description: return the response      fn: com.gs.transform      args: <% outputs.each_parallel_step1 %>on_error handling
You can add on_error at task level as well as at each_parallel loop level.See the below example,If a task gets failed for any task_value then control goes to on_error defined at task level. On continue false, it breaks the execution for the next tasks in tasks for current task_value in value list. For example, in the below workflow, if each_task1 step of task_value 1 gets failed then each_task2 will not get executed on continue false.If all the tasks are failed in loop then the control goes to on_error defined at loop level.noteon_error at loop level only gets executed when all the tasks are failed. If even one task gets successful then it won't get executed.  summary: For each sample  description: Here we transform the response of for loop  tasks:    - id: each_parallel_step1      description: for each      fn: com.gs.each_parallel      value: [1, 2, 3, 4]      tasks:        - id: each_task1          fn: com.gs.transform          args: <% 'each_task1 ' + task_value %>          on_error: # on_error at task level            continue: false            response: <%Coffee/JS expression%> | String        - id: each_task2          fn: com.gs.transform          args: <% 'each_task2 ' + task_value %>      on_error: # on_error at loop level        continue: true        response: <%Coffee/JS expression%> | String    - id: each_parallel_step2      description: return the response      fn: com.gs.transform      args: <% outputs.each_parallel_step1 %>7.6.11 com.gs.return​Return StatementIn typical scenarios, the "return" statement will terminate a workflow. However, when the "return" statement is used within a parallel function, it won't immediately exit the workflow. Instead, it will wait until all the child tasks within the parallel function have completed before exiting the workflow.Checkout return functionality in com.gs.parallelIt returns from the current function to the function caller. The function stops executing when the return statement is called.Example summary: Returning hello worldtasks:  - id: return_hello_word    fn: com.gs.return    args: 'Hello'  - id: return_with_status    fn: com.gs.transform     args: <% outputs.return_hello_word.data + inputs.query.word %>OutputHello7.6.12 com.gs.log​It logs the intermediate inputs/outputs during the workflow execution in pino logging format. The args are level and data. level takes any value from the Pino log levels and data takes a coffee/js expression to be evaluated during runtime or anything (like string, number, etc.) which you want to get logged during the workflow execution.  summary: Summing x + y  description: Here we sum two hardcoded x and y values. Feel free to try using API inputs from body or params!  tasks:    - id: sum_step1      description: add two numbers      fn: com.jfs.sum      args:        x: 1        y: 2    - id: sum_step2      description: log the output in logs      fn: com.gs.log      args:        level: info # log levels: info, debug, error, warn, fatal, silent, trace        data: <% outputs.sum_step1 %>    - id: sum_step3      description: return the response      fn: com.gs.transform      args: <% outputs.sum_step1 %>7.6.13 com.gs.dynamic_fn​It executes the workflow whose name is dynamically returned as the output of its task list. The tasks of this function should return a string output which will be the name of the workflow to be executed. Event DSL '/sum.http.get':  fn: com.jfs.sum_dynamic  summary: A workflow to sum x and y  description: This workflow sums two integers  params:    - name: x      in: query      required: true      allow_empty_value: false      schema:        type: string    - name: y      in: query      required: true      allow_empty_value: false      schema:        type: string com.jfs.sum_dynamic.yaml summary: Dynamic function to call com.jfs.sum_workflow.yamldescription: This function dynamically is taking workflow name and executing it at the runtime.tasks:  - id: sum_dynamic_step1    description: add two numbers    fn: com.gs.dynamic_fn    tasks: # the tasks should return a string value which will the name of the workflow to be executed.    # For example, in below task list, final workflow name will be `com.jfs.sum_workflow`      - id: get_wf_name_step1        fn: com.gs.transform        args: com.jfs.sum_workflow      - id: get_wf_name_step2 # this task is returning a workflow name dynamically        fn: com.gs.transform        args: <% outputs.get_wf_name_step1.data %> com.jfs.sum_workflow.yaml summary: Summing x + ydescription: Here we sum two hardcoded x and y values. Feel free to try using API inputs from body or params!tasks:  - id: sum_step1    description: add two numbers    fn: com.gs.return    args: |     <%       +inputs.query.x + +inputs.query.y     %>7.6.14 com.gs.aws​Interacts with AWS to use its various services and methods. params is the list of params to the AWS service methods. We are using AWS v3 style services.Please refer AWS S3 for AWS S3 methods.summary: upload s3tasks:  - id: step1    description: upload s3    fn: com.gs.aws    args:      datasource: aws_s3      params:        - Bucket: 'godspeedbucket'          Key: 'file4.yml'          Body: <% fs.createReadStream(inputs.files[0].tempFilePath) %>      config:        service: S3        method: putObject7.6.15 com.gs.redis​Developer can read / write to redis datasource using standard redis client functions.summary: demonstration of redis functionsid: accessing_redistasks:  - id: store_value_to_key    description: Writing user info in redis with key user    fn: com.gs.redis    args:      config:        method: set      data:        key: user        value: Adam  - id: retrieve_user_set_in_previous_task    description: Retriving user from redis    fn: com.gs.redis    args:      config:        method: get      data:        key: user7.6.16 com.gs.if, com.gs.elif, com.gs.else​control flow functionThe classic if-else flow executionThe args are condition and tasks. condition takes a coffee/js expression to be evaluated during runtime. The tasks can invoke another function or a workflow.summary: Returning hello worldtasks:  - id: if    fn: com.gs.if    condition: <% inputs.query.status == 'Hello' %>    tasks:      - id: step1        description: Return hello world        fn: com.gs.return        args: 'Hello!'  - id: elif1    description: Return hello world    fn: com.gs.elif    condition: <% inputs.query.status == 'Hell' %>    tasks:      - id: step2        description: Return hello world        fn: com.gs.return        args: 'Hell!'  - id: elif2    description: Return hello world    fn: com.gs.elif    condition: <% inputs.query.status == 'Hel' %>    tasks:      - id: step3        description: Return hello world        fn: com.gs.return        args: 'Hel!'  - id: else    description: Return hello world    fn: com.gs.else    tasks:      - id: step4        description: Return hello world        fn: com.gs.return        args: 'Hi!'7.7 Writing custom JS/TS workflows​Godspeed allows developers to write js/ts workflows.7.7.1 Executing a JS/TS Workflow within a YAML Workflow:​Developer can write functions in JS/TS and kept in src/functions folder at a path, which becomes its fully qualified name. Once it is written, the function can be invoked from within any workflow or sub-workflow, with its fully qualified name and argument structure.  summary: Custom workflow invocation  id: custom_function  tasks:    - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: custom_fn      fn: com.biz.custom_function # Can be JS/TS workflow in src/com/xyz directory with filename being custom.{js|ts}      args:        arg1: 'hello world'        arg2: 'hello again'7.7.2 Executing JS/TS workflow directly from event:​Developer can call JS/TS workflows directly from any event. Check out below event and workflow example for better understanding.Event: (src/events/mongo/create.yaml)​/mongo/category.http.post:  summary: Create a new Category  description: Create Category from database  fn: com.jfs.create # calling js workflow in src/functions/com/jfs folder.  body:    content:      application/json:        schema:          $ref: '#/definitions/mongo/Category'  responses:    content:      application/json:        schema:          type: objectJS Workflow: (src/functions/com/jfs/create.js)​In this JavaScript/TypeScript workflow, a pivotal stage is the creation of arguments encompassing the datasource, data, and configuration. These arguments are then supplied to the executeDatasource function, accompanied by the context and function     name. The workflow manages inputs, constructs appropriate arguments, and executes the 'Category.create' datasource function through executeDatasource. Ultimately, the workflow yields a GSStatus object that signals either success or failure, providing relevant details about the response or encountered error. Framework exported interfaces/functions allow developer with flexibility to write js/ts workflows while empowering them with the frameworks capabilities.CTX:​note (Every function/workflow has access to the ctx object, which is passed as an argument, and furthermore, you can access its properties by destructuring it.)what is CTX ?​CTX includes all the context specific information like tracing information, actor, environment, headers, payload, shared state (if this ctx is shared with other instruction threads, this part can be shared with them), immutable state (personal copy, personal view, for concurrency)Inputs:​Inputs Provide you all the Information you passed to event like headers, params, query params etc.  const {inputs} = ctx;  inputs.body = inputs.data.body;Outputs:​To access outputs of tasks executed before the current task, developer can destruct ctx object just like how inputs and datasources.If we have more then one task, we can access first task outputs in second task with Outputs object. we should access first task output by useing it's id.  const {outputs} = ctx;  const firstTaskOutput = outputs[firstTaskId]config:​you can access any information of config with ctx.    const { config } = ctx;    const mongoConnectionString = config.MONGO_URL;noteEvery workflow response should be in GSStatus. it has the below properties.GSStatus Properties :​    success: boolean;    code?: number;    message?: string;    data?: any;    headers?: {        [key: string]: any;    };const { GSStatus, executeDatasource } = require('#core/interfaces');module.exports = async (ctx, fn) => {  const { inputs } = ctx;  try {    inputs.body = inputs.data.body;    let args = {      datasource: 'mongo',      data: { data: inputs.body },      config: { method: 'Category.create' },    };    const responseData = await executeDatasource(      ctx,      fn['com.gs.datastore'],      args,    );    // return GSStatus response from a workflow    return new GSStatus(true, 200, undefined, responseData, undefined);  } catch (error) {    return new GSStatus(false, 500, undefined, error, undefined);  }};module.exports.id = 'main';In JS/TS workflows, we can utilize fn to access YAML workflows. In the example below, there is a workflow named create.yaml located at the path src/functions/com/biz/mongo/category/create.yaml. When the API is called, this JavaScript workflow is triggered, obtaining the response from the create.yaml workflow and returning it.const { GSStatus, executeDatasource } = require('#core/interfaces');module.exports = async (ctx, fn) => {  const { inputs, datasources } = ctx;  try {    inputs.body = inputs.data.body;    const responseData =  await fn['com.biz.mongo.category.create'](ctx)    return new GSStatus(true, 200, undefined, responseData, undefined);  } catch (error) {    return new GSStatus(false, 500, undefined, error, undefined);  }};module.exports.id = 'main';7.8 Headers defined at workflow level​Headers defined at workflow level are applicable for a single workflow only. You can find the example usage here7.9 File Upload feature​The framework provides file upload feature to upload files. Here is the sample event and workflow spec to upload any file.Event Spec/document.http.post:  fn: com.biz.documents.upload_file  id: '/sendDocuments'  summary: upload document  description: upload document on httpbin  data:    schema:      body:        required: false        content:          multipart/form-data:            schema:              type: object              properties:                fileName:                  type: string                  format: binary7.9.1 Workflow spec to upload files with same file key​  summary: upload file  id: upload_file  tasks:    - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: upload docfileuments      fn: com.gs.http      args:        datasource: httpbin        params:        file_key: files        files: <% inputs.files %>        config:          url : /v1/documents          method: post      retry:        max_attempts: 5        type: constant        interval: PT15MNoteIf file_key is same for all the files then you can use above workflow DSL. In case you have different file_keys for multiple files then you can directly use <% inputs.file_obj %> as given in the below section 6.9.27.9.2 Workflow spec to upload multiple files with different file keys​summary: upload multiple documentstasks:    - id: upload_multiple_files_step1      description: upload multiple documents      fn: com.gs.http      args:        datasource: httpbin        data: <% inputs.body %>        files: <% inputs.file_obj %>        config:          url : /anything          method: post7.9.3 Workflow spec to upload file directly from URL​summary: upload document from urltasks:  - id: upload_url_step1    description: upload document from url    fn: com.gs.http    args:      datasource: httpbin      data: <% inputs.body %>      files:        sample:          url: https://s3.ap-south-1.amazonaws.com/sample.pdf          method: get      config:        url : /anything        method: post        headers:           Content-Type: 'multipart/form-data'Edit this pagePreviousEventsNext8.1 Introduction7.1 The structure of workflows7.2 The tasks within workflowsThe output of task & external functionExample of multiple task with arguments7.3 Location and fully qualified name (id) of workflows and functions7.4 Referencing a workflow within an event or another workflow7.5 Use of Coffee/JS for scriptingDefine language at global levelDefine language at workflow levelBuilt-in Javascript modules7.6 Inbuilt functions7.6.1 com.gs.http7.6.2 com.gs.kafka7.6.3 com.gs.datastore7.6.4 com.gs.elasticgraph7.6.5 com.gs.transform7.6.6 com.gs.series7.6.7 com.gs.parallel7.6.8 com.gs.switch7.6.9 com.gs.each_sequential7.6.10 com.gs.each_parallel7.6.11 com.gs.return7.6.12 com.gs.log7.6.13 com.gs.dynamic_fn7.6.14 com.gs.aws7.6.15 com.gs.redis7.6.16 com.gs.if, com.gs.elif, com.gs.else7.7 Writing custom JS/TS workflows7.7.1 Executing a JS/TS Workflow within a YAML Workflow:7.7.2 Executing JS/TS workflow directly from event:CTX:7.8 Headers defined at workflow level7.9 File Upload feature7.9.1 Workflow spec to upload files with same file key7.9.2 Workflow spec to upload multiple files with different file keys7.9.3 Workflow spec to upload file directly from URLForumDiscordGithubTwitterLinkedIn








Workflows | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).7. WorkflowsVersion: v1On this pageWorkflowsWorkflows is where the actual computation and flow orchestration happens. The framework supports a YAML based DSL to write workflows and tasks containing the business logic. These workflows can be attached to the events as their handlers, or called from within another workflow.The framework exposes CoffeeScript/JS based expressions for evaluation of dynamic variables or transformation of data from inputs of event, or outputs of previous tasks.Default language for transformations (coffee/js) can be configured in configuration7.1 The structure of workflows​A workflow has the following attributessummary - the titledescription - more detailsid - Recommended for better logging visibilityon_error - Default error handling if any tasks fails. tasks - the tasks (workflows or sub-workflows) to be run in series (sequence, or one by one). The tasks invoke other workflows written in YAML or JS/TS. Other languages support is planned.summary: Hello worlddescription: Hello world example which invokes the com.gs.return workflowid: hello_world # needed for better logging visibilityon_error:  continue: false  log_attributes:  # You can add specific log attributes when an error happens in a task.        error_message: <% outputs.transform_error.message %>        error_type: 'your custom error type'  response:    success: false    code: 500    data: "Default error"tasks: # tasks to be run in sequence (default is sequence)  - id: step1 ## id of this task. Its output will be accessible  # to subsequent tasks at `outputs.step1_switch` location. Like in step2 below.    fn: com.gs.return    args: 'Hello World!' # com.gs.return takes its return value as `args`. Hence the args key.7.2 The tasks within workflows​A workflow has one or more tasks associated with it.
A task has the following attributesid - Needed for better logging visibility. It is compulsory for a task. Importantly, this is also used to access the output of this task in subsequent tasks in the outputs.{task_id} path, as shown in example below.summary - the titledescription - more detailsfn - The handler to be run in this task. It can be one of the framework functions, control functions (like parallel, sequential, switch), developer written functions, or another workflow.You can also use scripting in dynamic evaluation of a function name as given in below example. Refer Coffee/JS scripting for more information.summary: Call an API and transform thetasks:    - id: transform_fn_step1      description: find fn name      fn: com.gs.transform      args: |        <js%          if (inputs.body.fn == 'sum') {            return 'com.jfs.sum_workflow'          } else {            return 'com.jfs.helloworld'          }        %>    - id: call_fn_step2      description: call fn returned in transform_fn_step1      fn: <% outputs.transform_fn_step1.data %>      args:        name: <% inputs.body.name %>args - Every handler fn has its own argument structure, which is kept in the args key. For example,  id: httpbin_step1  fn: com.gs.http  args:    datasource: httpbin    config:      url : /v1/loan-application/<% inputs.params.lender_loan_application_id %>/agreement/esign/initiate      method: post      headers: <% inputs.headers %>on_error - What to do if this task fails?  on_error: #You can find sample usage of this in the examples below. Just search on_error in this page.    continue: false # Whether the next task should be executed, in case this task fails. by default continue is true.    response: <%Coffee/JS expression%> | String # If specified, the output of `response` is returned as the output of this task. If not specified, the error output is the default output of the failed task.    log_attributes:  # You can add specific log attributes when an error happens in a task.      error_message: <% outputs.transform_error.message %>      error_type: 'your custom error type'     tasks: # If specified, the tasks are executed in series/sequence. The output of the last task in these tasks is the default output of the failed task.      - id: transform_error        fn: com.gs.transform        args: <% outputs.httpbin_step1 %>      - id: publish_error        fn: com.gs.kafka        args:          datasource: kafka1          data:            value: <% outputs.transform_error.message %>          config:            topic: publish-producer1The only exception to this is control functions like series, parallel, switch, which don't take the args, for the sake of more readability.retry - Retry logic helps to handle transient failures, internal server errors, and network errors with support for constant, exponential and random types. Currently applied only for com.gs.http workflow.  retry:    max_attempts: 5    type: constant    interval: PT15m  retry:    max_attempts: 5    type: exponential    interval: PT15s  retry:    max_attempts: 5    type: random    min_interval: PT5s    max_interval: PT10sThe output of task & external function​The output of every task and function can be expected in the following format within other tasksuccess: true/false. Default value is truecode:  standard HTTP response codes[1xx, 2xx, 3xx, 4xx, 5xx] Default value is 200message: any string explaining the response. Optionaldata: the actual data returned from the task/function. OptionalNoteIf a task or external JS function returns a value which is not in this JSON structure then framework assumes the output is the data itself & wraps it in this JSON structure with default values.The output of any previously executed task is accesible in following manner outputs.step1.codeExample of multiple task with arguments​summary: Workflow with switch-case and transform taskid: example_switch_functionality_iddescription: |  Run two tasks in series. Both take different arguments. First one is switch case task.  Second is transform task which consumes the output of step1 and shapes the final output of this workflow.tasks: # tasks to be run in sequence (default is sequence)  - id: step1_switch ## id of this switch task. Its output will be accessible    # to subsequent tasks at `outputs.step1_switch` location. Like in step2 below.    fn: com.gs.switch # Switch workflow takes `value` and `cases` as arguments. The cases object specifies another task for every case.    value: <%inputs.body.condition%> # Evaluation of dynamic values happens via <% %>    cases:      FIRST:        id: 1st        fn: com.gs.return        args: "'case - 1'"      SECOND:        id: 2nd        fn: com.gs.return        args: "'case - 2'"      THIRD:        id: 3rd        fn: com.gs.return        args: "'case - 3'"    defaults:      id: default      fn: com.gs.return      args: <%inputs.body.default_return_val%> #coffee/js script for dyanmic evaluation. Wrapped in <% %>. Same as that used elsewhere in workflows for dynamic calculations and variable substitutions. For ex. as used in com.gs.transform and com.gs.return  - id: step2    fn: com.gs.transform    args: | #coffee for dyanmic evaluation. Wrapped in <% %>        <coffee% {          code: 200,              data: outputs['1st']        } %>7.3 Location and fully qualified name (id) of workflows and functions​All the workflows and functions are to be kept in the src/functions folder. Their directory tree path, followed by the file name becomes the workflow's fully qualified name or id, by which it can be referenced in the events or within other workflows.The JS function shown below will be available in workflows under the F.Q.N. com.biz.custom_function. Similarly, com.biz.create_hdfc_account, com.biz.create_parallel etc. are accessible as handlers from within other workflow tasks or events. 7.4 Referencing a workflow within an event or another workflow​A workflow task references and invokes other workflows written in either YAML or JS/TS, via the fn key. In future, other languages will also be supported.
An event definition references the handler yaml workflows by their fully qualified name, via the same fn key.7.5 Use of Coffee/JS for scripting​The framework provides coffee/js forTransformations in com.gs.transform and com.gs.returnDynamic evaluation or workflow or task variables, event variables, datasource variables.You will find its code in <% %> within various examples in this page below.Define language at global level​Default language for transformations (coffee/js) is configured in static configurationDefine language at workflow level​Global configuration for language is overridden by defining specific language inside <coffee/js% %>. For example,    - id: httpbinCof_step2      fn: com.gs.transform      args: |          <coffee% if outputs.httpbinCof_step1.data.json.code == 200 then {              code: 200,              success: true,              data: outputs.httpbinCof_step1.data.json,              headers: outputs.httpbinCof_step1.data.headers          } else {              code: 500,              success: false,              message: 'error in httpbinCof_step1'          } %>    - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: upload documents      fn: com.gs.http      args:        datasource: httpbin        params:        data: |          <js% {            [inputs.body.entity_type + 'id']: inputs.body.entity_id,            _.omit(inputs.body, ['entity_type', 'entity_id'])}          %>Built-in Javascript modules​You can use build-in javascript modules in inline scripting. Only synchronous methods of build-in modules are allowed in inline scripting. For example,summary: upload s3tasks:  - id: step1    description: upload s3    fn: com.gs.aws    args:      datasource: aws_s3      params:  # fs is used directly in scripting in Body        - Bucket: 'godspeedbucket'          Key: 'file4.yml'          Body: <% fs.createReadStream(inputs.files[0].tempFilePath) %>      config:        service: S3        method: putObject7.6 Inbuilt functions​The framework provides the following inbuilt functions7.6.1 com.gs.http​Send HTTP events to other APIs in Axios compatible format.Example 1  summary: agreement esign  id: agreement_esign  tasks:    - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: agreement esign      fn: com.gs.http      params: # query params to be sent in the request        id: 123      args:        datasource: httpbin        config:          url : /v1/loan-application/<% inputs.params.lender_loan_application_id %>/agreement/esign/initiate          method: post      retry:        max_attempts: 5        type: constant        interval: PT15M      on_error:        continue: true    - id: step2      fn: com.gs.transform      args: |          <%if outputs.step1.data.success then outputs.step1.data else {              code: outputs.step1.code,              success : false,              data: {                error_data: outputs.step1.data['error'],                uuid: outputs.step1.data.uuid,                status_code_error: outputs.step1.data.status_code_error,                event: outputs.step1.data.event              }          }%>Example 2  summary: upload documents  id: upload_documents  tasks:    - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: upload documents      fn: com.gs.http      args:        datasource: httpbin        params:        data: |          <js% {            [inputs.body.entity_type + 'id']: inputs.body.entity_id,            _.omit(inputs.body, ['entity_type', 'entity_id'])}          %>        file_key: files        files: <% inputs.files %>        config:          url : /v1/documents          method: post      retry:        max_attempts: 5        type: constant        interval: PT15M      on_error:        continue: false        response: <%'Some error happened in saving' + inputs.body.entity_type%>    - id: step2      fn: com.gs.transform      args: <% delete outputs.step1.headers; outputs.step1 %>7.6.2 com.gs.kafka​Publish events on Kafka.  summary: Publishing incoming event data to a Kafka topic  id: push_to_kafka  tasks:    - id: step1      summary: Publish an event with input event's data, adding to_process = true      fn: com.gs.kafka      args: # similar to Axios format        datasource: kafka1        config:          method: publish          topic: kyc_initiate_recieved          group_id: kyc_domain        data: # Refer https://kafka.js.org/docs/producing#message-structure for information on data attributes.          value: <% inputs %> # Your message content. Evaluation of dynamic values happens via <% %>. The type of scripting is coffee.          key: # Optional - Used for partitioning.          partition: # Optional - Which partition to send the message to.          timestamp: # Optional - The timestamp of when the message was created.          headers: # Optional - Metadata to associate with your message.Refer https://kafka.js.org/docs/producing#message-structure for information on data attributes.7.6.3 com.gs.datastore​The datastore function allows CRUD access to any supported datastore in a format extending Prisma API.summary: Create and read datatasks:  - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key    description: Create entity from REST input data (POST request)    fn: com.gs.datastore    args:      datasource: mongo # Which ds to use.      data: <% inputs.body + {extra_field: its_value} %>      config:        method: <% inputs.params.entity_type %>.create  - id: step2 # the response of this will be accessible within the parent step key, under the step1 sub key    description: test again    fn: com.gs.datastore    args:      datasource: mongo # Adding this knows which ds/model we are talking about here.      config: # Similar approach as Axios        method: <% inputs.params.entity_type %>.findMany7.6.4 com.gs.elasticgraph​The elasticgraph function allows CRUD access to elasticsearch datastore.summary: egtasks:  - id: create_entity1    description: create_entity1    fn: com.gs.elasticgraph    args:      datasource: elasticgraph1      data:        index: <% inputs.params.entity_type + 's' %>        type: '_doc'        body: <% inputs.body %>      config:        method: index    on_error:      continue: false7.6.5 com.gs.transform​This function allows to transform data from one format to another using coffee/js scripting.  summary: Parallel Multiplexing create loan for hdfc api calls  tasks:    - id: parallel      fn: com.gs.parallel      tasks:        - id: 1st          fn: com.gs.return          args: |            'parallel task1'        - id: 2nd          fn: com.gs.return          args: |            'parallel task2'    - id: step2      fn: com.gs.transform      args:        code: 200        data: <% outputs.step1_switch.data %>7.6.6 com.gs.series​control flow functionExecutes the tasks in series.By default every top level workflow executes its task in series. But when invoking subworkflows if you need, you can explicitly use series workflow. Its syntax is same as parallel.  summary: Parallel Multiplexing create loan for hdfc api calls  tasks:    - id: parallel      fn: com.gs.series      tasks:        - id: 1st          fn: com.gs.return          args: |            'parallel task1'        - id: 2nd          fn: com.gs.return          args: |            'parallel task2'    - id: step2      fn: com.gs.transform      args: |        <coffee% {          code: 200,          data: outputs['1st']        } %>7.6.7 com.gs.parallel​control flow functionExecutes the child tasks in parallel.id: return4tasks:  - id: parallel    fn: com.gs.parallel    tasks:      - id: 1st        fn: com.gs.return        args: |          'parallel task1'      - id: 2nd        fn: com.gs.return        args: |          'parallel task2'  - id: output_task    fn: com.gs.return    args: <% outputs.parallel.data %>Output[  {    "code": 200,    "success": true,    "data": "parallel task1"  },  {    "code": 200,    "success": true,    "data": "parallel task2"  }]7.6.8 com.gs.switch​control flow functionThe classic switch-case flow executionThe args of switch-flow are value and cases. value takes a coffee/js expression to be evaluated during runtime. Every case has a task associated with it. The task can invoke another function or a workflow.  summary: create loan application for lender  tasks:      - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key        description: create account in the bank        fn: com.gs.switch        value: <%inputs.headers['lender']%>        cases:          httpbin:            - id: 1st              fn: com.biz.loan_application.httpbin_create_loan_application              args: <%inputs%>7.6.9 com.gs.each_sequential​control flow functionThe classic for-each flow executionThe args is list of values in value field along with associated tasks. For each value in value tasks are executed sequentially. The final output each_sequential is the array of status of the last executed task of each iteration.  summary: For each sample  description: Here we transform the response of for loop  tasks:    - id: each_sequential_step1      description: for each      fn: com.gs.each_sequential      value: [1, 2, 3, 4]      tasks:        - id: each_task1          fn: com.gs.transform          args: <% 'each_task1 ' + task_value %>    - id: each_sequential_step2      description: return the response      fn: com.gs.transform      args: <% outputs.each_sequential_step1 %>on_error handling
You can add on_error at task level as well as at each_sequential loop level.See the below example,If a task gets failed for any task_value then control goes to on_error defined at task level. On continue false, it breaks the loop else it continues the next tasks.If all the tasks are failed in loop then the control goes to on_error defined at loop level.noteon_error at loop level only gets executed when all the tasks are failed. If even one task gets successful then it won't get executed.  summary: For each sample  description: Here we transform the response of for loop  tasks:    - id: each_sequential_step1      description: for each      fn: com.gs.each_sequential      value: [1, 2, 3, 4]      tasks:        - id: each_task1          fn: com.gs.transform          args: <% 'each_task1 ' + task_value %>          on_error: # on_error at task level            continue: false            response: <%Coffee/JS expression%> | String      on_error: # on_error at loop level        continue: true        response: <%Coffee/JS expression%> | String    - id: each_sequential_step2      description: return the response      fn: com.gs.transform      args: <% outputs.each_sequential_step1 %>7.6.10 com.gs.each_parallel​The args is list of values in value field along with associated tasks. For each value in value tasks are executed in parallel. The final output each_parallel is the array of status of the last executed task of each iteration.  summary: For each sample  description: Here we transform the response of for loop  tasks:    - id: each_parallel_step1      description: for each      fn: com.gs.each_parallel      value: [1, 2, 3, 4]      tasks:        - id: each_task1          fn: com.gs.transform          args: <% 'each_task1 ' + task_value %>    - id: each_parallel_step2      description: return the response      fn: com.gs.transform      args: <% outputs.each_parallel_step1 %>on_error handling
You can add on_error at task level as well as at each_parallel loop level.See the below example,If a task gets failed for any task_value then control goes to on_error defined at task level. On continue false, it breaks the execution for the next tasks in tasks for current task_value in value list. For example, in the below workflow, if each_task1 step of task_value 1 gets failed then each_task2 will not get executed on continue false.If all the tasks are failed in loop then the control goes to on_error defined at loop level.noteon_error at loop level only gets executed when all the tasks are failed. If even one task gets successful then it won't get executed.  summary: For each sample  description: Here we transform the response of for loop  tasks:    - id: each_parallel_step1      description: for each      fn: com.gs.each_parallel      value: [1, 2, 3, 4]      tasks:        - id: each_task1          fn: com.gs.transform          args: <% 'each_task1 ' + task_value %>          on_error: # on_error at task level            continue: false            response: <%Coffee/JS expression%> | String        - id: each_task2          fn: com.gs.transform          args: <% 'each_task2 ' + task_value %>      on_error: # on_error at loop level        continue: true        response: <%Coffee/JS expression%> | String    - id: each_parallel_step2      description: return the response      fn: com.gs.transform      args: <% outputs.each_parallel_step1 %>7.6.11 com.gs.return​Return StatementIn typical scenarios, the "return" statement will terminate a workflow. However, when the "return" statement is used within a parallel function, it won't immediately exit the workflow. Instead, it will wait until all the child tasks within the parallel function have completed before exiting the workflow.Checkout return functionality in com.gs.parallelIt returns from the current function to the function caller. The function stops executing when the return statement is called.Example summary: Returning hello worldtasks:  - id: return_hello_word    fn: com.gs.return    args: 'Hello'  - id: return_with_status    fn: com.gs.transform     args: <% outputs.return_hello_word.data + inputs.query.word %>OutputHello7.6.12 com.gs.log​It logs the intermediate inputs/outputs during the workflow execution in pino logging format. The args are level and data. level takes any value from the Pino log levels and data takes a coffee/js expression to be evaluated during runtime or anything (like string, number, etc.) which you want to get logged during the workflow execution.  summary: Summing x + y  description: Here we sum two hardcoded x and y values. Feel free to try using API inputs from body or params!  tasks:    - id: sum_step1      description: add two numbers      fn: com.jfs.sum      args:        x: 1        y: 2    - id: sum_step2      description: log the output in logs      fn: com.gs.log      args:        level: info # log levels: info, debug, error, warn, fatal, silent, trace        data: <% outputs.sum_step1 %>    - id: sum_step3      description: return the response      fn: com.gs.transform      args: <% outputs.sum_step1 %>7.6.13 com.gs.dynamic_fn​It executes the workflow whose name is dynamically returned as the output of its task list. The tasks of this function should return a string output which will be the name of the workflow to be executed. Event DSL '/sum.http.get':  fn: com.jfs.sum_dynamic  summary: A workflow to sum x and y  description: This workflow sums two integers  params:    - name: x      in: query      required: true      allow_empty_value: false      schema:        type: string    - name: y      in: query      required: true      allow_empty_value: false      schema:        type: string com.jfs.sum_dynamic.yaml summary: Dynamic function to call com.jfs.sum_workflow.yamldescription: This function dynamically is taking workflow name and executing it at the runtime.tasks:  - id: sum_dynamic_step1    description: add two numbers    fn: com.gs.dynamic_fn    tasks: # the tasks should return a string value which will the name of the workflow to be executed.    # For example, in below task list, final workflow name will be `com.jfs.sum_workflow`      - id: get_wf_name_step1        fn: com.gs.transform        args: com.jfs.sum_workflow      - id: get_wf_name_step2 # this task is returning a workflow name dynamically        fn: com.gs.transform        args: <% outputs.get_wf_name_step1.data %> com.jfs.sum_workflow.yaml summary: Summing x + ydescription: Here we sum two hardcoded x and y values. Feel free to try using API inputs from body or params!tasks:  - id: sum_step1    description: add two numbers    fn: com.gs.return    args: |     <%       +inputs.query.x + +inputs.query.y     %>7.6.14 com.gs.aws​Interacts with AWS to use its various services and methods. params is the list of params to the AWS service methods. We are using AWS v3 style services.Please refer AWS S3 for AWS S3 methods.summary: upload s3tasks:  - id: step1    description: upload s3    fn: com.gs.aws    args:      datasource: aws_s3      params:        - Bucket: 'godspeedbucket'          Key: 'file4.yml'          Body: <% fs.createReadStream(inputs.files[0].tempFilePath) %>      config:        service: S3        method: putObject7.6.15 com.gs.redis​Developer can read / write to redis datasource using standard redis client functions.summary: demonstration of redis functionsid: accessing_redistasks:  - id: store_value_to_key    description: Writing user info in redis with key user    fn: com.gs.redis    args:      config:        method: set      data:        key: user        value: Adam  - id: retrieve_user_set_in_previous_task    description: Retriving user from redis    fn: com.gs.redis    args:      config:        method: get      data:        key: user7.6.16 com.gs.if, com.gs.elif, com.gs.else​control flow functionThe classic if-else flow executionThe args are condition and tasks. condition takes a coffee/js expression to be evaluated during runtime. The tasks can invoke another function or a workflow.summary: Returning hello worldtasks:  - id: if    fn: com.gs.if    condition: <% inputs.query.status == 'Hello' %>    tasks:      - id: step1        description: Return hello world        fn: com.gs.return        args: 'Hello!'  - id: elif1    description: Return hello world    fn: com.gs.elif    condition: <% inputs.query.status == 'Hell' %>    tasks:      - id: step2        description: Return hello world        fn: com.gs.return        args: 'Hell!'  - id: elif2    description: Return hello world    fn: com.gs.elif    condition: <% inputs.query.status == 'Hel' %>    tasks:      - id: step3        description: Return hello world        fn: com.gs.return        args: 'Hel!'  - id: else    description: Return hello world    fn: com.gs.else    tasks:      - id: step4        description: Return hello world        fn: com.gs.return        args: 'Hi!'7.7 Writing custom JS/TS workflows​Godspeed allows developers to write js/ts workflows.7.7.1 Executing a JS/TS Workflow within a YAML Workflow:​Developer can write functions in JS/TS and kept in src/functions folder at a path, which becomes its fully qualified name. Once it is written, the function can be invoked from within any workflow or sub-workflow, with its fully qualified name and argument structure.  summary: Custom workflow invocation  id: custom_function  tasks:    - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: custom_fn      fn: com.biz.custom_function # Can be JS/TS workflow in src/com/xyz directory with filename being custom.{js|ts}      args:        arg1: 'hello world'        arg2: 'hello again'7.7.2 Executing JS/TS workflow directly from event:​Developer can call JS/TS workflows directly from any event. Check out below event and workflow example for better understanding.Event: (src/events/mongo/create.yaml)​/mongo/category.http.post:  summary: Create a new Category  description: Create Category from database  fn: com.jfs.create # calling js workflow in src/functions/com/jfs folder.  body:    content:      application/json:        schema:          $ref: '#/definitions/mongo/Category'  responses:    content:      application/json:        schema:          type: objectJS Workflow: (src/functions/com/jfs/create.js)​In this JavaScript/TypeScript workflow, a pivotal stage is the creation of arguments encompassing the datasource, data, and configuration. These arguments are then supplied to the executeDatasource function, accompanied by the context and function     name. The workflow manages inputs, constructs appropriate arguments, and executes the 'Category.create' datasource function through executeDatasource. Ultimately, the workflow yields a GSStatus object that signals either success or failure, providing relevant details about the response or encountered error. Framework exported interfaces/functions allow developer with flexibility to write js/ts workflows while empowering them with the frameworks capabilities.CTX:​note (Every function/workflow has access to the ctx object, which is passed as an argument, and furthermore, you can access its properties by destructuring it.)what is CTX ?​CTX includes all the context specific information like tracing information, actor, environment, headers, payload, shared state (if this ctx is shared with other instruction threads, this part can be shared with them), immutable state (personal copy, personal view, for concurrency)Inputs:​Inputs Provide you all the Information you passed to event like headers, params, query params etc.  const {inputs} = ctx;  inputs.body = inputs.data.body;Outputs:​To access outputs of tasks executed before the current task, developer can destruct ctx object just like how inputs and datasources.If we have more then one task, we can access first task outputs in second task with Outputs object. we should access first task output by useing it's id.  const {outputs} = ctx;  const firstTaskOutput = outputs[firstTaskId]config:​you can access any information of config with ctx.    const { config } = ctx;    const mongoConnectionString = config.MONGO_URL;noteEvery workflow response should be in GSStatus. it has the below properties.GSStatus Properties :​    success: boolean;    code?: number;    message?: string;    data?: any;    headers?: {        [key: string]: any;    };const { GSStatus, executeDatasource } = require('#core/interfaces');module.exports = async (ctx, fn) => {  const { inputs } = ctx;  try {    inputs.body = inputs.data.body;    let args = {      datasource: 'mongo',      data: { data: inputs.body },      config: { method: 'Category.create' },    };    const responseData = await executeDatasource(      ctx,      fn['com.gs.datastore'],      args,    );    // return GSStatus response from a workflow    return new GSStatus(true, 200, undefined, responseData, undefined);  } catch (error) {    return new GSStatus(false, 500, undefined, error, undefined);  }};module.exports.id = 'main';In JS/TS workflows, we can utilize fn to access YAML workflows. In the example below, there is a workflow named create.yaml located at the path src/functions/com/biz/mongo/category/create.yaml. When the API is called, this JavaScript workflow is triggered, obtaining the response from the create.yaml workflow and returning it.const { GSStatus, executeDatasource } = require('#core/interfaces');module.exports = async (ctx, fn) => {  const { inputs, datasources } = ctx;  try {    inputs.body = inputs.data.body;    const responseData =  await fn['com.biz.mongo.category.create'](ctx)    return new GSStatus(true, 200, undefined, responseData, undefined);  } catch (error) {    return new GSStatus(false, 500, undefined, error, undefined);  }};module.exports.id = 'main';7.8 Headers defined at workflow level​Headers defined at workflow level are applicable for a single workflow only. You can find the example usage here7.9 File Upload feature​The framework provides file upload feature to upload files. Here is the sample event and workflow spec to upload any file.Event Spec/document.http.post:  fn: com.biz.documents.upload_file  id: '/sendDocuments'  summary: upload document  description: upload document on httpbin  data:    schema:      body:        required: false        content:          multipart/form-data:            schema:              type: object              properties:                fileName:                  type: string                  format: binary7.9.1 Workflow spec to upload files with same file key​  summary: upload file  id: upload_file  tasks:    - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: upload docfileuments      fn: com.gs.http      args:        datasource: httpbin        params:        file_key: files        files: <% inputs.files %>        config:          url : /v1/documents          method: post      retry:        max_attempts: 5        type: constant        interval: PT15MNoteIf file_key is same for all the files then you can use above workflow DSL. In case you have different file_keys for multiple files then you can directly use <% inputs.file_obj %> as given in the below section 6.9.27.9.2 Workflow spec to upload multiple files with different file keys​summary: upload multiple documentstasks:    - id: upload_multiple_files_step1      description: upload multiple documents      fn: com.gs.http      args:        datasource: httpbin        data: <% inputs.body %>        files: <% inputs.file_obj %>        config:          url : /anything          method: post7.9.3 Workflow spec to upload file directly from URL​summary: upload document from urltasks:  - id: upload_url_step1    description: upload document from url    fn: com.gs.http    args:      datasource: httpbin      data: <% inputs.body %>      files:        sample:          url: https://s3.ap-south-1.amazonaws.com/sample.pdf          method: get      config:        url : /anything        method: post        headers:           Content-Type: 'multipart/form-data'Edit this pagePreviousEventsNext8.1 Introduction7.1 The structure of workflows7.2 The tasks within workflowsThe output of task & external functionExample of multiple task with arguments7.3 Location and fully qualified name (id) of workflows and functions7.4 Referencing a workflow within an event or another workflow7.5 Use of Coffee/JS for scriptingDefine language at global levelDefine language at workflow levelBuilt-in Javascript modules7.6 Inbuilt functions7.6.1 com.gs.http7.6.2 com.gs.kafka7.6.3 com.gs.datastore7.6.4 com.gs.elasticgraph7.6.5 com.gs.transform7.6.6 com.gs.series7.6.7 com.gs.parallel7.6.8 com.gs.switch7.6.9 com.gs.each_sequential7.6.10 com.gs.each_parallel7.6.11 com.gs.return7.6.12 com.gs.log7.6.13 com.gs.dynamic_fn7.6.14 com.gs.aws7.6.15 com.gs.redis7.6.16 com.gs.if, com.gs.elif, com.gs.else7.7 Writing custom JS/TS workflows7.7.1 Executing a JS/TS Workflow within a YAML Workflow:7.7.2 Executing JS/TS workflow directly from event:CTX:7.8 Headers defined at workflow level7.9 File Upload feature7.9.1 Workflow spec to upload files with same file key7.9.2 Workflow spec to upload multiple files with different file keys7.9.3 Workflow spec to upload file directly from URLForumDiscordGithubTwitterLinkedIn








8.1 Introduction | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 Elasticgraph8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.1 IntroductionVersion: v1On this pageDatasourcesAny kind of entity which provides read and write mechanism for data is considered a datasource. For example, an API, a SQL or NoSQL datastore which includes RDBMS, key value stores, document stores etc. The settings for each datasource lies in src/datasources directory.8.1.1 Datasource types​Currently supported typesAPIDatastores (SQL/NoSQL)PostgresMysqlMongodbKafkaElasticsearchUpcomingS3File system8.1.2 Connecting to a database and accessing them  using AdminUI​If a developer wants to connect to MongoDB or any other database using admin panel then he can read the necessary values in the docker compose such as host, port, username, password, database.Below are the few examples of URL format patterns for some databases.MongoDBConnection URL format: mongodb://username:password@host:port/databaseExample connection URL: mongodb://admin:mindgrep@localhost:27017/testMySQLConnection URL format: mysql://username:password@host:port/databaseExample connection URL: mysql://root:root@localhost:3306/testPostgreSQLConnection URL format: postgresql://username:password@host:port/databaseExample connection URL: postgresql://postgres:postgres@localhost:5432/testEdit this pagePreviousWorkflowsNext8.2 Before and after hooks to datasource calls8.1.1 Datasource types8.1.2 Connecting to a database and accessing them  using AdminUIForumDiscordGithubTwitterLinkedIn








8.1 Introduction | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 Elasticgraph8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.1 IntroductionVersion: v1On this pageDatasourcesAny kind of entity which provides read and write mechanism for data is considered a datasource. For example, an API, a SQL or NoSQL datastore which includes RDBMS, key value stores, document stores etc. The settings for each datasource lies in src/datasources directory.8.1.1 Datasource types​Currently supported typesAPIDatastores (SQL/NoSQL)PostgresMysqlMongodbKafkaElasticsearchUpcomingS3File system8.1.2 Connecting to a database and accessing them  using AdminUI​If a developer wants to connect to MongoDB or any other database using admin panel then he can read the necessary values in the docker compose such as host, port, username, password, database.Below are the few examples of URL format patterns for some databases.MongoDBConnection URL format: mongodb://username:password@host:port/databaseExample connection URL: mongodb://admin:mindgrep@localhost:27017/testMySQLConnection URL format: mysql://username:password@host:port/databaseExample connection URL: mysql://root:root@localhost:3306/testPostgreSQLConnection URL format: postgresql://username:password@host:port/databaseExample connection URL: postgresql://postgres:postgres@localhost:5432/testEdit this pagePreviousWorkflowsNext8.2 Before and after hooks to datasource calls8.1.1 Datasource types8.1.2 Connecting to a database and accessing them  using AdminUIForumDiscordGithubTwitterLinkedIn








8.2 Before and after hooks to datasource calls | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 Elasticgraph8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.2 Before and after hooks to datasource callsVersion: v1On this page8.2 Before and after hooks to datasource calls8.2.1 Adding before and after hooks​You can execute custom workflows before_method_hook and after_method_hook any datasource call. this applies to all kinds of datasources you integrate in a godspeed project, whether of type api,redis, kafka etcbefore_method_hook this hook will trigger a workflow before executing the any method of the datasource in a task.src/datasource/test_datasource.yamltype: apischema:base_url: <% config.httpbin.base_url %>    before_method_hook: com.jfs.audit_log_workflowafter_method_hook this hook will trigger a workflow after executing the method of the datasource in a task.src/datasource/test_datasource.yamltype: apischema:base_url: <% config.httpbin.base_url %>    after_method_hook: com.jfs.audit_log_workflowTo access datasource context in the workflows of the before_method_hook and after_method_hook use <% config.context %> script.for eg.summary: 'hook workflow for testing'id: logging_input_outputtasks:  - id: audit_log   fn: com.gs.transform   args:     request: <% config.context %>     response: <% outputs %>context of datasource type: api{  "type": "api",  "base_url": "https://dummyjson.com",  "gsName": "testdatasource",  "url": "/products/1",  "method": "post",  "body": {    "test": "key"  }}```Edit this pagePrevious8.1 IntroductionNext8.3 API datasource8.2.1 Adding before and after hooksForumDiscordGithubTwitterLinkedIn








8.2 Before and after hooks to datasource calls | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 Elasticgraph8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.2 Before and after hooks to datasource callsVersion: v1On this page8.2 Before and after hooks to datasource calls8.2.1 Adding before and after hooks​You can execute custom workflows before_method_hook and after_method_hook any datasource call. this applies to all kinds of datasources you integrate in a godspeed project, whether of type api,redis, kafka etcbefore_method_hook this hook will trigger a workflow before executing the any method of the datasource in a task.src/datasource/test_datasource.yamltype: apischema:base_url: <% config.httpbin.base_url %>    before_method_hook: com.jfs.audit_log_workflowafter_method_hook this hook will trigger a workflow after executing the method of the datasource in a task.src/datasource/test_datasource.yamltype: apischema:base_url: <% config.httpbin.base_url %>    after_method_hook: com.jfs.audit_log_workflowTo access datasource context in the workflows of the before_method_hook and after_method_hook use <% config.context %> script.for eg.summary: 'hook workflow for testing'id: logging_input_outputtasks:  - id: audit_log   fn: com.gs.transform   args:     request: <% config.context %>     response: <% outputs %>context of datasource type: api{  "type": "api",  "base_url": "https://dummyjson.com",  "gsName": "testdatasource",  "url": "/products/1",  "method": "post",  "body": {    "test": "key"  }}```Edit this pagePrevious8.1 IntroductionNext8.3 API datasource8.2.1 Adding before and after hooksForumDiscordGithubTwitterLinkedIn








8.3 API datasource | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 Elasticgraph8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.3 API datasourceVersion: v1On this pageAPI datasourceThe API datasource acts as a wrapper around third party APIs. It helps interact with third party APIs or own microservices. It takes OpenAPI schema as its setting, and the datasource can be used in com.gs.http calls out of the box. Following functionality is provided by the framework based on the schema of the datasourceAuthentication and authorization as per the specValidation of the input to the http method (must be compliant to the API spec)Validation of the response from the API (must be compliant to the API spec)8.3.1 API datasource schema defined externally​If the OpenAPI spec of the API to consume/connect with is available at a URL, then one can simply refer the url here itself.type: apischema: https://raw.githubusercontent.com/Kong/swagger-ui-kong-theme/main/demo/public/specs/httpbin.yaml8.3.2 API datasource schema defined within the yaml file​If there is no OpenAPI spec available for an API, then developer needs to provide details of the API schema in the .yaml file for that datasource.type: apischema:base_url: <% config.httpbin.base_url %>security:  - ApiKey: sample-app  - ApiToken: <% config.httpbin.api_token %>securitySchemes:  ApiKey:    type: apiKey    in: header    name: x-api-key  ApiToken:    type: apiKey    in: header    name: Authorization#    before_method_hook: com.jfs.before_method_hook_workflow#after_method_hook: com.jfs.after_method_hook_workflow 8.3.3 Headers defined at datasource level​Headers defined at datasource level are applicable for all the workflows, which are using this datasource. For example, in below datasource, headers 'name' and 'title' are sent in each workflow which is using this datasource.type: apibase_url: <% config.httpbin.base_url %>headers:  name: godspeed  title: <% inputs.headers['title'] %>8.3.4 Headers defined at task level​Headers defined at task level are applicable for a single task only. You can find the example usage here8.3.5 Datasource extensibility with before and after method hooks​before_method_hook and after_method_hook defined at datasource level are applicable for all the workflows, which are using this datasource.You can leverage before_method_hook and after_method_hook method hooks to trigger another workflow as per your use case.for ex. You want to make an audit log for a third party api. before_method_hook this workflow will be triggered before executing the workflow where the datasource is defined.  src/datasource/test_datasource.yamltype: apischema:base_url: <% config.httpbin.base_url %>    before_method_hook: com.jfs.audit_log_workflowafter_method_hook this workflow will be triggered after executing the workflow where the datasource is defined.
src/datasource/test_datasource.yamltype: apischema:base_url: <% config.httpbin.base_url %>    after_method_hook: com.jfs.audit_log_workflow8.3.6 Example usage​You can find the example usage hereEdit this pagePrevious8.2 Before and after hooks to datasource callsNext8.4 Datastore as datasource8.3.1 API datasource schema defined externally8.3.2 API datasource schema defined within the yaml file8.3.3 Headers defined at datasource level8.3.4 Headers defined at task level8.3.5 Datasource extensibility with before and after method hooks8.3.6 Example usageForumDiscordGithubTwitterLinkedIn








8.3 API datasource | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 Elasticgraph8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.3 API datasourceVersion: v1On this pageAPI datasourceThe API datasource acts as a wrapper around third party APIs. It helps interact with third party APIs or own microservices. It takes OpenAPI schema as its setting, and the datasource can be used in com.gs.http calls out of the box. Following functionality is provided by the framework based on the schema of the datasourceAuthentication and authorization as per the specValidation of the input to the http method (must be compliant to the API spec)Validation of the response from the API (must be compliant to the API spec)8.3.1 API datasource schema defined externally​If the OpenAPI spec of the API to consume/connect with is available at a URL, then one can simply refer the url here itself.type: apischema: https://raw.githubusercontent.com/Kong/swagger-ui-kong-theme/main/demo/public/specs/httpbin.yaml8.3.2 API datasource schema defined within the yaml file​If there is no OpenAPI spec available for an API, then developer needs to provide details of the API schema in the .yaml file for that datasource.type: apischema:base_url: <% config.httpbin.base_url %>security:  - ApiKey: sample-app  - ApiToken: <% config.httpbin.api_token %>securitySchemes:  ApiKey:    type: apiKey    in: header    name: x-api-key  ApiToken:    type: apiKey    in: header    name: Authorization#    before_method_hook: com.jfs.before_method_hook_workflow#after_method_hook: com.jfs.after_method_hook_workflow 8.3.3 Headers defined at datasource level​Headers defined at datasource level are applicable for all the workflows, which are using this datasource. For example, in below datasource, headers 'name' and 'title' are sent in each workflow which is using this datasource.type: apibase_url: <% config.httpbin.base_url %>headers:  name: godspeed  title: <% inputs.headers['title'] %>8.3.4 Headers defined at task level​Headers defined at task level are applicable for a single task only. You can find the example usage here8.3.5 Datasource extensibility with before and after method hooks​before_method_hook and after_method_hook defined at datasource level are applicable for all the workflows, which are using this datasource.You can leverage before_method_hook and after_method_hook method hooks to trigger another workflow as per your use case.for ex. You want to make an audit log for a third party api. before_method_hook this workflow will be triggered before executing the workflow where the datasource is defined.  src/datasource/test_datasource.yamltype: apischema:base_url: <% config.httpbin.base_url %>    before_method_hook: com.jfs.audit_log_workflowafter_method_hook this workflow will be triggered after executing the workflow where the datasource is defined.
src/datasource/test_datasource.yamltype: apischema:base_url: <% config.httpbin.base_url %>    after_method_hook: com.jfs.audit_log_workflow8.3.6 Example usage​You can find the example usage hereEdit this pagePrevious8.2 Before and after hooks to datasource callsNext8.4 Datastore as datasource8.3.1 API datasource schema defined externally8.3.2 API datasource schema defined within the yaml file8.3.3 Headers defined at datasource level8.3.4 Headers defined at task level8.3.5 Datasource extensibility with before and after method hooks8.3.6 Example usageForumDiscordGithubTwitterLinkedIn








8.4 Datastore as datasource | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 Elasticgraph8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.4 Datastore as datasourceVersion: v1On this pageIntroductionThe framework takes the approach of schema driven development.
It supports multiple kinds of SQL and NoSQL datastores. The developer only needs to specify or generate the schema for a datastore, with authorization policies. The CRUD events and workflows are automatically generated from the schema itself. Shall the developer need to use these within other workflows, they can do that as well.Currently supported datastores Postgres (via Prisma)Mysql (via Prisma)Mongodb (via Prisma)Elasticsearch (via Elasticgraph, our inhouse implementation providing bunch of exciting features over Elasticsearch, including relationship management and joins.)The integration supportsModel declaration (For both relational and non-relational stores)Schema generation from existing databaseUniversal, autogenerated CRUD API.Validation of the CRUD requestsAuthorization mechanism at the entity, column, row and ownership levelsAutomatic caching based on configuration.8.4.1 Schema specification​The framework extends Prisma specification for specifying the schema of any datastore. This can be generated from an existing database or manually created by the developer. The schema is present as {datastore_name}.prisma file in the src/datasources folder. Sample Schema generator client {  provider = "prisma-client-js"  output   = "./generated-clients/mongo"  previewFeatures = ["metrics"]}datasource db {  provider = "mongodb"  url      = env("MONGO_TEST_URL")}model User1 {  id        String      @id @default(auto()) @map("_id") @db.ObjectId  createdAt DateTime @default(now())  email     String   @unique  name      String?}8.4.2 CLI Commands​Any Prisma CLI command can be executed from godspeed CLI using godspeed prisma <command>. For example,$ godspeed prisma db pull --schema=./src/datasources/mongo_pull.prisma                       _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Prisma schema loaded from src/datasources/mongo_pull.prismaEnvironment variables loaded from .envDatasource "db"✔ Introspected 6 models and wrote them into src/datasources/mongo_pull.prisma in 81ms      *** WARNING ***Could not determine the types for the following fields.- Model "Post", field: "slug"- Model "Profile", field: "userId"- Model "User", field: "email"Run prisma generate to generate Prisma Client.notePlease make sure that godspeed prisma <command> is executed inside from devcontainer/project root directory.8.4.3 Prisma Datastore Setup​The framework has inbuilt feature of setting up datastore automatically whenever a new {datastore_name}.prisma file is created in the src/datasources folder. In case, you are getting any error in the datastore setup, then you can refer to below section for manual setup: During the project setup, if you have not specified the type of datastore you just added, then you will have to execute godspeed update in project root directory, outside the dev container. This will deploy the container for this datastore in the dev container environment.Model setup​Prisma model setup is done using prisma generate and db push commands.Step 1: godspeed prisma generate​$ godspeed prisma generate --schema=./src/datasources/mongo2.prisma                       _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Environment variables loaded from .envPrisma schema loaded from src/datasources/mongo2.prisma✔ Generated Prisma Client (3.15.2 | library) to ./src/datasources/generated-clients/mongo2 in 111msYou can now start using Prisma Client in your code. Reference: https://pris.ly/d/clientimport { PrismaClient } from './src/datasources/generated-clients/mongo2'const prisma = new PrismaClient()Step 2: godspeed prisma db push​$ godspeed prisma db push --schema=./src/datasources/mongo.prisma                       _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Environment variables loaded from .envPrisma schema loaded from src/datasources/mongo.prismaDatasource "db"The database is already in sync with the Prisma schema.✔ Generated Prisma Client (3.15.2 | library) to ./src/datasources/generated-clients/mongo in 149ms8.4.4 Auto generating CRUD APIs from data store models​Developer can generate CRUD APIs for all the models in a datastore. Events and Workflows will be auto generated for Create, Read, Update and Delete operations for each model in respective datastore. Auto-generated events and workflows will be stored in /events/{datasourceName}/{modelName} and /functions/com/gs/{datasourceName}/{modelName} folders respectively.godspeed gen-crud-api8.4.5 Sample datastore CRUD task​Please find an example here8.4.6 Prisma encryption of fields​You can apply encryption on String type fields in Prisma. Be default, the encryption algorithm used is AES-GCM with 256 bit keys.  8.4.6.1 Specification​In your prisma schema, add /// @encrypted to the fields you want to encrypts.
For example, email field in below schema:generator client {  provider = "prisma-client-js"  output   = "./generated-clients/mongo"  previewFeatures = ["metrics"]}datasource db {  provider = "mongodb"  url      = env("MONGO_TEST_URL")}model User1 {  id        String      @id @default(auto()) @map("_id") @db.ObjectId  createdAt DateTime @default(now())  email     String   @unique /// @encrypted  name      String?}8.4.6.2 Configuration​You can specify prisma_secret in environment configuration
For example, this is the sample configuration, set PRISMA_SECRET as env variable:prisma_secret: PRISMA_SECRET # secret used to generate hash of prisma fieldsEdit this pagePrevious8.3 API datasourceNext8.5 Kafka as datasource8.4.1 Schema specification8.4.2 CLI Commands8.4.3 Prisma Datastore SetupModel setup8.4.4 Auto generating CRUD APIs from data store models8.4.5 Sample datastore CRUD task8.4.6 Prisma encryption of fields8.4.6.1 Specification8.4.6.2 ConfigurationForumDiscordGithubTwitterLinkedIn








8.4 Datastore as datasource | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 Elasticgraph8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.4 Datastore as datasourceVersion: v1On this pageIntroductionThe framework takes the approach of schema driven development.
It supports multiple kinds of SQL and NoSQL datastores. The developer only needs to specify or generate the schema for a datastore, with authorization policies. The CRUD events and workflows are automatically generated from the schema itself. Shall the developer need to use these within other workflows, they can do that as well.Currently supported datastores Postgres (via Prisma)Mysql (via Prisma)Mongodb (via Prisma)Elasticsearch (via Elasticgraph, our inhouse implementation providing bunch of exciting features over Elasticsearch, including relationship management and joins.)The integration supportsModel declaration (For both relational and non-relational stores)Schema generation from existing databaseUniversal, autogenerated CRUD API.Validation of the CRUD requestsAuthorization mechanism at the entity, column, row and ownership levelsAutomatic caching based on configuration.8.4.1 Schema specification​The framework extends Prisma specification for specifying the schema of any datastore. This can be generated from an existing database or manually created by the developer. The schema is present as {datastore_name}.prisma file in the src/datasources folder. Sample Schema generator client {  provider = "prisma-client-js"  output   = "./generated-clients/mongo"  previewFeatures = ["metrics"]}datasource db {  provider = "mongodb"  url      = env("MONGO_TEST_URL")}model User1 {  id        String      @id @default(auto()) @map("_id") @db.ObjectId  createdAt DateTime @default(now())  email     String   @unique  name      String?}8.4.2 CLI Commands​Any Prisma CLI command can be executed from godspeed CLI using godspeed prisma <command>. For example,$ godspeed prisma db pull --schema=./src/datasources/mongo_pull.prisma                       _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Prisma schema loaded from src/datasources/mongo_pull.prismaEnvironment variables loaded from .envDatasource "db"✔ Introspected 6 models and wrote them into src/datasources/mongo_pull.prisma in 81ms      *** WARNING ***Could not determine the types for the following fields.- Model "Post", field: "slug"- Model "Profile", field: "userId"- Model "User", field: "email"Run prisma generate to generate Prisma Client.notePlease make sure that godspeed prisma <command> is executed inside from devcontainer/project root directory.8.4.3 Prisma Datastore Setup​The framework has inbuilt feature of setting up datastore automatically whenever a new {datastore_name}.prisma file is created in the src/datasources folder. In case, you are getting any error in the datastore setup, then you can refer to below section for manual setup: During the project setup, if you have not specified the type of datastore you just added, then you will have to execute godspeed update in project root directory, outside the dev container. This will deploy the container for this datastore in the dev container environment.Model setup​Prisma model setup is done using prisma generate and db push commands.Step 1: godspeed prisma generate​$ godspeed prisma generate --schema=./src/datasources/mongo2.prisma                       _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Environment variables loaded from .envPrisma schema loaded from src/datasources/mongo2.prisma✔ Generated Prisma Client (3.15.2 | library) to ./src/datasources/generated-clients/mongo2 in 111msYou can now start using Prisma Client in your code. Reference: https://pris.ly/d/clientimport { PrismaClient } from './src/datasources/generated-clients/mongo2'const prisma = new PrismaClient()Step 2: godspeed prisma db push​$ godspeed prisma db push --schema=./src/datasources/mongo.prisma                       _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Environment variables loaded from .envPrisma schema loaded from src/datasources/mongo.prismaDatasource "db"The database is already in sync with the Prisma schema.✔ Generated Prisma Client (3.15.2 | library) to ./src/datasources/generated-clients/mongo in 149ms8.4.4 Auto generating CRUD APIs from data store models​Developer can generate CRUD APIs for all the models in a datastore. Events and Workflows will be auto generated for Create, Read, Update and Delete operations for each model in respective datastore. Auto-generated events and workflows will be stored in /events/{datasourceName}/{modelName} and /functions/com/gs/{datasourceName}/{modelName} folders respectively.godspeed gen-crud-api8.4.5 Sample datastore CRUD task​Please find an example here8.4.6 Prisma encryption of fields​You can apply encryption on String type fields in Prisma. Be default, the encryption algorithm used is AES-GCM with 256 bit keys.  8.4.6.1 Specification​In your prisma schema, add /// @encrypted to the fields you want to encrypts.
For example, email field in below schema:generator client {  provider = "prisma-client-js"  output   = "./generated-clients/mongo"  previewFeatures = ["metrics"]}datasource db {  provider = "mongodb"  url      = env("MONGO_TEST_URL")}model User1 {  id        String      @id @default(auto()) @map("_id") @db.ObjectId  createdAt DateTime @default(now())  email     String   @unique /// @encrypted  name      String?}8.4.6.2 Configuration​You can specify prisma_secret in environment configuration
For example, this is the sample configuration, set PRISMA_SECRET as env variable:prisma_secret: PRISMA_SECRET # secret used to generate hash of prisma fieldsEdit this pagePrevious8.3 API datasourceNext8.5 Kafka as datasource8.4.1 Schema specification8.4.2 CLI Commands8.4.3 Prisma Datastore SetupModel setup8.4.4 Auto generating CRUD APIs from data store models8.4.5 Sample datastore CRUD task8.4.6 Prisma encryption of fields8.4.6.1 Specification8.4.6.2 ConfigurationForumDiscordGithubTwitterLinkedIn








8.5 Kafka as datasource | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 Elasticgraph8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.5 Kafka as datasourceVersion: v1On this pageIntroductionThe framework supports kafka as a datasource. It helps in interacting with kafka, to send/receive events on a kafka message bus. 8.5.1 Example spec​The datasources for kafka are defined in src/datasources. Here, two kafka clients kafka1.yaml and kafka2.yaml are defined in datasources..├── config└── src    ├── datasources    │   └── httpbin.yaml    │   ├── kafka1.yaml    │   └── kafka2.yaml    ├── events    ├── functions    └── mappingsSample configuration in kafka1.yamltype: kafkaclient_id: my_servicebrokers: [ "kafka:9092" ]Edit this pagePrevious8.4 Datastore as datasourceNextElasticgraph as datasource8.5.1 Example specForumDiscordGithubTwitterLinkedIn








8.5 Kafka as datasource | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 Elasticgraph8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.5 Kafka as datasourceVersion: v1On this pageIntroductionThe framework supports kafka as a datasource. It helps in interacting with kafka, to send/receive events on a kafka message bus. 8.5.1 Example spec​The datasources for kafka are defined in src/datasources. Here, two kafka clients kafka1.yaml and kafka2.yaml are defined in datasources..├── config└── src    ├── datasources    │   └── httpbin.yaml    │   ├── kafka1.yaml    │   └── kafka2.yaml    ├── events    ├── functions    └── mappingsSample configuration in kafka1.yamltype: kafkaclient_id: my_servicebrokers: [ "kafka:9092" ]Edit this pagePrevious8.4 Datastore as datasourceNextElasticgraph as datasource8.5.1 Example specForumDiscordGithubTwitterLinkedIn








Elasticgraph as datasource | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 ElasticgraphElasticgraph as datasourceFeature, Configurations & API8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.6 ElasticgraphElasticgraph as datasourceVersion: v1On this pageIntroductionThe framework supports Elasticgraph as a datasource. It supports elasticsearch as datastore. In addition, you can use various features of Elasticgraph like deep graph search algorithms, de-normalization, joins, aggregations, multi-lingual support.8.6.1 Folder Structure​The datasources for Elasticgraph are defined in src/datasources. Here, elasticgraph1.yaml and elasticgraph2.yaml are defined in datasources..├── config└── src    ├── datasources    │   └── httpbin.yaml    │   ├── elasticgraph1.yaml    │   ├── elasticgraph2.yaml    ├── events    ├── functions    └── mappings8.6.2 Datasource DSL​elasticgraph1.yaml  type: elasticgraph  schema_backend: ./eg_config/eg1/ # relative path to config files  deep: false # deep feature of Elasticgraph to use graph algorithms  collect: true # collect feature of elasticsearchelasticgraph2.yamltype: elasticgraphschema_backend: ./eg_config/eg1/ # relative path to config filesdeep: false # deep feature of Elasticgraph to use graph algorithmscollect: true # collect feature of elasticsearch8.6.3 Configuration files of Elasticgraph​All the configuration files of Elasticgraph datasources should be defined in src/datasources/eg_config/ directory.Sample strucutre of config files..├── elasticgraph1.yaml├── elasticgraph2.yaml├── eg1│   ├── collect.toml│   ├── common.toml│   ├── config.toml│   ├── custom.toml│   ├── elasticsearch.toml│   ├── joins│   │   └── search.txt│   └── schema│       ├── aggregation.toml│       ├── dependencies.toml│       ├── entities│       │   ├── reconciled.toml│       │   └── auth_user.toml│       ├── entitiesInfo.toml│       ├── relationships.txt│       ├── suggestions.toml│       └── union.toml└── eg2    ├── collect.toml    ├── common.toml    ├── config.toml    ├── custom.toml    ├── elasticsearch.toml    ├── joins    │   └── search.txt    └── schema        ├── aggregation.toml        ├── dependencies.toml        ├── entities        │   ├── reconciled.toml        │   └── auth_user.toml        ├── entitiesInfo.toml        ├── relationships.txt        ├── suggestions.toml        └── union.toml8.6.4 Elasticgraph Setup​The framework has inbuilt feature of setting up Elasticgraph model automatically whenever a new configuration is added in src/datasources/eg_config/ directory. In case, you are getting any error in the setup, then you can refer execute below step for manual setup:During the project setup, if you have not selected elasticsearch, then you will have to execute godspeed update in project root directory, outside the dev container. This will add elasticsearch in the dev container environment.Step 1: godspeed eg-push​$ godspeed eg-push                      _                                   _   __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|> eg_test@1.0.0 eg-push> for f in src/datasources/eg_config/*; do echo ${f}; node ../gs_service/elasticgraph/lib/mappingGenerator/reIndexer.js ${f} all; donesrc/datasources/eg_config/eg18.6.5 Auto generating CRUD APIs for Elasticgraph​Developer can generate CRUD APIs for all the entities in src/datasources/eg_config/ directory. Events and Workflows will be auto generated for Create, Read, Update and Delete operations for each entity in respective datastore. Auto-generated events and workflows will be stored in /events/{datasourceName}/{entityName} and /functions/com/gs/eg/{datasourceName}/{entityName} folders respectively.$ godspeed gen-crud-api                      _                                   _   __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|> eg_test@1.0.0 gen-crud-api> npx godspeed-crud-api-generatorSelect datasource / schema to generate CRUD APIsEvents and Workflows are generated for elasticgraph.yaml8.6.6 Elasticgraph setupCreating the mapping in Elasticsearch for first time​To create the mapping for the first time, run the following command:DEBUG=*,-elasticsearch node ../gs_service/elasticgraph/lib/mappingGenerator/reIndexer.js ./datasources/eg_config/eg1 all|<comma seprated list of defined entity types> inittip  If there are existing data indexed in Elasticsearch and we want to make changes to the mapping, such as adding new fields, it is not recommended to use the command used for creating the mapping for the first timeReindexing after mapping updates​If we have made any changes to the mapping, such as adding new fields, we will need to reindex our data to apply the changes to the existing documents. To reindex in Elasticsearch,run the following command:$ cd <path-to-elasticgraph-repo>DEBUG=*,-elasticsearch node ../gs_service/elasticgraph/lib/mappingGenerator/reIndexer.js ./datasources/eg_config/eg1 backend all|<comma seprated list of defined entity types>Configuration: Switching to OpenSearch in Elasticgraph​ElasticGraph supports both Elasticsearch and OpenSearch as underlying data stores. By default, Elasticsearch is used. To configure ElasticGraph to use OpenSearch instead of Elasticsearch, add the following either in an environment variable or in the elasticsearch.toml file in your project's configuration:Way 1: Add the following line to the .env file:​  ds=awsWay 2: Add the following line to the elasticsearch.toml file:​sample_project└── config      ├── backend           └── elasticsearch.tomlelasticsearch.tomlmaxConnections = 200apiVersion = '7.4'requestTimeout = 90000node = 'http://localhost:9200'sniffOnStart = trueds = 'aws'Custom Elasticsearch Mapping​If you want to override the auto-generated, default Elasticsearch mapping, You can override that in custom-mapping.yaml.custom-mapping.yamlreconciled: #The type of entity  mappings:    dynamic_templates:    - full_name:        path_match: charge_params.*        mapping:          type: float    properties:      charge_params:        properties:          fee (Fee):            type: float          fee (Phí dịch vụ):            type: floatAPI examples: Postman collection​Download the collection with documentation here
There you will see core CRUD API (same in sync and async). Each CRUD api has its documentation in the collection itself.Edit this pagePrevious8.5 Kafka as datasourceNextFeature, Configurations & API8.6.1 Folder Structure8.6.2 Datasource DSL8.6.3 Configuration files of Elasticgraph8.6.4 Elasticgraph Setup8.6.5 Auto generating CRUD APIs for ElasticgraphCreating the mapping in Elasticsearch for first timeReindexing after mapping updatesConfiguration: Switching to OpenSearch in ElasticgraphWay 1: Add the following line to the .env file:Way 2: Add the following line to the elasticsearch.toml file:Custom Elasticsearch MappingAPI examples: Postman collectionForumDiscordGithubTwitterLinkedIn








Elasticgraph as datasource | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 ElasticgraphElasticgraph as datasourceFeature, Configurations & API8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.6 ElasticgraphElasticgraph as datasourceVersion: v1On this pageIntroductionThe framework supports Elasticgraph as a datasource. It supports elasticsearch as datastore. In addition, you can use various features of Elasticgraph like deep graph search algorithms, de-normalization, joins, aggregations, multi-lingual support.8.6.1 Folder Structure​The datasources for Elasticgraph are defined in src/datasources. Here, elasticgraph1.yaml and elasticgraph2.yaml are defined in datasources..├── config└── src    ├── datasources    │   └── httpbin.yaml    │   ├── elasticgraph1.yaml    │   ├── elasticgraph2.yaml    ├── events    ├── functions    └── mappings8.6.2 Datasource DSL​elasticgraph1.yaml  type: elasticgraph  schema_backend: ./eg_config/eg1/ # relative path to config files  deep: false # deep feature of Elasticgraph to use graph algorithms  collect: true # collect feature of elasticsearchelasticgraph2.yamltype: elasticgraphschema_backend: ./eg_config/eg1/ # relative path to config filesdeep: false # deep feature of Elasticgraph to use graph algorithmscollect: true # collect feature of elasticsearch8.6.3 Configuration files of Elasticgraph​All the configuration files of Elasticgraph datasources should be defined in src/datasources/eg_config/ directory.Sample strucutre of config files..├── elasticgraph1.yaml├── elasticgraph2.yaml├── eg1│   ├── collect.toml│   ├── common.toml│   ├── config.toml│   ├── custom.toml│   ├── elasticsearch.toml│   ├── joins│   │   └── search.txt│   └── schema│       ├── aggregation.toml│       ├── dependencies.toml│       ├── entities│       │   ├── reconciled.toml│       │   └── auth_user.toml│       ├── entitiesInfo.toml│       ├── relationships.txt│       ├── suggestions.toml│       └── union.toml└── eg2    ├── collect.toml    ├── common.toml    ├── config.toml    ├── custom.toml    ├── elasticsearch.toml    ├── joins    │   └── search.txt    └── schema        ├── aggregation.toml        ├── dependencies.toml        ├── entities        │   ├── reconciled.toml        │   └── auth_user.toml        ├── entitiesInfo.toml        ├── relationships.txt        ├── suggestions.toml        └── union.toml8.6.4 Elasticgraph Setup​The framework has inbuilt feature of setting up Elasticgraph model automatically whenever a new configuration is added in src/datasources/eg_config/ directory. In case, you are getting any error in the setup, then you can refer execute below step for manual setup:During the project setup, if you have not selected elasticsearch, then you will have to execute godspeed update in project root directory, outside the dev container. This will add elasticsearch in the dev container environment.Step 1: godspeed eg-push​$ godspeed eg-push                      _                                   _   __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|> eg_test@1.0.0 eg-push> for f in src/datasources/eg_config/*; do echo ${f}; node ../gs_service/elasticgraph/lib/mappingGenerator/reIndexer.js ${f} all; donesrc/datasources/eg_config/eg18.6.5 Auto generating CRUD APIs for Elasticgraph​Developer can generate CRUD APIs for all the entities in src/datasources/eg_config/ directory. Events and Workflows will be auto generated for Create, Read, Update and Delete operations for each entity in respective datastore. Auto-generated events and workflows will be stored in /events/{datasourceName}/{entityName} and /functions/com/gs/eg/{datasourceName}/{entityName} folders respectively.$ godspeed gen-crud-api                      _                                   _   __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|> eg_test@1.0.0 gen-crud-api> npx godspeed-crud-api-generatorSelect datasource / schema to generate CRUD APIsEvents and Workflows are generated for elasticgraph.yaml8.6.6 Elasticgraph setupCreating the mapping in Elasticsearch for first time​To create the mapping for the first time, run the following command:DEBUG=*,-elasticsearch node ../gs_service/elasticgraph/lib/mappingGenerator/reIndexer.js ./datasources/eg_config/eg1 all|<comma seprated list of defined entity types> inittip  If there are existing data indexed in Elasticsearch and we want to make changes to the mapping, such as adding new fields, it is not recommended to use the command used for creating the mapping for the first timeReindexing after mapping updates​If we have made any changes to the mapping, such as adding new fields, we will need to reindex our data to apply the changes to the existing documents. To reindex in Elasticsearch,run the following command:$ cd <path-to-elasticgraph-repo>DEBUG=*,-elasticsearch node ../gs_service/elasticgraph/lib/mappingGenerator/reIndexer.js ./datasources/eg_config/eg1 backend all|<comma seprated list of defined entity types>Configuration: Switching to OpenSearch in Elasticgraph​ElasticGraph supports both Elasticsearch and OpenSearch as underlying data stores. By default, Elasticsearch is used. To configure ElasticGraph to use OpenSearch instead of Elasticsearch, add the following either in an environment variable or in the elasticsearch.toml file in your project's configuration:Way 1: Add the following line to the .env file:​  ds=awsWay 2: Add the following line to the elasticsearch.toml file:​sample_project└── config      ├── backend           └── elasticsearch.tomlelasticsearch.tomlmaxConnections = 200apiVersion = '7.4'requestTimeout = 90000node = 'http://localhost:9200'sniffOnStart = trueds = 'aws'Custom Elasticsearch Mapping​If you want to override the auto-generated, default Elasticsearch mapping, You can override that in custom-mapping.yaml.custom-mapping.yamlreconciled: #The type of entity  mappings:    dynamic_templates:    - full_name:        path_match: charge_params.*        mapping:          type: float    properties:      charge_params:        properties:          fee (Fee):            type: float          fee (Phí dịch vụ):            type: floatAPI examples: Postman collection​Download the collection with documentation here
There you will see core CRUD API (same in sync and async). Each CRUD api has its documentation in the collection itself.Edit this pagePrevious8.5 Kafka as datasourceNextFeature, Configurations & API8.6.1 Folder Structure8.6.2 Datasource DSL8.6.3 Configuration files of Elasticgraph8.6.4 Elasticgraph Setup8.6.5 Auto generating CRUD APIs for ElasticgraphCreating the mapping in Elasticsearch for first timeReindexing after mapping updatesConfiguration: Switching to OpenSearch in ElasticgraphWay 1: Add the following line to the .env file:Way 2: Add the following line to the elasticsearch.toml file:Custom Elasticsearch MappingAPI examples: Postman collectionForumDiscordGithubTwitterLinkedIn








Feature, Configurations & API | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 ElasticgraphElasticgraph as datasourceFeature, Configurations & API8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.6 ElasticgraphFeature, Configurations & APIVersion: v1On this pageAbout ElasticGraphBenefits​Productivity​EG saves LOT of effort in development of an Elasticsearch based app because it abstracts some most common data operations into a simple configurable abstractions saving hundreds to thousand lines of code, makes the code neat, elegantly abstracts business logic in configurable text files and saves many hours of development and testing.Performance​Using ElasticGraph one can configure and run (out of the box) highly scalable microservices using relational graph approach, optimized for storing and querying large informational graphs in greater depth and complexity.The node module internally uses intelligent query batching and in memory caching, to support thousands of concurrent users, and complex search and analytic graph queries.Features​Supports relationshipsJoinsYou can do this for upto multiple depths of relationships in an easy fashion.Graph search and aggregations (using denormalization + caching)Graph search: Find friends whose friends are from India.Graph aggrigations: Give countwise breakup of users across city.state.country.name propertyDependency management between data of related entities (At indexing time).Sometimes the value of some field of an entity depends on the value of another field in (possibly) another entity related to it.Example unions and copy values. More on it below.Here you can configure such dependencies through configuration.Multi lingual storage and read operationsYou can store, retrieve and search text fields in any languagesAny new language support can be added though a simple configurationEasy SQLEnglish like (or easy) query language is a custom DSL built to richly express queries in a very small and handy syntax, easily human readable.Write complex database operation logic in "very few lines"You (almost) don't need to be a developer to grasp it :-)Performance featuresQuery batchingEG collects and executes, multiple queries from different places in your application logic, as one bulk query to your datastores.Saves typical throughput time in high load scenarioIn memory cachingCheck and store queries and entities in an in-memory cache. This cache is internally populated and used during execution of EG’s deep API.Saves N -1 round trips to the database for every N queries.Developers can use this feature via EG’s npm module, to keep alive and share a cache object as long as they want for performance optimisation.Entities and model​In ElasticGraph (EG) domain, there are entities (similar to rows in MySQL, or nodes in a Graph). Each entity has an id, type, fields like text, date etc. and relationships (akin to foreign keys). The configurations of a field are all declared in one place.Each entity is stored in a separate ElasticSearch index by the name entity._type + ‘s’For example. for type video, the ES index will be videosThe simple fields of an entity and their settings are defined inHere is a sample config for 'event' entity type in TOML formatconfigFolder/schema/entities/{entityType}.toml[title]type = 'String'multiLingual = trueautoSuggestion = trueencrypted = truesort = true # Mark this field to be index as sortable or searchable[description]type = 'String' # String | Boolean | Number(stored as Long) | Object | DatemultiLingual = true[startingDate]type = 'date'multiLingual = falsetipIf you want to use `type = Float` then you need to specify in [custom-mappings.yaml](/docs/v1/microservices/datasources/elasticgraph//#custom-elasticsearch-mapping)Corresponding document of an Event, when returned from the API will look like shown below. It does not matter which underlying database the information is being fetched from.{  "_index": "events",  "_type": "event",  "_id": "294464",  "_version": 4,  "found": true,  "_source": {    "startingDate": 489004200000,    "tibetan": {      "description": "\nལ་དཱགས་མི་མང་ནས་ཇི་ལྟར་གསོལ་བ་འདེབས་པ་བཞིན་༧སྤྱི་ནོར་༧གོང་ས་སྐྱབས་མགོན་\n\nཆེན་པོ་མཆོག་ནས་ནང་ཆོས་ངོ་སྤྲོད་སྩལ་།",      "title": "Sample event"    },    "english": {      "description": "His Holiness the Fourteenth Dalai Lama gives an introduction on basic Tibetan Buddhism in Ladakh.",      "title": "པོ་མཆོག་ནས་ནང་ཆོས་ངོ་སྤྲོད་སྩལ"    }  }}The data model you set is used to generate the appropriate mappings for ES. This way, EG can be used to automatically create schema in ES.Field Encryption and Search in ElasticGraph​Protecting sensitive data is crucial in any application. ElasticGraph offers a powerful feature that allows encryption of specific fields mentioned in the TOML file of the schema. This ensures the confidentiality and integrity of sensitive information stored in your database.Furthermore, ElasticGraph enables search functionality on encrypted fields in their plaintext form. To achieve this, ElasticGraph utilizes the robust SHA-256 algorithm for deterministic encryption.For example, if you want to encrypt a mobile number field, you can easily achieve this by simply adding the line encrypted = true in the corresponding TOML file.[mobileNumber]type ="String"sort = trueencrypted = trueRelationships​You must define the relationships of your data model in configFolder/schema/relationships.txt.The format for specifying relationships in relationship file isrelationNameFromAToB <> relationNameFromBToAentityTypeA <> entityTypeB //One to onerelationNameFromAToB <> relationNameFromBToA[entityTypeA] <> entityTypeB //Many to onerelationNameFromAToBs <> relationNameFromBToAentityTypeA <> [entityTypeB] //One to manyrelationNameFromAsToBs <> relationNameFromBsToAs[entityTypeA] <> [entityTypeB] //many to manyAs you can see, when an entity type is surrounded by square brackets [], it means cardinality of manytipIt is compulsory to maintain relationship name both ways, from Entity A to B, and B to A.* This is so that one can express Graph traversal from both sides.Some examplesspeakers <> events[event] <> [speaker]sessions <> eventevent <> [session]Linking entities via relation​    es.deep.link({        e1: {            _type: ‘event’,            _id: ‘674’        },        e2: {            _type: session,            _id: 4        },        e1ToE2Relation: ‘sessions’    })    .then(console.log)Un-linking entities via relation​    es.deep.unlink({        e1: {            _type: ‘event’,            _id: ‘674’        },        e2: {            _type: session,            _id: 4        },        e1ToE2Relation: ‘sessions’    })    .then(console.log)Graph Search and Graph analytics​We use denormalisation to make it fastSettings configFolder/joins/index.txtImagine you have a database composed of events, speakers and persons.And, you wish to do the following two queries.Search events by speakers.person.nameShow countwise breakup of search results on events, based on speakers.person.name (like on ecommerce sites)If your tables have only the foreign keys, you will have to do multiple hits to implement such cross table queries. And they will be slow. Depending on your data size, this may take a long long time before the final query result is returned. Also, your database will most probably get under heavy load.With ElasticGraph you can denormalize based on simple rule setting and achieve the same result with a single hit to the database. By denormalizing (always ensuring latest copy of) the speaker.person.name information within the event object, during index, update, link or unlink calls.How does this work?By denormalizing (always ensuring latest copy of) the speaker.person.name information within the event object, during index, update, link or unlink calls.For example, here is how ‘event’ may look like in denormalization settings (in the file joins/index.txt)[event]sessions{title, description}speakers.person{name}Based on your configuration ElasticGraph works to automatically maintain the denormalised storage of speaker and session data in the event entities. Y
 You only need to link or unlink two entities by a relationship. Everything else is taken care by ElasticGraph. Maintenance of the denormalised graph state​Here are some scenarios in which the automatic denormalization will trigger in our example database.Whenever you update the name of a person, the events where he or she spoke, will also get updated with person’s new name.When you index (store) the event for first time in the database, and it contains speakers ids, the speaker’s name will also get copied inside the event entity as it gets stored/indexed.When the event is linked to a speaker, the speaker’s name will get copied inside the event entityWhen the event is unlinked from a speaker, the speaker’s id, name etc will get removed from the event entityThe Butterfly effect​As you just saw, any update can potentially create a ripple update across entire Graph, for maintaining correct data state as per the denormalisation and also the data dependency rules like union and copy (more on the latter below).Since this is handled internally by ElasticGraph, it saves the developer from the overhead of maintaining a consistent, denormalised graph state across all updates. His code doesn’t need to save the updated field value at multiple places in the database- a big overhead, lots of confusing code, more bugs... Instead, he simply declares the behavior just once, in a human readable way. After that he leaves it to ElasticGraph to do all the internal bookkeeping to upkeep a correct denormalised graph state all the time.In ElasticSearch and also in popular SQL stores, we can make use of the JSON style storage and do the joins within one document. In comparison to SQL way of rows, the document way of ES saves storage space and helps in faster analytics also. Have a look at how the denormalized speakers relationship is stored within an ElasticGraph event document.{  "_index": "events",  "_type": "event",  "_id": "294464",  "_version": 4,  "found": true,  "_source": {    "speakers": [      {        "_id": "c6c35e3b21815a4209054505ac5e1680a954efdf",        "own": true,        "fields": {          "person": {            "_id": "1",            "_version": 1,            "fields": {              "english": {                "name": "His Holiness the 14th Dalai Lama"              },              "tibetan": {                  "name" : "ང་ས་སྐུ་ཕྲེང་བཅུ་བཞི་"              }            }          }        }      }    ]  }}Data dependency implementation​Note: This strategy is perhaps best applied in write less and read more scenarios.In many data models, data of an entity in your graph may depend on the data of other related entities. For ex. if a married woman has a new child, the husband also has a new child. And vice versa.ElasticGraph gives you an easy way to manage complex data dependencies between related entities of your information graph. As any update is made to any Entity in your Graph, ElasticGraph checks if any part of the remaining Graph should be updated by this change as per your data model settings. If yes, it updates the entire affected Graph (Butterfly effect).For now EG supports two kinds of dependencies - Union from and Copy.Union fromSettings are in configFolder/schema/union.tomlUnion from operation can be used to compute and store distinct values, whether relationships or data values, merged from field values of multiple related entities.This is useful for one to many or many to many relationships. Please look at the following examples to understand.[conference]speakers = '+talks.speaker' #As soon as a talk is linked to a conferece, or an already linked talk gets linked to a speaker, *the talk’s speaker is also linked to the conference as one of its speakers, if not already linked before*. Vice versa happens if the talk is unlinked to its speaker, or the talk is removed from the conferencetopics = '+talks.topics' #As soon as a talk is linked to an conference, or a topic is set to an already linked talk, the talk’s topic is also added to the conference as one of its topics, if not already there. Vice versa happens if the talk is unliked to the conference, or the topic is removed from the talk.[‘person’]grandChildren = +‘children.children’ #Whenever a person’s child gets a new child, the new child gets added to the person’s grandchildren[‘folder’]fileTypes = ‘+childFolders.fileTypes +childFiles.type’ #Calculate union of all file types existing in the entire folder tree (recursively). Anytime, any file gets added to any child folder in this tree, the type of that file gets unioned with the list of fileTypes of that child folder, and all its parent folders up in the hierarchy.CopySettings are in configFolder/schema/union.tomlCurrently the copy functionality is achieved from within the union configuration.This is effective for many to one or one to one relations. For ex.[person]child = "+wife.child +husband.child" #This will ensure copy of child between husband and wife, whenever child is added to any one of the person entities[file]permissions = "+folder.permissions" #Whenever a folder’s permissions are updated the underlying files’ permissions are updated automatically. You can still manually override them, without affecting the folder. But whenever the folder’s permissions are updated again, the file’s permissions will get overwritten.Read time joins​This is helpful to create multiple views on the fly, during read time joinsTwo ways to specify read time joins:Approach A: Create a file in joins folder, and send the name of the file in the JSON query.Settings folder: configFolder/joinsFor read time joins, you specify name of a join configuration file stored in configFolder/joins. You can specify different joins for same entity in different contexts like read, search etc. The particular view can be referred by the ${filename} in your code.Ex. read.txt or search.txt. You can create multiple such files and refer themSample configuration in text file (Same as denormalization settings in joins/index.txt)    [event]    sessions{title, description}    speakers.person{name}    speakers.primaryLanguages{name}Approach B: Send the view (join) info in the query as JSON objectThis gives developer the flexibility to create any views on the fly.Example joins for user who lives in a city belonging to a state    {        "joins": {        "name": 1,        "city.name": 1,        "city.state.name": 1,        "city": { // Same effect as above two lines            "name": 1,            "state": {                "name": 1            }        }    }    }Sample API calls```js    deep.get({_id:1, _type: ‘event’ , joins: ‘read’});    deep.get({        _id:1,        _type: ‘event’ , joins: {        "name": 1,        "city.name": 1,        "city.state.name": 1        }}    );    deep.search({        _id:1,        _type: ‘event’ ,        query: {"match": {“speakers.person.english.name”: “Dalai Lama”}},        joins: ‘search’    })The joined response is returned in same structure as the denormalization join you saw just above. You can apply joins across any relation depth.For read time joins, you specify name of a join configuration file stored in configFolder/joins. You can specify different joins for same entity in different contexts like read, search etc. The joined response is returned in same structure as the denormalization join you saw just above. You can apply joins across any relation depth.Multi Linguality​Settings file: configFolder/common.toml.In that set, supportedLanguages = [‘english’ , ‘tibetan’, ‘thirdLanguage’]If your data is in a single language or is language agnostic, then supportedLanguages = []The fields which are declared multilingual, are stored like this in the _source of the entities."english": {    "name": "His Holiness the 14th Dalai Lama"},"tibetan": {    "name": "ྋགོང་ས་སྐུ་ཕྲེང་བཅུ་བཞི་པ།"}When creating, updating, searching or getting an entity, you have to specify the full path of every field, including its language. In search and get calls, you specify langs parameter, for the languages in which the data is to be fetched. By default data in all supported languages is fetched.Easy SQL​English like SQL to get lot of data work done - fast and easy. Even non-programmers can easily learn to do complex work over big data using this.One can use ESQL for working with EG entities or even pure ES indices.Its main features areGet much done with very less lines of code.Much elegant way compared to equivalent Javascript code.It supportsSearch, get, index, link, unlink, delete.Creation of variables and assignment of values. Numbers string, boolean, objects supportedIf/else operationsbreak, continuePrint logLooping over array - Async each parallelUseful for scanning over a search result or entire index and doing operations.Loops can be nested within each otherMixing pure JS functions as instructions of the script when the script can not handle the complexity of logicThe grammar of dsl engine is in the source code of ElasticGraph npm. lib/dslEngine/grammar.pegjsTo run the a single statement in EQL you call eg.dsl.execute(statement).To execute a whole script you call eg.dsl.runScripts(script)const fillSpeakersTranslatorsAndLinkWithEvent = [    'iterate over old-contents where {$exist: event_id} as old-content. Get 25 at a time. Flush every 5 cycles. Wait for 100 millis',    [        'get event *old-content.event_id',        'if *event is empty, display "empty event", *old-content.event_id',        'if *event is empty, stop here',        'search old-content-to-audio-channel where {content_id: *old-content._id} as cac',        'async each *cac.hits.hits as old-content-to-audio-channel'        [            'get old-audio-channel *old-content-to-audio-channel.audiochannel_id as old-audio-channel', //No need to mention _source or fields. Both places, including top level object will be checked for existence of audiochannelId field            'search first person where {_id: *old-audio-channel.speaker_id} as person.', //Creates person in index if not found there. Also sets person entity viz id+type as key in ctx.data, query as key with value being result in ctx.data            //Handle event.speakers/translators. This guy is either a speaker or a translator. Set the relevent linking            //Initializer            'roleType is speaker if *old-audio-channel.translation_type is empty. Else is translator',            'roleFeatures are {person._id: *old-audio-channel.speaker_id, primaryLanguages._id: *old-audio-channel.language_id}',            //Can include pure JS functions within the script also            (ctx) => {                //TODO fix this 'roleFeatures.translationType is *old-audio-channel.translation_type if *roleType is translator.',                if (ctx.get('roleType') === 'translator') {                const translationType = ctx.get('old-audio-channel')._source.translation_type                ctx.get('roleFeatures').translationType = translationType                }                return ctx            },            'search first *roleType where *roleFeatures as speakerOrTranslator. Create if not exists.',            'if *speakerOrTranslator is empty, display "empty speaker", *roleFeatures, *roleType',            'if *speakerOrTranslator is empty, stop here',            (ctx) => {                const speaker = ctx.get('speakerOrTranslator')                const speakerBody = speaker._source || speaker.fields                const pmName = _.get(_.first(speakerBody.primaryLanguages), 'fields.english.name')                if (_.isObject(pmName)) {                    debug('throw stopHere error to break the loop', JSON.stringify(speaker))                    throw new Error('stopHere')                }            },            //'display *roleType, *speakerOrTranslator._id, *roleFeatures',            'link *speakerOrTranslator with *event as events',        ],    ],    (ctx) => debug('Done ' + n++ + ' iterations')];//Now run the scripteg.dsl.execute(fillSpeakersTranslatorsAndLinkWithEvent);Performance features​There are two internal feature which stand behind the awesome performance of ElasticGraph - Collect and Cache.Collect​A typical program, during runtime, sends multiple queries to the database from different places. In case of using ES from NodeJS, each query entails an HTTP hit. Each such hit is an overhead on the system. Both to the Nodejs client and the ES cluster.This feature allows you to save this overhead to achieve greater system speed and performance. Using this you can collect multiple queries and when a specified timeout or batch size threshold is reached, you send them to ES as a single bulk request. You can collect multiple queries from any parts of your middle ware.     es.{methodName}.collect({methodParams})Sample settings in configFolder/collect.toml[batchSizes]msearch = 200index = 200mget = 200get = 200search = 200bulk = 200[timeouts] #in millisecondsindex = 30get = 30bulk = 30mget = 30msearch = 30search = 30Each type of query is collected in a batch till any one of the batchSize threshold or the timeout threshold is reached.The supported es methods are get, mget, search, msearch, bulk and index.
For ex. es.get.collect({_id:..,_type:..}).then()The deep functions and esql scripts of EG internally use this feature. This feature is available as part of the npm module.Cache​In the deep EG operations, a cache is used like a temporary EG index in memory. Hit to ES for each get/search query is done only once. After that each retrieved entity or document, and search result, is kept in the in memory store. Further, the graph update operations are also done in memory. Once the time to flush the updated graph to ES has come, one can call cache.flush()
All the in-memory-updated entities will be written to ES indices, and all cache data will be cleared.Limitations​Currently it does not support transactions or authorization (as of today)ElasticSearch also does not provide transactions or acidity. In EG, since a single update also updates rest of the graph, but first in memory, and then altogether flushed into ElasticSearch, it is possible that another process may have updated a part of updated graph in meantime. If so flushing of this subgraph update will throw an error because someone already updated part of the subgraph before. This will lead to a partial subgraph update.When using EG for denormalisation and dependency management, one has to be OK with possible errors in maintenance of the graph state. If you need strict ACID behavior in your application, its best to use a transactional database as your primary datastore and use ES as your secondary datastore for read/search/analytic queries at scale and speed.Soon EG, will provide both kind of data store support out of the box.Deep API​You can find the API and docs in the CRUD folder of the Postman collection shared hereA full API doc shall be made soon.Summing it up​This project started with the .collect() feature sometime in 2015, from there it has evolved to include the deep API, denormalization, esql and other features. And now it is expanding to become a very powerful full fledged Microservice Platform. We have catered to four clients so far, and also built our own admin panel using the same.Built with deep thought from the Himalayas. <3/|\Edit this pagePreviousElasticgraph as datasourceNext8.7 Extensible datasourcesBenefitsProductivityPerformanceFeaturesEntities and modelField Encryption and Search in ElasticGraphRelationshipsLinking entities via relationUn-linking entities via relationGraph Search and Graph analyticsData dependency implementationRead time joinsMulti LingualityEasy SQLPerformance featuresCollectCacheLimitationsDeep APISumming it upForumDiscordGithubTwitterLinkedIn








Feature, Configurations & API | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 ElasticgraphElasticgraph as datasourceFeature, Configurations & API8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.6 ElasticgraphFeature, Configurations & APIVersion: v1On this pageAbout ElasticGraphBenefits​Productivity​EG saves LOT of effort in development of an Elasticsearch based app because it abstracts some most common data operations into a simple configurable abstractions saving hundreds to thousand lines of code, makes the code neat, elegantly abstracts business logic in configurable text files and saves many hours of development and testing.Performance​Using ElasticGraph one can configure and run (out of the box) highly scalable microservices using relational graph approach, optimized for storing and querying large informational graphs in greater depth and complexity.The node module internally uses intelligent query batching and in memory caching, to support thousands of concurrent users, and complex search and analytic graph queries.Features​Supports relationshipsJoinsYou can do this for upto multiple depths of relationships in an easy fashion.Graph search and aggregations (using denormalization + caching)Graph search: Find friends whose friends are from India.Graph aggrigations: Give countwise breakup of users across city.state.country.name propertyDependency management between data of related entities (At indexing time).Sometimes the value of some field of an entity depends on the value of another field in (possibly) another entity related to it.Example unions and copy values. More on it below.Here you can configure such dependencies through configuration.Multi lingual storage and read operationsYou can store, retrieve and search text fields in any languagesAny new language support can be added though a simple configurationEasy SQLEnglish like (or easy) query language is a custom DSL built to richly express queries in a very small and handy syntax, easily human readable.Write complex database operation logic in "very few lines"You (almost) don't need to be a developer to grasp it :-)Performance featuresQuery batchingEG collects and executes, multiple queries from different places in your application logic, as one bulk query to your datastores.Saves typical throughput time in high load scenarioIn memory cachingCheck and store queries and entities in an in-memory cache. This cache is internally populated and used during execution of EG’s deep API.Saves N -1 round trips to the database for every N queries.Developers can use this feature via EG’s npm module, to keep alive and share a cache object as long as they want for performance optimisation.Entities and model​In ElasticGraph (EG) domain, there are entities (similar to rows in MySQL, or nodes in a Graph). Each entity has an id, type, fields like text, date etc. and relationships (akin to foreign keys). The configurations of a field are all declared in one place.Each entity is stored in a separate ElasticSearch index by the name entity._type + ‘s’For example. for type video, the ES index will be videosThe simple fields of an entity and their settings are defined inHere is a sample config for 'event' entity type in TOML formatconfigFolder/schema/entities/{entityType}.toml[title]type = 'String'multiLingual = trueautoSuggestion = trueencrypted = truesort = true # Mark this field to be index as sortable or searchable[description]type = 'String' # String | Boolean | Number(stored as Long) | Object | DatemultiLingual = true[startingDate]type = 'date'multiLingual = falsetipIf you want to use `type = Float` then you need to specify in [custom-mappings.yaml](/docs/v1/microservices/datasources/elasticgraph//#custom-elasticsearch-mapping)Corresponding document of an Event, when returned from the API will look like shown below. It does not matter which underlying database the information is being fetched from.{  "_index": "events",  "_type": "event",  "_id": "294464",  "_version": 4,  "found": true,  "_source": {    "startingDate": 489004200000,    "tibetan": {      "description": "\nལ་དཱགས་མི་མང་ནས་ཇི་ལྟར་གསོལ་བ་འདེབས་པ་བཞིན་༧སྤྱི་ནོར་༧གོང་ས་སྐྱབས་མགོན་\n\nཆེན་པོ་མཆོག་ནས་ནང་ཆོས་ངོ་སྤྲོད་སྩལ་།",      "title": "Sample event"    },    "english": {      "description": "His Holiness the Fourteenth Dalai Lama gives an introduction on basic Tibetan Buddhism in Ladakh.",      "title": "པོ་མཆོག་ནས་ནང་ཆོས་ངོ་སྤྲོད་སྩལ"    }  }}The data model you set is used to generate the appropriate mappings for ES. This way, EG can be used to automatically create schema in ES.Field Encryption and Search in ElasticGraph​Protecting sensitive data is crucial in any application. ElasticGraph offers a powerful feature that allows encryption of specific fields mentioned in the TOML file of the schema. This ensures the confidentiality and integrity of sensitive information stored in your database.Furthermore, ElasticGraph enables search functionality on encrypted fields in their plaintext form. To achieve this, ElasticGraph utilizes the robust SHA-256 algorithm for deterministic encryption.For example, if you want to encrypt a mobile number field, you can easily achieve this by simply adding the line encrypted = true in the corresponding TOML file.[mobileNumber]type ="String"sort = trueencrypted = trueRelationships​You must define the relationships of your data model in configFolder/schema/relationships.txt.The format for specifying relationships in relationship file isrelationNameFromAToB <> relationNameFromBToAentityTypeA <> entityTypeB //One to onerelationNameFromAToB <> relationNameFromBToA[entityTypeA] <> entityTypeB //Many to onerelationNameFromAToBs <> relationNameFromBToAentityTypeA <> [entityTypeB] //One to manyrelationNameFromAsToBs <> relationNameFromBsToAs[entityTypeA] <> [entityTypeB] //many to manyAs you can see, when an entity type is surrounded by square brackets [], it means cardinality of manytipIt is compulsory to maintain relationship name both ways, from Entity A to B, and B to A.* This is so that one can express Graph traversal from both sides.Some examplesspeakers <> events[event] <> [speaker]sessions <> eventevent <> [session]Linking entities via relation​    es.deep.link({        e1: {            _type: ‘event’,            _id: ‘674’        },        e2: {            _type: session,            _id: 4        },        e1ToE2Relation: ‘sessions’    })    .then(console.log)Un-linking entities via relation​    es.deep.unlink({        e1: {            _type: ‘event’,            _id: ‘674’        },        e2: {            _type: session,            _id: 4        },        e1ToE2Relation: ‘sessions’    })    .then(console.log)Graph Search and Graph analytics​We use denormalisation to make it fastSettings configFolder/joins/index.txtImagine you have a database composed of events, speakers and persons.And, you wish to do the following two queries.Search events by speakers.person.nameShow countwise breakup of search results on events, based on speakers.person.name (like on ecommerce sites)If your tables have only the foreign keys, you will have to do multiple hits to implement such cross table queries. And they will be slow. Depending on your data size, this may take a long long time before the final query result is returned. Also, your database will most probably get under heavy load.With ElasticGraph you can denormalize based on simple rule setting and achieve the same result with a single hit to the database. By denormalizing (always ensuring latest copy of) the speaker.person.name information within the event object, during index, update, link or unlink calls.How does this work?By denormalizing (always ensuring latest copy of) the speaker.person.name information within the event object, during index, update, link or unlink calls.For example, here is how ‘event’ may look like in denormalization settings (in the file joins/index.txt)[event]sessions{title, description}speakers.person{name}Based on your configuration ElasticGraph works to automatically maintain the denormalised storage of speaker and session data in the event entities. Y
 You only need to link or unlink two entities by a relationship. Everything else is taken care by ElasticGraph. Maintenance of the denormalised graph state​Here are some scenarios in which the automatic denormalization will trigger in our example database.Whenever you update the name of a person, the events where he or she spoke, will also get updated with person’s new name.When you index (store) the event for first time in the database, and it contains speakers ids, the speaker’s name will also get copied inside the event entity as it gets stored/indexed.When the event is linked to a speaker, the speaker’s name will get copied inside the event entityWhen the event is unlinked from a speaker, the speaker’s id, name etc will get removed from the event entityThe Butterfly effect​As you just saw, any update can potentially create a ripple update across entire Graph, for maintaining correct data state as per the denormalisation and also the data dependency rules like union and copy (more on the latter below).Since this is handled internally by ElasticGraph, it saves the developer from the overhead of maintaining a consistent, denormalised graph state across all updates. His code doesn’t need to save the updated field value at multiple places in the database- a big overhead, lots of confusing code, more bugs... Instead, he simply declares the behavior just once, in a human readable way. After that he leaves it to ElasticGraph to do all the internal bookkeeping to upkeep a correct denormalised graph state all the time.In ElasticSearch and also in popular SQL stores, we can make use of the JSON style storage and do the joins within one document. In comparison to SQL way of rows, the document way of ES saves storage space and helps in faster analytics also. Have a look at how the denormalized speakers relationship is stored within an ElasticGraph event document.{  "_index": "events",  "_type": "event",  "_id": "294464",  "_version": 4,  "found": true,  "_source": {    "speakers": [      {        "_id": "c6c35e3b21815a4209054505ac5e1680a954efdf",        "own": true,        "fields": {          "person": {            "_id": "1",            "_version": 1,            "fields": {              "english": {                "name": "His Holiness the 14th Dalai Lama"              },              "tibetan": {                  "name" : "ང་ས་སྐུ་ཕྲེང་བཅུ་བཞི་"              }            }          }        }      }    ]  }}Data dependency implementation​Note: This strategy is perhaps best applied in write less and read more scenarios.In many data models, data of an entity in your graph may depend on the data of other related entities. For ex. if a married woman has a new child, the husband also has a new child. And vice versa.ElasticGraph gives you an easy way to manage complex data dependencies between related entities of your information graph. As any update is made to any Entity in your Graph, ElasticGraph checks if any part of the remaining Graph should be updated by this change as per your data model settings. If yes, it updates the entire affected Graph (Butterfly effect).For now EG supports two kinds of dependencies - Union from and Copy.Union fromSettings are in configFolder/schema/union.tomlUnion from operation can be used to compute and store distinct values, whether relationships or data values, merged from field values of multiple related entities.This is useful for one to many or many to many relationships. Please look at the following examples to understand.[conference]speakers = '+talks.speaker' #As soon as a talk is linked to a conferece, or an already linked talk gets linked to a speaker, *the talk’s speaker is also linked to the conference as one of its speakers, if not already linked before*. Vice versa happens if the talk is unlinked to its speaker, or the talk is removed from the conferencetopics = '+talks.topics' #As soon as a talk is linked to an conference, or a topic is set to an already linked talk, the talk’s topic is also added to the conference as one of its topics, if not already there. Vice versa happens if the talk is unliked to the conference, or the topic is removed from the talk.[‘person’]grandChildren = +‘children.children’ #Whenever a person’s child gets a new child, the new child gets added to the person’s grandchildren[‘folder’]fileTypes = ‘+childFolders.fileTypes +childFiles.type’ #Calculate union of all file types existing in the entire folder tree (recursively). Anytime, any file gets added to any child folder in this tree, the type of that file gets unioned with the list of fileTypes of that child folder, and all its parent folders up in the hierarchy.CopySettings are in configFolder/schema/union.tomlCurrently the copy functionality is achieved from within the union configuration.This is effective for many to one or one to one relations. For ex.[person]child = "+wife.child +husband.child" #This will ensure copy of child between husband and wife, whenever child is added to any one of the person entities[file]permissions = "+folder.permissions" #Whenever a folder’s permissions are updated the underlying files’ permissions are updated automatically. You can still manually override them, without affecting the folder. But whenever the folder’s permissions are updated again, the file’s permissions will get overwritten.Read time joins​This is helpful to create multiple views on the fly, during read time joinsTwo ways to specify read time joins:Approach A: Create a file in joins folder, and send the name of the file in the JSON query.Settings folder: configFolder/joinsFor read time joins, you specify name of a join configuration file stored in configFolder/joins. You can specify different joins for same entity in different contexts like read, search etc. The particular view can be referred by the ${filename} in your code.Ex. read.txt or search.txt. You can create multiple such files and refer themSample configuration in text file (Same as denormalization settings in joins/index.txt)    [event]    sessions{title, description}    speakers.person{name}    speakers.primaryLanguages{name}Approach B: Send the view (join) info in the query as JSON objectThis gives developer the flexibility to create any views on the fly.Example joins for user who lives in a city belonging to a state    {        "joins": {        "name": 1,        "city.name": 1,        "city.state.name": 1,        "city": { // Same effect as above two lines            "name": 1,            "state": {                "name": 1            }        }    }    }Sample API calls```js    deep.get({_id:1, _type: ‘event’ , joins: ‘read’});    deep.get({        _id:1,        _type: ‘event’ , joins: {        "name": 1,        "city.name": 1,        "city.state.name": 1        }}    );    deep.search({        _id:1,        _type: ‘event’ ,        query: {"match": {“speakers.person.english.name”: “Dalai Lama”}},        joins: ‘search’    })The joined response is returned in same structure as the denormalization join you saw just above. You can apply joins across any relation depth.For read time joins, you specify name of a join configuration file stored in configFolder/joins. You can specify different joins for same entity in different contexts like read, search etc. The joined response is returned in same structure as the denormalization join you saw just above. You can apply joins across any relation depth.Multi Linguality​Settings file: configFolder/common.toml.In that set, supportedLanguages = [‘english’ , ‘tibetan’, ‘thirdLanguage’]If your data is in a single language or is language agnostic, then supportedLanguages = []The fields which are declared multilingual, are stored like this in the _source of the entities."english": {    "name": "His Holiness the 14th Dalai Lama"},"tibetan": {    "name": "ྋགོང་ས་སྐུ་ཕྲེང་བཅུ་བཞི་པ།"}When creating, updating, searching or getting an entity, you have to specify the full path of every field, including its language. In search and get calls, you specify langs parameter, for the languages in which the data is to be fetched. By default data in all supported languages is fetched.Easy SQL​English like SQL to get lot of data work done - fast and easy. Even non-programmers can easily learn to do complex work over big data using this.One can use ESQL for working with EG entities or even pure ES indices.Its main features areGet much done with very less lines of code.Much elegant way compared to equivalent Javascript code.It supportsSearch, get, index, link, unlink, delete.Creation of variables and assignment of values. Numbers string, boolean, objects supportedIf/else operationsbreak, continuePrint logLooping over array - Async each parallelUseful for scanning over a search result or entire index and doing operations.Loops can be nested within each otherMixing pure JS functions as instructions of the script when the script can not handle the complexity of logicThe grammar of dsl engine is in the source code of ElasticGraph npm. lib/dslEngine/grammar.pegjsTo run the a single statement in EQL you call eg.dsl.execute(statement).To execute a whole script you call eg.dsl.runScripts(script)const fillSpeakersTranslatorsAndLinkWithEvent = [    'iterate over old-contents where {$exist: event_id} as old-content. Get 25 at a time. Flush every 5 cycles. Wait for 100 millis',    [        'get event *old-content.event_id',        'if *event is empty, display "empty event", *old-content.event_id',        'if *event is empty, stop here',        'search old-content-to-audio-channel where {content_id: *old-content._id} as cac',        'async each *cac.hits.hits as old-content-to-audio-channel'        [            'get old-audio-channel *old-content-to-audio-channel.audiochannel_id as old-audio-channel', //No need to mention _source or fields. Both places, including top level object will be checked for existence of audiochannelId field            'search first person where {_id: *old-audio-channel.speaker_id} as person.', //Creates person in index if not found there. Also sets person entity viz id+type as key in ctx.data, query as key with value being result in ctx.data            //Handle event.speakers/translators. This guy is either a speaker or a translator. Set the relevent linking            //Initializer            'roleType is speaker if *old-audio-channel.translation_type is empty. Else is translator',            'roleFeatures are {person._id: *old-audio-channel.speaker_id, primaryLanguages._id: *old-audio-channel.language_id}',            //Can include pure JS functions within the script also            (ctx) => {                //TODO fix this 'roleFeatures.translationType is *old-audio-channel.translation_type if *roleType is translator.',                if (ctx.get('roleType') === 'translator') {                const translationType = ctx.get('old-audio-channel')._source.translation_type                ctx.get('roleFeatures').translationType = translationType                }                return ctx            },            'search first *roleType where *roleFeatures as speakerOrTranslator. Create if not exists.',            'if *speakerOrTranslator is empty, display "empty speaker", *roleFeatures, *roleType',            'if *speakerOrTranslator is empty, stop here',            (ctx) => {                const speaker = ctx.get('speakerOrTranslator')                const speakerBody = speaker._source || speaker.fields                const pmName = _.get(_.first(speakerBody.primaryLanguages), 'fields.english.name')                if (_.isObject(pmName)) {                    debug('throw stopHere error to break the loop', JSON.stringify(speaker))                    throw new Error('stopHere')                }            },            //'display *roleType, *speakerOrTranslator._id, *roleFeatures',            'link *speakerOrTranslator with *event as events',        ],    ],    (ctx) => debug('Done ' + n++ + ' iterations')];//Now run the scripteg.dsl.execute(fillSpeakersTranslatorsAndLinkWithEvent);Performance features​There are two internal feature which stand behind the awesome performance of ElasticGraph - Collect and Cache.Collect​A typical program, during runtime, sends multiple queries to the database from different places. In case of using ES from NodeJS, each query entails an HTTP hit. Each such hit is an overhead on the system. Both to the Nodejs client and the ES cluster.This feature allows you to save this overhead to achieve greater system speed and performance. Using this you can collect multiple queries and when a specified timeout or batch size threshold is reached, you send them to ES as a single bulk request. You can collect multiple queries from any parts of your middle ware.     es.{methodName}.collect({methodParams})Sample settings in configFolder/collect.toml[batchSizes]msearch = 200index = 200mget = 200get = 200search = 200bulk = 200[timeouts] #in millisecondsindex = 30get = 30bulk = 30mget = 30msearch = 30search = 30Each type of query is collected in a batch till any one of the batchSize threshold or the timeout threshold is reached.The supported es methods are get, mget, search, msearch, bulk and index.
For ex. es.get.collect({_id:..,_type:..}).then()The deep functions and esql scripts of EG internally use this feature. This feature is available as part of the npm module.Cache​In the deep EG operations, a cache is used like a temporary EG index in memory. Hit to ES for each get/search query is done only once. After that each retrieved entity or document, and search result, is kept in the in memory store. Further, the graph update operations are also done in memory. Once the time to flush the updated graph to ES has come, one can call cache.flush()
All the in-memory-updated entities will be written to ES indices, and all cache data will be cleared.Limitations​Currently it does not support transactions or authorization (as of today)ElasticSearch also does not provide transactions or acidity. In EG, since a single update also updates rest of the graph, but first in memory, and then altogether flushed into ElasticSearch, it is possible that another process may have updated a part of updated graph in meantime. If so flushing of this subgraph update will throw an error because someone already updated part of the subgraph before. This will lead to a partial subgraph update.When using EG for denormalisation and dependency management, one has to be OK with possible errors in maintenance of the graph state. If you need strict ACID behavior in your application, its best to use a transactional database as your primary datastore and use ES as your secondary datastore for read/search/analytic queries at scale and speed.Soon EG, will provide both kind of data store support out of the box.Deep API​You can find the API and docs in the CRUD folder of the Postman collection shared hereA full API doc shall be made soon.Summing it up​This project started with the .collect() feature sometime in 2015, from there it has evolved to include the deep API, denormalization, esql and other features. And now it is expanding to become a very powerful full fledged Microservice Platform. We have catered to four clients so far, and also built our own admin panel using the same.Built with deep thought from the Himalayas. <3/|\Edit this pagePreviousElasticgraph as datasourceNext8.7 Extensible datasourcesBenefitsProductivityPerformanceFeaturesEntities and modelField Encryption and Search in ElasticGraphRelationshipsLinking entities via relationUn-linking entities via relationGraph Search and Graph analyticsData dependency implementationRead time joinsMulti LingualityEasy SQLPerformance featuresCollectCacheLimitationsDeep APISumming it upForumDiscordGithubTwitterLinkedIn








8.7 Extensible datasources | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 Elasticgraph8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.7 Extensible datasourcesVersion: v1On this pageIntroductionThe framework provides feature to extend datasources where you can add new datasources with any customized type as per your business logic.8.7.1 Datasource definition​You can define your datasource in yaml file inside src/datasources directory. For example, newDatasource.yaml is defined in the datasources..├── config└── src    ├── datasources    │   └── httpbin.yaml    │   ├── kafka1.yaml    │   └── newDatasource.yaml    ├── events    ├── functions    └── mappingsThe three keys in yaml type, loadFn and executeFn are mandatory to define any new datasource which is not provided by the framework as core datasources. You can define other key/value pairs as per your need.Below is a sample of newDatasource.yamltype: sampleloadFn: com.sample.loaderexecuteFn: com.sample.executeclient_url: https://sample.comclient_id: sample123type​It defines the type of the datasource like api, soap, datastore, etc.loadFn​It defines the load function which loads the client for the datasource. The developer must define the load function in the workflows as mentioned in the below project structure. The loadFn can be a js/ts function which takes the datasource yaml as an input and return an object that contains client..├── config└── src    ├── datasources    ├── events    ├── functions    │   └── com    │       └── sample    │           ├── loader.ts    │           └── execute.ts    └── mappingsA sample of loader.tsexport default async function(args:{[key:string]:any;}) {    const ds = {        ...args,        client: new SampleClient(args)        };    return ds;    }executeFn​It defines the execute function which gets executed in the workflow. The developer must define the execute function in the workflows as mentioned in the above project structure. The executeFn can be a js/ts function which takes the workflow args as input and return status/output.export default async function(args:{[key:string]:any;}) {    if(args.datasource) {        const client = args.datasource.client;        const data = args.data;        if (!Array.isArray(args.data)) {            data = [args.data];        }. . . . . . . . . .        } else {        return { success: false, code: 500, data: 'datasource not found in the workflow' };    }}8.7.2 Example spec for the event​/sample_helloworld.http.post:  id: sample_event  fn: com.jfs.sample_helloworld  body:     description: The body of the query    required: true    content:      application/json: # For ex. application/json application/xml        schema:           type: object          properties:            name:               type: string          required: [name]8.7.3 Example spec for the workflow​summary: hello worldtasks:  - id: helloworld_step1    fn: com.sample.execute    args:      datasource: newDatasource      data: <% inputs %>      config:        method: sampleEdit this pagePreviousFeature, Configurations & APINext8.8 AWS as datasource8.7.1 Datasource definitiontypeloadFnexecuteFn8.7.2 Example spec for the event8.7.3 Example spec for the workflowForumDiscordGithubTwitterLinkedIn








8.7 Extensible datasources | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 Elasticgraph8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.7 Extensible datasourcesVersion: v1On this pageIntroductionThe framework provides feature to extend datasources where you can add new datasources with any customized type as per your business logic.8.7.1 Datasource definition​You can define your datasource in yaml file inside src/datasources directory. For example, newDatasource.yaml is defined in the datasources..├── config└── src    ├── datasources    │   └── httpbin.yaml    │   ├── kafka1.yaml    │   └── newDatasource.yaml    ├── events    ├── functions    └── mappingsThe three keys in yaml type, loadFn and executeFn are mandatory to define any new datasource which is not provided by the framework as core datasources. You can define other key/value pairs as per your need.Below is a sample of newDatasource.yamltype: sampleloadFn: com.sample.loaderexecuteFn: com.sample.executeclient_url: https://sample.comclient_id: sample123type​It defines the type of the datasource like api, soap, datastore, etc.loadFn​It defines the load function which loads the client for the datasource. The developer must define the load function in the workflows as mentioned in the below project structure. The loadFn can be a js/ts function which takes the datasource yaml as an input and return an object that contains client..├── config└── src    ├── datasources    ├── events    ├── functions    │   └── com    │       └── sample    │           ├── loader.ts    │           └── execute.ts    └── mappingsA sample of loader.tsexport default async function(args:{[key:string]:any;}) {    const ds = {        ...args,        client: new SampleClient(args)        };    return ds;    }executeFn​It defines the execute function which gets executed in the workflow. The developer must define the execute function in the workflows as mentioned in the above project structure. The executeFn can be a js/ts function which takes the workflow args as input and return status/output.export default async function(args:{[key:string]:any;}) {    if(args.datasource) {        const client = args.datasource.client;        const data = args.data;        if (!Array.isArray(args.data)) {            data = [args.data];        }. . . . . . . . . .        } else {        return { success: false, code: 500, data: 'datasource not found in the workflow' };    }}8.7.2 Example spec for the event​/sample_helloworld.http.post:  id: sample_event  fn: com.jfs.sample_helloworld  body:     description: The body of the query    required: true    content:      application/json: # For ex. application/json application/xml        schema:           type: object          properties:            name:               type: string          required: [name]8.7.3 Example spec for the workflow​summary: hello worldtasks:  - id: helloworld_step1    fn: com.sample.execute    args:      datasource: newDatasource      data: <% inputs %>      config:        method: sampleEdit this pagePreviousFeature, Configurations & APINext8.8 AWS as datasource8.7.1 Datasource definitiontypeloadFnexecuteFn8.7.2 Example spec for the event8.7.3 Example spec for the workflowForumDiscordGithubTwitterLinkedIn








8.8 AWS as datasource | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 Elasticgraph8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.8 AWS as datasourceVersion: v1On this pageIntroductionThe framework supports AWS as a datasource. It helps in interacting with AWS, to use various AWS services and methods. 8.8.1 Example spec​The datasources for AWS are defined in src/datasources. Here, AWS datasource is defined in aws_s3.yaml..├── config└── src    ├── datasources    │   └── httpbin.yaml    │   ├── aws_s3.yaml    ├── events    ├── functions    └── mappingsSample configuration in aws_s3.yamltype: awscommon:    credentials:        accessKeyId: 'AKIA4KQJJFGY2KPNNOEMmnbv'        secretAccessKey: '+pf5xyyPSUfBNn0V9ZIH0oPVzARBvxoehR+mpzigcdfg'    region: "ap-south-1"services:    S3:        config: {}8.8.2 com.gs.aws workflow​Refer here for com.gs.aws workflow.Edit this pagePrevious8.7 Extensible datasourcesNext8.9 Redis as datasource8.8.1 Example spec8.8.2 com.gs.aws workflowForumDiscordGithubTwitterLinkedIn








8.8 AWS as datasource | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 Elasticgraph8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.8 AWS as datasourceVersion: v1On this pageIntroductionThe framework supports AWS as a datasource. It helps in interacting with AWS, to use various AWS services and methods. 8.8.1 Example spec​The datasources for AWS are defined in src/datasources. Here, AWS datasource is defined in aws_s3.yaml..├── config└── src    ├── datasources    │   └── httpbin.yaml    │   ├── aws_s3.yaml    ├── events    ├── functions    └── mappingsSample configuration in aws_s3.yamltype: awscommon:    credentials:        accessKeyId: 'AKIA4KQJJFGY2KPNNOEMmnbv'        secretAccessKey: '+pf5xyyPSUfBNn0V9ZIH0oPVzARBvxoehR+mpzigcdfg'    region: "ap-south-1"services:    S3:        config: {}8.8.2 com.gs.aws workflow​Refer here for com.gs.aws workflow.Edit this pagePrevious8.7 Extensible datasourcesNext8.9 Redis as datasource8.8.1 Example spec8.8.2 com.gs.aws workflowForumDiscordGithubTwitterLinkedIn








8.9 Redis as datasource | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 Elasticgraph8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.9 Redis as datasourceVersion: v1On this pageIntroductionThe framework supports Redis as a datasource. It helps to utilize redis in different ways.8.9.1 Example spec​The datasources for Redis are defined in src/datasources. Here, Redis datasource is defined in redis.yaml..├── config└── src    ├── datasources    │   └── httpbin.yaml    │   ├── redis.yaml    ├── events    ├── functions    └── mappingsSample configuration in redis.yamltype: redisurl: redis[s]://[[username][:password]@][host][:port][/db-number]For full redis configuration, Refer redis node client documentation.redis-as-datasource also support connecting to cluster mode. Here is a sample redis datasource for cluster mode.type: rediscluster:    rootNodes:        - url: redis://10.0.0.1:30001        - url: redis://10.0.0.2:30002For full redis configuration, Refer redis cluster mode documentation.Edit this pagePrevious8.8 AWS as datasourceNext8.10 RabbitMQ as datasource8.9.1 Example specForumDiscordGithubTwitterLinkedIn








8.9 Redis as datasource | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 Elasticgraph8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.9 Redis as datasourceVersion: v1On this pageIntroductionThe framework supports Redis as a datasource. It helps to utilize redis in different ways.8.9.1 Example spec​The datasources for Redis are defined in src/datasources. Here, Redis datasource is defined in redis.yaml..├── config└── src    ├── datasources    │   └── httpbin.yaml    │   ├── redis.yaml    ├── events    ├── functions    └── mappingsSample configuration in redis.yamltype: redisurl: redis[s]://[[username][:password]@][host][:port][/db-number]For full redis configuration, Refer redis node client documentation.redis-as-datasource also support connecting to cluster mode. Here is a sample redis datasource for cluster mode.type: rediscluster:    rootNodes:        - url: redis://10.0.0.1:30001        - url: redis://10.0.0.2:30002For full redis configuration, Refer redis cluster mode documentation.Edit this pagePrevious8.8 AWS as datasourceNext8.10 RabbitMQ as datasource8.9.1 Example specForumDiscordGithubTwitterLinkedIn








8.10 RabbitMQ as datasource | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 Elasticgraph8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.10 RabbitMQ as datasourceVersion: v1On this pageIntroductionThe framework supports RabbitMQ as a messaging broker, acting as an intermediary for messaging. It provides a common platform for applications to send and receive messages and ensures that messages are securely stored until they are received, similar to Kafka.8.10.1 Example spec​The datasources for RabbitMQ are defined in src/datasources.  Here, RabbitMQ datasource is defined in rabbitmq.yaml..├── config└── src    ├── datasources    │   └── httpbin.yaml    │   ├── rabbitmq.yaml    │       ├── events    ├── functions    └── mappingsSample configuration in rabbitmq.yamltype: rabbitmqconfig:   connectionString: amqp://guest:guest@host.docker.internal:5672    exchange: TestOne   routingKey: TestQueueOne_keyretryCount: 3loadFn: com.gs.rabbitmq.loaderexecuteFn: com.gs.rabbitmq.publishEdit this pagePrevious8.9 Redis as datasourceNext8.11 Soap as datasource8.10.1 Example specForumDiscordGithubTwitterLinkedIn








8.10 RabbitMQ as datasource | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 Elasticgraph8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.10 RabbitMQ as datasourceVersion: v1On this pageIntroductionThe framework supports RabbitMQ as a messaging broker, acting as an intermediary for messaging. It provides a common platform for applications to send and receive messages and ensures that messages are securely stored until they are received, similar to Kafka.8.10.1 Example spec​The datasources for RabbitMQ are defined in src/datasources.  Here, RabbitMQ datasource is defined in rabbitmq.yaml..├── config└── src    ├── datasources    │   └── httpbin.yaml    │   ├── rabbitmq.yaml    │       ├── events    ├── functions    └── mappingsSample configuration in rabbitmq.yamltype: rabbitmqconfig:   connectionString: amqp://guest:guest@host.docker.internal:5672    exchange: TestOne   routingKey: TestQueueOne_keyretryCount: 3loadFn: com.gs.rabbitmq.loaderexecuteFn: com.gs.rabbitmq.publishEdit this pagePrevious8.9 Redis as datasourceNext8.11 Soap as datasource8.10.1 Example specForumDiscordGithubTwitterLinkedIn








8.11 Soap as datasource | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 Elasticgraph8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.11 Soap as datasourceVersion: v1On this pageIntroductionThe framework supports SOAP as a datasource. SOAP, which stands for Simple Object Access Protocol, is a way for different systems to talk to each other. It uses XML, a type of code that is easy for people to read and understand.8.11.1 Example spec​The datasources for soap are defined in src/datasources.  Here, soap datasource is defined in soap.yaml..├── config└── src    ├── datasources    │   └── httpbin.yaml    │   ├── soap.yaml    │       ├── events    ├── functions    └── mappingsSample configuration in soap.yamltype: soapurl: http://www.dneonline.com/calculator.asmx?WSDLsecurity:  type: basic  username: my_username  password: my_passwordEdit this pagePrevious8.10 RabbitMQ as datasourceNextCaching8.11.1 Example specForumDiscordGithubTwitterLinkedIn








8.11 Soap as datasource | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources8.1 Introduction8.2 Before and after hooks to datasource calls8.3 API datasource8.4 Datastore as datasource8.5 Kafka as datasource8.6 Elasticgraph8.7 Extensible datasources8.8 AWS as datasource8.9 Redis as datasource8.10 RabbitMQ as datasource8.11 Soap as datasource9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).8. Datasources8.11 Soap as datasourceVersion: v1On this pageIntroductionThe framework supports SOAP as a datasource. SOAP, which stands for Simple Object Access Protocol, is a way for different systems to talk to each other. It uses XML, a type of code that is easy for people to read and understand.8.11.1 Example spec​The datasources for soap are defined in src/datasources.  Here, soap datasource is defined in soap.yaml..├── config└── src    ├── datasources    │   └── httpbin.yaml    │   ├── soap.yaml    │       ├── events    ├── functions    └── mappingsSample configuration in soap.yamltype: soapurl: http://www.dneonline.com/calculator.asmx?WSDLsecurity:  type: basic  username: my_username  password: my_passwordEdit this pagePrevious8.10 RabbitMQ as datasourceNextCaching8.11.1 Example specForumDiscordGithubTwitterLinkedIn








Caching | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).9. CachingVersion: v1On this pageCachingGodspeed provides caching of the tasks using redis as cache. You can cache the result of any task in the workflows. 9.1 Specifications​9.1.1 Datasource spec for redis​Define a datasource with type 'redis' in src/datasources. Here, redis datasource is defined in src/datasources/redis.yamltype: redisurl: redis[s]://[[username][:password]@][host][:port][/db-number]9.1.2 Configuration​Define default caching datasource in static configurationlog_level: debuglang: coffeeserver_url: https://api.example.com:8443/v1/apicaching: redis9.1.3 Workflow spec​Here is the caching spec to write in the workflow.caching:    key: <key name which is used to cache result in redis>    invalidate: <used to invalidate the cache of some other task. Key name which we want to delete/remove from cache e.g. this field can be used in CRUD types task. While delete operation, invalidate the cache of read or update task>    cache_on_failure: <true|false, whether you want to cache the failure result or not. By default, it is false>    expires: <timer in seconds, until the cached result is valid>    force: <true|false, force flag to specify not to use cache, always trigger task's function. Set it to true if you don't want to use cache>Example Specsummary: workflow to cache task resultsid: cache_wftasks:  - id: cache_step1    caching:      key: cache_step1      invalidate: cache_step2      cache_on_failure : false      expires: 60      force: false    fn: com.gs.http    args:        datasource: httpbin        data:          name: 'hello'        config:          url : /anything          method: post  - id: cache_step2    caching:      key: cache_step2      cache_on_failure : false      expires: 60      force: false    fn: com.gs.http    args:        datasource: httpbin        data:          name: 'cache'        config:          url : /anything          method: postWhen the workflow is triggered for the first time, then the result of the two tasks are cached in DB with keys cache_step1 and cache_step2 for 60 seconds.If the next call to this workflow occurs within 60 seconds then the cached results will be used, else API call will be triggered.In the cache_step1, invaldiate spec is defined, which is invalidating/deleting the cached result of the cache_step2. It means even if cache_step2 is cached, if any calls occurs within 60 seconds then the cache_step1 will delete the cached result of cache_step2. So, no cache will be used for cache_step2.Edit this pagePrevious8.11 Soap as datasourceNextMappings9.1 Specifications9.1.1 Datasource spec for redis9.1.2 Configuration9.1.3 Workflow specForumDiscordGithubTwitterLinkedIn








Caching | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).9. CachingVersion: v1On this pageCachingGodspeed provides caching of the tasks using redis as cache. You can cache the result of any task in the workflows. 9.1 Specifications​9.1.1 Datasource spec for redis​Define a datasource with type 'redis' in src/datasources. Here, redis datasource is defined in src/datasources/redis.yamltype: redisurl: redis[s]://[[username][:password]@][host][:port][/db-number]9.1.2 Configuration​Define default caching datasource in static configurationlog_level: debuglang: coffeeserver_url: https://api.example.com:8443/v1/apicaching: redis9.1.3 Workflow spec​Here is the caching spec to write in the workflow.caching:    key: <key name which is used to cache result in redis>    invalidate: <used to invalidate the cache of some other task. Key name which we want to delete/remove from cache e.g. this field can be used in CRUD types task. While delete operation, invalidate the cache of read or update task>    cache_on_failure: <true|false, whether you want to cache the failure result or not. By default, it is false>    expires: <timer in seconds, until the cached result is valid>    force: <true|false, force flag to specify not to use cache, always trigger task's function. Set it to true if you don't want to use cache>Example Specsummary: workflow to cache task resultsid: cache_wftasks:  - id: cache_step1    caching:      key: cache_step1      invalidate: cache_step2      cache_on_failure : false      expires: 60      force: false    fn: com.gs.http    args:        datasource: httpbin        data:          name: 'hello'        config:          url : /anything          method: post  - id: cache_step2    caching:      key: cache_step2      cache_on_failure : false      expires: 60      force: false    fn: com.gs.http    args:        datasource: httpbin        data:          name: 'cache'        config:          url : /anything          method: postWhen the workflow is triggered for the first time, then the result of the two tasks are cached in DB with keys cache_step1 and cache_step2 for 60 seconds.If the next call to this workflow occurs within 60 seconds then the cached results will be used, else API call will be triggered.In the cache_step1, invaldiate spec is defined, which is invalidating/deleting the cached result of the cache_step2. It means even if cache_step2 is cached, if any calls occurs within 60 seconds then the cache_step1 will delete the cached result of cache_step2. So, no cache will be used for cache_step2.Edit this pagePrevious8.11 Soap as datasourceNextMappings9.1 Specifications9.1.1 Datasource spec for redis9.1.2 Configuration9.1.3 Workflow specForumDiscordGithubTwitterLinkedIn








Mappings | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).10. MappingsVersion: v1On this pageMappingsMappings is a global object which will be available in your microservice. You can define anything in the mappings i.e. key/value pair map, array, etc. You can access these mappings inside your workflows at any time.10.1 Project structure​Mappings are present in src/mappings directory. The default format is yaml and you can store mappings in the nested directories also. The nested directories are also accessible in the same mappings object..├── config└── src    └── mappings        └── index.yaml        └── generate.yaml10.2 Sample mappings​This is a sample mapping which is accessible in the workflows inside mappings object using mappings.Gender and mappings.generate.genId index.yamlGender:  Male: M  Female: F  Others: Ogenerate.yamlgenId: 12345NoteIf the file name is index.yaml then its content is available directly at global level i.e. you don't need to write index explicitly while accessing the mappings object like mappings.Gender.
However, for other file names you need to mention the file name while accessing the mappings object like mappings.generate.genIdSmaple workflow accessing mappings object:  - id: httpbinCof_step1    description: Hit http bin with some dummy data. It will send back same as response    fn: com.gs.http    args:      datasource: httpbin      params:      data:        personal_email_id: 'ala.eforwich@email.com'        gender: <% mappings.Gender[inputs.body.Gender] %>        id:  <% mappings.generate.genId %>      config:        url : /anything        method: post10.3 Use mappings constants in other mapping files​You can use mapping constants in other mapping files using coffee/js scripting.For example, you have mapping files index.yaml, relations.json and reference.yaml. Use the mappings from first two files as reference in the third file as follows:   index.yamlGender:  Male: M  Female: F  Others: Orelations.json{    "id": 1,    "title": "Hello World",    "completed": false}reference.yamlNewGender: <% mappings.Gender.Others %>title:  <% mappings.relations.title %>Edit this pagePreviousCachingNextPlugins10.1 Project structure10.2 Sample mappings10.3 Use mappings constants in other mapping filesForumDiscordGithubTwitterLinkedIn








Mappings | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).10. MappingsVersion: v1On this pageMappingsMappings is a global object which will be available in your microservice. You can define anything in the mappings i.e. key/value pair map, array, etc. You can access these mappings inside your workflows at any time.10.1 Project structure​Mappings are present in src/mappings directory. The default format is yaml and you can store mappings in the nested directories also. The nested directories are also accessible in the same mappings object..├── config└── src    └── mappings        └── index.yaml        └── generate.yaml10.2 Sample mappings​This is a sample mapping which is accessible in the workflows inside mappings object using mappings.Gender and mappings.generate.genId index.yamlGender:  Male: M  Female: F  Others: Ogenerate.yamlgenId: 12345NoteIf the file name is index.yaml then its content is available directly at global level i.e. you don't need to write index explicitly while accessing the mappings object like mappings.Gender.
However, for other file names you need to mention the file name while accessing the mappings object like mappings.generate.genIdSmaple workflow accessing mappings object:  - id: httpbinCof_step1    description: Hit http bin with some dummy data. It will send back same as response    fn: com.gs.http    args:      datasource: httpbin      params:      data:        personal_email_id: 'ala.eforwich@email.com'        gender: <% mappings.Gender[inputs.body.Gender] %>        id:  <% mappings.generate.genId %>      config:        url : /anything        method: post10.3 Use mappings constants in other mapping files​You can use mapping constants in other mapping files using coffee/js scripting.For example, you have mapping files index.yaml, relations.json and reference.yaml. Use the mappings from first two files as reference in the third file as follows:   index.yamlGender:  Male: M  Female: F  Others: Orelations.json{    "id": 1,    "title": "Hello World",    "completed": false}reference.yamlNewGender: <% mappings.Gender.Others %>title:  <% mappings.relations.title %>Edit this pagePreviousCachingNextPlugins10.1 Project structure10.2 Sample mappings10.3 Use mappings constants in other mapping filesForumDiscordGithubTwitterLinkedIn








Plugins | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).11. PluginsVersion: v1On this pagePluginsPlugins are small js/ts functions to enhance the workflows capabilities. You can write any piece of code in the plugin and can access it inside your workflows at any time.11.1 Project structure​Plugins are present in src/plugins directory. The default format is js/ts and you can store plugins in the nested directories also..├── config└── src    └── plugins        └── index.ts        └── time            └── epoch.ts        └── epoch            └── convertEpoch.ts11.2 Sample plugins​These are the sample plugins file which export plugin functions named randomInt and convertEpochToDate.plugins/index.tsexport function randomInt(min: number, max: number) {    return Math.floor(Math.random() * (max - min + 1)) + min;}plugins/time/epoch.tsimport format from 'date-fns/format';export function convertEpochToDate(inputTimestamp: string){    const newDateTime = new Date(inputTimestamp);    return format(newDateTime, 'yyyy-MM-dd HH:mm:ss');}plugins/epoch/convertEpoch.tsimport format from 'date-fns/format';export default function convertEpoch(inputTimestamp: string){    const newDateTime = new Date(inputTimestamp);    return format(newDateTime, 'yyyy-MM-dd HH:mm:ss');}NoteIf the file name is index.ts then its content is available directly at global level i.e. you don't need to write index explicitly while accessing the plugin e.g. randomInt.    For other file names you need to mention the file name using underscore notation while accessing the plugins function inside your workflow e.g. time_epoch_convertEpochToDateIf it's a default import then you don't need to mention the plugin function name e.g. epoch_convertEpoch11.3 Sample workflow using plugins​You can use these plugins in your workflows as given below:  - id: httpbinCof_step1    description: Hit http bin with some dummy data. It will send back same as response    fn: com.gs.http    args:      datasource: httpbin      params:      data:        personal_email_id: 'ala.eforwich@email.com'        id: <% 'UID-' + randomInt(1,9) %>        date: <% time_epoch_convertEpochToDate(inputs.body.datetimestamp) %>        default_date: <% epoch_convertEpoch(inputs.body.datetimestamp) %>      config:        url : /anything        method: postEdit this pagePreviousMappingsNextAuthentication & Authorization11.1 Project structure11.2 Sample plugins11.3 Sample workflow using pluginsForumDiscordGithubTwitterLinkedIn








Plugins | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).11. PluginsVersion: v1On this pagePluginsPlugins are small js/ts functions to enhance the workflows capabilities. You can write any piece of code in the plugin and can access it inside your workflows at any time.11.1 Project structure​Plugins are present in src/plugins directory. The default format is js/ts and you can store plugins in the nested directories also..├── config└── src    └── plugins        └── index.ts        └── time            └── epoch.ts        └── epoch            └── convertEpoch.ts11.2 Sample plugins​These are the sample plugins file which export plugin functions named randomInt and convertEpochToDate.plugins/index.tsexport function randomInt(min: number, max: number) {    return Math.floor(Math.random() * (max - min + 1)) + min;}plugins/time/epoch.tsimport format from 'date-fns/format';export function convertEpochToDate(inputTimestamp: string){    const newDateTime = new Date(inputTimestamp);    return format(newDateTime, 'yyyy-MM-dd HH:mm:ss');}plugins/epoch/convertEpoch.tsimport format from 'date-fns/format';export default function convertEpoch(inputTimestamp: string){    const newDateTime = new Date(inputTimestamp);    return format(newDateTime, 'yyyy-MM-dd HH:mm:ss');}NoteIf the file name is index.ts then its content is available directly at global level i.e. you don't need to write index explicitly while accessing the plugin e.g. randomInt.    For other file names you need to mention the file name using underscore notation while accessing the plugins function inside your workflow e.g. time_epoch_convertEpochToDateIf it's a default import then you don't need to mention the plugin function name e.g. epoch_convertEpoch11.3 Sample workflow using plugins​You can use these plugins in your workflows as given below:  - id: httpbinCof_step1    description: Hit http bin with some dummy data. It will send back same as response    fn: com.gs.http    args:      datasource: httpbin      params:      data:        personal_email_id: 'ala.eforwich@email.com'        id: <% 'UID-' + randomInt(1,9) %>        date: <% time_epoch_convertEpochToDate(inputs.body.datetimestamp) %>        default_date: <% epoch_convertEpoch(inputs.body.datetimestamp) %>      config:        url : /anything        method: postEdit this pagePreviousMappingsNextAuthentication & Authorization11.1 Project structure11.2 Sample plugins11.3 Sample workflow using pluginsForumDiscordGithubTwitterLinkedIn








Authentication & Authorization | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).12. Authentication & AuthorizationVersion: v1On this pageAuthentication & Authorization12.1 Authentication​The framework provides JWT authentication for securely transmitting information among microservices.
The user agent should send the JWT in the Authorization header using the Bearer schema. The content of the header should look like the following:Authorization: Bearer <token>12.1.1 JWT Configuration​You can do JWT configuration in Configuration/Environment variables. For example, this is the sample configuration:jwt:  issuer: JWT_ISS #iss  audience: JWT_AUD #aud  secretOrKey: JWT_SECRETOptions which can be passed for jwt config are: When configuring jwt config, if you dont not provide secretOrKeyProvider or secretOrKey property from the above config options it will throw an error. If you pass an issuer or audience value in config and the token values are set differently than the config payload, the response will be Unauthorised.You need to export these environment variables in your environment.12.1.1.1 Access JWT payload in Workflow DSL​You can access the complete JWT payload in <% inputs.user %> in workflow DSL as given below:summary: Call an API and transform the tasks:    - id: httpbin_step1      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      args:        datasource: httpbin        data: <% inputs.body %>          jwt_payload: <% inputs.user %>        config:          url : /anything          method: post12.1.2 Event spec​Add authn: true in the event DSL to enable authentication for any event./v1/loan-application/:lender_loan_application_id/kyc/ckyc/initiate.http.post:   authn: true  fn: com.biz.kyc.ckyc.ckyc_initiate  on_validation_error: com.jfs.handle_validation_error  data:    schema:      body:         required: true        content:          application/json:            schema:              type: 'object'              required: []              properties:                dob:  { type : 'string', format : 'date', pattern : "[0-9]{4}-[0-9]{2}-[0-9]{2}" }                meta:                  type: 'object'      params:       - name: lender_loan_application_id        in: params        required: true        allow_empty_value: false        schema:          type: string  responses: #Output data defined as per the OpenAPI spec    200:      schema:        data:           required: # default value is false          content:            application/json:              schema:                 type: object                properties:                  application_id:                     type: string                additionalProperties: false                required: [application_id]12.1.3 Generate JWT​Generally, you will get JWT from your authentication service. For testing purposes, you can generate JWT at https://jwt.io/ by providing the iss, aud and secretOrKey to verify signature. Use the encoded token as JWT authentication token. For example,
In the above case, the Authorization header should look like:Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtcy5zYW1wbGUuY29tIiwiYXVkIjoic2FtcGxlLmNvbSJ9._1fpM6VYq1rfKdTEqi8BcPTm8KIm4cNP8VhX0kQOEts12.1.4 Datasource authentication​You can add authentication at datasource level on API datasource. You can define an authn workflow at datasource level which requests to any authentication service for token/authentication then this workflow can return headers, params or statusCodes to the main workflow. Here is the sample spec:
Datasourcetype: apibase_url: <% config.httpbin.base_url %>authn: com.jfs.httpbin_authHere, com.jfs.httpbin_auth is the authentication workflow which gets called for the authentication of any request to this datasource.Sample workflow using the above datasourcesummary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      args:        datasource: httpbin        data: <% inputs.body %>        config:          url : /anything          method: postSample authentication workflow com.jfs.httpbin_authsummary: Auth workflowtasks:    - id: auth_step1      description: Hit the authn request      fn: com.gs.http      args:        datasource: authapi        data: <% inputs.query.username %>        config:           url: /authenticate          method: post    - id: auth_step2      description: Transform the response received from authn api      fn: com.gs.transform      args:        headers:          Authorization: <% 'Bearer ' + outputs.auth_step1.auth.token %>        params:          queryid: <% outputs.auth_step1.params.queryid %>        statusCodes: <% outputs.auth_step1.status_code %>          The authentication workflow should return response in this format:headers:   header1: val1params:  param1: val1statusCodes: [401, 403, ....]noteThe authentication workflow gets called when any request returns the specified statusCodes. 12.2 Authorization​The framework provides authorization, to verify if any event/model is authorized to access specific information or is allowed to execute certain actions.12.2.1 Workflow DSL​You can add authorization workflow at the task level in any workflow. The authorization workflow should return allow/deny or json output to the main worklfow. Allow/Deny 
If authz workflow returns data as true/false, it means the task is allowed/denied to get executed. JSON output 
If authz workflow returns JSON output then it is merged with args.data of the task for which authz is being executed.Here is the sample spec:
Sample workflow calling the authz workflowsummary: Call an APItasks:    - id: httpbin_step1      description: Hit http bin with some dummy data. It will send back same as response      authz:        fn: com.jfs.authz        args: <% inputs %>      fn: com.gs.http      args:        datasource: httpbin        data: <% inputs %>        config:          url : /anything          method: postSample authorization workflow com.jfs.authzsummary: Authorization workflowtasks:  - id: authz_step1    description: return allow/deny based upon user    fn: com.gs.http    args:       datasource: authz      data: <% inputs.body.user %>      config:        url : /authorize        method: post  - id: authz_step2    description: transform response from authz api    fn: com.gs.transform    args: |        <coffee% if outputs.authz_step1.data.code == 200 then {            success: true            data: true        } else if outputs.authz_step1.data.code == 201 then {            success: true            data:              where:                role: 'USER'        } else {            success: false            data: false        } %>The authorization workflow should return response in this format to allow/deny:success: true/falsedata: true/false/JSON outputWhen data is returned as false i.e. deny then the framework will send 403 Unauthorized response.12.2.2 Sample DB query call authorization​In DB query call, authz workflow can return JSON output with where clause, include clause etc. which will be merged with the args of the main workflow which is doing DB query.Here is the sample spec:
Sample workflow calling the authz workflowsummary: datastore demotasks:  - id: find_user    description: find users    authz:      fn: com.jfs.auth      args: <% inputs %>    fn: com.gs.datastore    args:      datasource: mongo      data:        include: <% inputs.body.include %>        where: <% inputs.body.where %>      config:        method: user.findManySample authorization workflow com.jfs.authzsummary: Authorization workflowtasks:  - id: authz_step1    description: return allow/deny based upon user    fn: com.gs.http    args:       datasource: authz      data: <% inputs.body.user %>      config:        url : /authorize        method: post  - id: authz_step2    description: transform response from authz api    fn: com.gs.transform    args: |        <coffee% if outputs.authz_step1.data.code == 200 then {            success: true            data:              where:                role: 'USER'        } else {            success: false            data: false        } %>When authorization workflow com.jfs.authz returns success: true then its data will be merged with the main workflow which is calling the authz workflow.
For example, in the above authz workflow, data is returned as:data:  where:    role: 'USER'This data will be merged with the args.data of the main workflow i.e.args:  data:    include: <% inputs.body.include %>    where: <% inputs.body.where %> # where clause from authz workflow will be merged with thisEdit this pagePreviousPluginsNextObservability12.1 Authentication12.1.1 JWT Configuration12.1.1.1 Access JWT payload in Workflow DSL12.1.2 Event spec12.1.3 Generate JWT12.1.4 Datasource authentication12.2 Authorization12.2.1 Workflow DSL12.2.2 Sample DB query call authorizationForumDiscordGithubTwitterLinkedIn








Authentication & Authorization | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).12. Authentication & AuthorizationVersion: v1On this pageAuthentication & Authorization12.1 Authentication​The framework provides JWT authentication for securely transmitting information among microservices.
The user agent should send the JWT in the Authorization header using the Bearer schema. The content of the header should look like the following:Authorization: Bearer <token>12.1.1 JWT Configuration​You can do JWT configuration in Configuration/Environment variables. For example, this is the sample configuration:jwt:  issuer: JWT_ISS #iss  audience: JWT_AUD #aud  secretOrKey: JWT_SECRETOptions which can be passed for jwt config are: When configuring jwt config, if you dont not provide secretOrKeyProvider or secretOrKey property from the above config options it will throw an error. If you pass an issuer or audience value in config and the token values are set differently than the config payload, the response will be Unauthorised.You need to export these environment variables in your environment.12.1.1.1 Access JWT payload in Workflow DSL​You can access the complete JWT payload in <% inputs.user %> in workflow DSL as given below:summary: Call an API and transform the tasks:    - id: httpbin_step1      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      args:        datasource: httpbin        data: <% inputs.body %>          jwt_payload: <% inputs.user %>        config:          url : /anything          method: post12.1.2 Event spec​Add authn: true in the event DSL to enable authentication for any event./v1/loan-application/:lender_loan_application_id/kyc/ckyc/initiate.http.post:   authn: true  fn: com.biz.kyc.ckyc.ckyc_initiate  on_validation_error: com.jfs.handle_validation_error  data:    schema:      body:         required: true        content:          application/json:            schema:              type: 'object'              required: []              properties:                dob:  { type : 'string', format : 'date', pattern : "[0-9]{4}-[0-9]{2}-[0-9]{2}" }                meta:                  type: 'object'      params:       - name: lender_loan_application_id        in: params        required: true        allow_empty_value: false        schema:          type: string  responses: #Output data defined as per the OpenAPI spec    200:      schema:        data:           required: # default value is false          content:            application/json:              schema:                 type: object                properties:                  application_id:                     type: string                additionalProperties: false                required: [application_id]12.1.3 Generate JWT​Generally, you will get JWT from your authentication service. For testing purposes, you can generate JWT at https://jwt.io/ by providing the iss, aud and secretOrKey to verify signature. Use the encoded token as JWT authentication token. For example,
In the above case, the Authorization header should look like:Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJtcy5zYW1wbGUuY29tIiwiYXVkIjoic2FtcGxlLmNvbSJ9._1fpM6VYq1rfKdTEqi8BcPTm8KIm4cNP8VhX0kQOEts12.1.4 Datasource authentication​You can add authentication at datasource level on API datasource. You can define an authn workflow at datasource level which requests to any authentication service for token/authentication then this workflow can return headers, params or statusCodes to the main workflow. Here is the sample spec:
Datasourcetype: apibase_url: <% config.httpbin.base_url %>authn: com.jfs.httpbin_authHere, com.jfs.httpbin_auth is the authentication workflow which gets called for the authentication of any request to this datasource.Sample workflow using the above datasourcesummary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      args:        datasource: httpbin        data: <% inputs.body %>        config:          url : /anything          method: postSample authentication workflow com.jfs.httpbin_authsummary: Auth workflowtasks:    - id: auth_step1      description: Hit the authn request      fn: com.gs.http      args:        datasource: authapi        data: <% inputs.query.username %>        config:           url: /authenticate          method: post    - id: auth_step2      description: Transform the response received from authn api      fn: com.gs.transform      args:        headers:          Authorization: <% 'Bearer ' + outputs.auth_step1.auth.token %>        params:          queryid: <% outputs.auth_step1.params.queryid %>        statusCodes: <% outputs.auth_step1.status_code %>          The authentication workflow should return response in this format:headers:   header1: val1params:  param1: val1statusCodes: [401, 403, ....]noteThe authentication workflow gets called when any request returns the specified statusCodes. 12.2 Authorization​The framework provides authorization, to verify if any event/model is authorized to access specific information or is allowed to execute certain actions.12.2.1 Workflow DSL​You can add authorization workflow at the task level in any workflow. The authorization workflow should return allow/deny or json output to the main worklfow. Allow/Deny 
If authz workflow returns data as true/false, it means the task is allowed/denied to get executed. JSON output 
If authz workflow returns JSON output then it is merged with args.data of the task for which authz is being executed.Here is the sample spec:
Sample workflow calling the authz workflowsummary: Call an APItasks:    - id: httpbin_step1      description: Hit http bin with some dummy data. It will send back same as response      authz:        fn: com.jfs.authz        args: <% inputs %>      fn: com.gs.http      args:        datasource: httpbin        data: <% inputs %>        config:          url : /anything          method: postSample authorization workflow com.jfs.authzsummary: Authorization workflowtasks:  - id: authz_step1    description: return allow/deny based upon user    fn: com.gs.http    args:       datasource: authz      data: <% inputs.body.user %>      config:        url : /authorize        method: post  - id: authz_step2    description: transform response from authz api    fn: com.gs.transform    args: |        <coffee% if outputs.authz_step1.data.code == 200 then {            success: true            data: true        } else if outputs.authz_step1.data.code == 201 then {            success: true            data:              where:                role: 'USER'        } else {            success: false            data: false        } %>The authorization workflow should return response in this format to allow/deny:success: true/falsedata: true/false/JSON outputWhen data is returned as false i.e. deny then the framework will send 403 Unauthorized response.12.2.2 Sample DB query call authorization​In DB query call, authz workflow can return JSON output with where clause, include clause etc. which will be merged with the args of the main workflow which is doing DB query.Here is the sample spec:
Sample workflow calling the authz workflowsummary: datastore demotasks:  - id: find_user    description: find users    authz:      fn: com.jfs.auth      args: <% inputs %>    fn: com.gs.datastore    args:      datasource: mongo      data:        include: <% inputs.body.include %>        where: <% inputs.body.where %>      config:        method: user.findManySample authorization workflow com.jfs.authzsummary: Authorization workflowtasks:  - id: authz_step1    description: return allow/deny based upon user    fn: com.gs.http    args:       datasource: authz      data: <% inputs.body.user %>      config:        url : /authorize        method: post  - id: authz_step2    description: transform response from authz api    fn: com.gs.transform    args: |        <coffee% if outputs.authz_step1.data.code == 200 then {            success: true            data:              where:                role: 'USER'        } else {            success: false            data: false        } %>When authorization workflow com.jfs.authz returns success: true then its data will be merged with the main workflow which is calling the authz workflow.
For example, in the above authz workflow, data is returned as:data:  where:    role: 'USER'This data will be merged with the args.data of the main workflow i.e.args:  data:    include: <% inputs.body.include %>    where: <% inputs.body.where %> # where clause from authz workflow will be merged with thisEdit this pagePreviousPluginsNextObservability12.1 Authentication12.1.1 JWT Configuration12.1.1.1 Access JWT payload in Workflow DSL12.1.2 Event spec12.1.3 Generate JWT12.1.4 Datasource authentication12.2 Authorization12.2.1 Workflow DSL12.2.2 Sample DB query call authorizationForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Custom Middleware | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).14. Custom MiddlewareVersion: v1On this pageCustom MiddlewareGodspeed provides usage of application level middleware functions. You can add any custom middleware functions which will have access to the request object (req), the response object (res), and the next middleware function in the application’s request-response cycle.14.1 How to add custom middleware in Godspeed​Step 1: Create an index.js/index.ts file in src/middlewares dierctory in your project.   Project structure.├── config└── src    └── middlewares        └── index.tsStep 2: index.ts/index.js should be exporting array of middleware functions with signature (req, res, next)   index.tsimport { uuid } from 'uuidv4';function addUuid(req: any, res: any, next: any) {    // Set data    req.body.uuid = uuid();        // Go to next middleware    next();}function addTitle(req: any, res: any, next: any) {    // Set data    req.body.title = "Title from middleware/ts";        // Go to next middleware    next();}export default [addUuid, addTitle];cautionIf the current middleware function does not end the request-response cycle, it must call next() to pass control to the next middleware function. Otherwise, the request will be left hanging. Sample req object 
Here, two properties uuid and title are added in the body of req object.{  "_events": {},  "_eventsCount": 1,  "httpVersionMajor": 1,  "httpVersionMinor": 1,  "httpVersion": "1.1",  "complete": true,  "rawHeaders": [    "Content-Type",    "application/json",    "User-Agent",    "PostmanRuntime/7.29.2",    "Accept",    "*/*",    "Cache-Control",    "no-cache",    "Postman-Token",    "7ce46b80-61e1-44c4-b91a-8a3c914797e8",    "Host",    "localhost:4901",    "Accept-Encoding",    "gzip, deflate, br",    "Connection",    "keep-alive",    "Content-Length",    "2"  ],  "rawTrailers": [],  "aborted": false,  "upgrade": false,  "url": "/test3",  "method": "POST",  "statusCode": null,  "statusMessage": null,  "_consuming": true,  "_dumped": false,  "baseUrl": "",  "originalUrl": "/test3",  "params": {},  "query": {},  "body": {    "uuid": "cfc5fc7f-cfdf-4fe7-99ad-08993f90f570",    "title": "Title from middleware/ts"  },  "_body": true,  "id": 2,  "log": {},  "route": {    "path": "/test3",    "stack": [      {        "name": "<anonymous>",        "keys": [],        "regexp": {          "fast_star": false,          "fast_slash": false        },        "method": "post"      },      {        "name": "<anonymous>",        "keys": [],        "regexp": {          "fast_star": false,          "fast_slash": false        },        "method": "post"      }    ],    "methods": {      "post": true    }  },  "protocol": "http",  "secure": false,  "ip": "::ffff:192.168.224.1",  "ips": [],  "subdomains": [],  "path": "/test3",  "hostname": "localhost",  "host": "localhost",  "fresh": false,  "stale": true,  "xhr": false,  "files": []}Edit this pagePreviousObservabilityNextRoadmap14.1 How to add custom middleware in GodspeedForumDiscordGithubTwitterLinkedIn








Custom Middleware | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).14. Custom MiddlewareVersion: v1On this pageCustom MiddlewareGodspeed provides usage of application level middleware functions. You can add any custom middleware functions which will have access to the request object (req), the response object (res), and the next middleware function in the application’s request-response cycle.14.1 How to add custom middleware in Godspeed​Step 1: Create an index.js/index.ts file in src/middlewares dierctory in your project.   Project structure.├── config└── src    └── middlewares        └── index.tsStep 2: index.ts/index.js should be exporting array of middleware functions with signature (req, res, next)   index.tsimport { uuid } from 'uuidv4';function addUuid(req: any, res: any, next: any) {    // Set data    req.body.uuid = uuid();        // Go to next middleware    next();}function addTitle(req: any, res: any, next: any) {    // Set data    req.body.title = "Title from middleware/ts";        // Go to next middleware    next();}export default [addUuid, addTitle];cautionIf the current middleware function does not end the request-response cycle, it must call next() to pass control to the next middleware function. Otherwise, the request will be left hanging. Sample req object 
Here, two properties uuid and title are added in the body of req object.{  "_events": {},  "_eventsCount": 1,  "httpVersionMajor": 1,  "httpVersionMinor": 1,  "httpVersion": "1.1",  "complete": true,  "rawHeaders": [    "Content-Type",    "application/json",    "User-Agent",    "PostmanRuntime/7.29.2",    "Accept",    "*/*",    "Cache-Control",    "no-cache",    "Postman-Token",    "7ce46b80-61e1-44c4-b91a-8a3c914797e8",    "Host",    "localhost:4901",    "Accept-Encoding",    "gzip, deflate, br",    "Connection",    "keep-alive",    "Content-Length",    "2"  ],  "rawTrailers": [],  "aborted": false,  "upgrade": false,  "url": "/test3",  "method": "POST",  "statusCode": null,  "statusMessage": null,  "_consuming": true,  "_dumped": false,  "baseUrl": "",  "originalUrl": "/test3",  "params": {},  "query": {},  "body": {    "uuid": "cfc5fc7f-cfdf-4fe7-99ad-08993f90f570",    "title": "Title from middleware/ts"  },  "_body": true,  "id": 2,  "log": {},  "route": {    "path": "/test3",    "stack": [      {        "name": "<anonymous>",        "keys": [],        "regexp": {          "fast_star": false,          "fast_slash": false        },        "method": "post"      },      {        "name": "<anonymous>",        "keys": [],        "regexp": {          "fast_star": false,          "fast_slash": false        },        "method": "post"      }    ],    "methods": {      "post": true    }  },  "protocol": "http",  "secure": false,  "ip": "::ffff:192.168.224.1",  "ips": [],  "subdomains": [],  "path": "/test3",  "hostname": "localhost",  "host": "localhost",  "fresh": false,  "stale": true,  "xhr": false,  "files": []}Edit this pagePreviousObservabilityNextRoadmap14.1 How to add custom middleware in GodspeedForumDiscordGithubTwitterLinkedIn








Roadmap | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).15. RoadmapVersion: v1On this pageRoadmapGodspeed Framework Roadmap Q1 and Q2 - 2023​Features [Core Framework]​Generative AI based microservice code generation [In progress - Q1]Generative AI based app generation [Q-2]Support to define and handle custom event sources [Done - Q1] Adding capability for defining reusable modules and use them in projects [Q-2]Support for Java, Golang, Python{on prioritisation by partners} [Q-2]Support for GraphQL like subscriptions - For event driven architecture and its varied use cases viz, Dual writes with eventual consistency, fraud detection, anomalies, notifications,any custom actions. [Q-2]Language Features & Debugging VSCode Extension​AI based FAQ & troubleshooting [Q-1]VS code Debugger  for step through debuggability[Q-2]Enhanced language & DSL feature support for coding [Constant & ongoing][Q1-2]Platform​Kubernetes based CI-CD governance setup using Argo stack [Done- Q1]K8s based Grafana observability stack - [Done- Q1]Shift left approach - Technology and infra agnostic, control plane for CI,CD, governance and observability management control plane. [In progress [Q1 - Q2]K8s based stack for common services (FOSS) for authn, authz, notifications etc [on Demand][Q1-2]Other Minor Stories- Core Framework, Platform & Language features​Support for Authentication for dynamic JWT tokens [Q1]Support to call YAML workflows from JS workflows [Q1]Support for using mapping file constants in other mapping file [Q1]Enhancements in Language​Support for validating / formatting inline js/coffee in yaml files [Q-1]Support to show proper error hints in events, workflows and datasources yaml files [Q-1]Help / Tooltip for different kind godspeed functions [Q-1]Support for JS/TS syntax check in workflows/datasources [Q-1]Better navigate between events and workflows and definitions through [Q-1]May pick up​Unified dashboard with SSO for CD and observability.Java flavour of microservice framework (on customer demand)Edit this pagePreviousCustom MiddlewareGodspeed Framework Roadmap Q1 and Q2 - 2023Features Core FrameworkLanguage Features & Debugging VSCode ExtensionPlatformOther Minor Stories- Core Framework, Platform & Language featuresEnhancements in LanguageMay pick upForumDiscordGithubTwitterLinkedIn








Roadmap | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).15. RoadmapVersion: v1On this pageRoadmapGodspeed Framework Roadmap Q1 and Q2 - 2023​Features [Core Framework]​Generative AI based microservice code generation [In progress - Q1]Generative AI based app generation [Q-2]Support to define and handle custom event sources [Done - Q1] Adding capability for defining reusable modules and use them in projects [Q-2]Support for Java, Golang, Python{on prioritisation by partners} [Q-2]Support for GraphQL like subscriptions - For event driven architecture and its varied use cases viz, Dual writes with eventual consistency, fraud detection, anomalies, notifications,any custom actions. [Q-2]Language Features & Debugging VSCode Extension​AI based FAQ & troubleshooting [Q-1]VS code Debugger  for step through debuggability[Q-2]Enhanced language & DSL feature support for coding [Constant & ongoing][Q1-2]Platform​Kubernetes based CI-CD governance setup using Argo stack [Done- Q1]K8s based Grafana observability stack - [Done- Q1]Shift left approach - Technology and infra agnostic, control plane for CI,CD, governance and observability management control plane. [In progress [Q1 - Q2]K8s based stack for common services (FOSS) for authn, authz, notifications etc [on Demand][Q1-2]Other Minor Stories- Core Framework, Platform & Language features​Support for Authentication for dynamic JWT tokens [Q1]Support to call YAML workflows from JS workflows [Q1]Support for using mapping file constants in other mapping file [Q1]Enhancements in Language​Support for validating / formatting inline js/coffee in yaml files [Q-1]Support to show proper error hints in events, workflows and datasources yaml files [Q-1]Help / Tooltip for different kind godspeed functions [Q-1]Support for JS/TS syntax check in workflows/datasources [Q-1]Better navigate between events and workflows and definitions through [Q-1]May pick up​Unified dashboard with SSO for CD and observability.Java flavour of microservice framework (on customer demand)Edit this pagePreviousCustom MiddlewareGodspeed Framework Roadmap Q1 and Q2 - 2023Features Core FrameworkLanguage Features & Debugging VSCode ExtensionPlatformOther Minor Stories- Core Framework, Platform & Language featuresEnhancements in LanguageMay pick upForumDiscordGithubTwitterLinkedIn








Roadmap | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).15. RoadmapVersion: v1On this pageRoadmapGodspeed Framework Roadmap Q1 and Q2 - 2023​Features [Core Framework]​Generative AI based microservice code generation [In progress - Q1]Generative AI based app generation [Q-2]Support to define and handle custom event sources [Done - Q1] Adding capability for defining reusable modules and use them in projects [Q-2]Support for Java, Golang, Python{on prioritisation by partners} [Q-2]Support for GraphQL like subscriptions - For event driven architecture and its varied use cases viz, Dual writes with eventual consistency, fraud detection, anomalies, notifications,any custom actions. [Q-2]Language Features & Debugging VSCode Extension​AI based FAQ & troubleshooting [Q-1]VS code Debugger  for step through debuggability[Q-2]Enhanced language & DSL feature support for coding [Constant & ongoing][Q1-2]Platform​Kubernetes based CI-CD governance setup using Argo stack [Done- Q1]K8s based Grafana observability stack - [Done- Q1]Shift left approach - Technology and infra agnostic, control plane for CI,CD, governance and observability management control plane. [In progress [Q1 - Q2]K8s based stack for common services (FOSS) for authn, authz, notifications etc [on Demand][Q1-2]Other Minor Stories- Core Framework, Platform & Language features​Support for Authentication for dynamic JWT tokens [Q1]Support to call YAML workflows from JS workflows [Q1]Support for using mapping file constants in other mapping file [Q1]Enhancements in Language​Support for validating / formatting inline js/coffee in yaml files [Q-1]Support to show proper error hints in events, workflows and datasources yaml files [Q-1]Help / Tooltip for different kind godspeed functions [Q-1]Support for JS/TS syntax check in workflows/datasources [Q-1]Better navigate between events and workflows and definitions through [Q-1]May pick up​Unified dashboard with SSO for CD and observability.Java flavour of microservice framework (on customer demand)Edit this pagePreviousCustom MiddlewareGodspeed Framework Roadmap Q1 and Q2 - 2023Features Core FrameworkLanguage Features & Debugging VSCode ExtensionPlatformOther Minor Stories- Core Framework, Platform & Language featuresEnhancements in LanguageMay pick upForumDiscordGithubTwitterLinkedIn








Roadmap | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).15. RoadmapVersion: v1On this pageRoadmapGodspeed Framework Roadmap Q1 and Q2 - 2023​Features [Core Framework]​Generative AI based microservice code generation [In progress - Q1]Generative AI based app generation [Q-2]Support to define and handle custom event sources [Done - Q1] Adding capability for defining reusable modules and use them in projects [Q-2]Support for Java, Golang, Python{on prioritisation by partners} [Q-2]Support for GraphQL like subscriptions - For event driven architecture and its varied use cases viz, Dual writes with eventual consistency, fraud detection, anomalies, notifications,any custom actions. [Q-2]Language Features & Debugging VSCode Extension​AI based FAQ & troubleshooting [Q-1]VS code Debugger  for step through debuggability[Q-2]Enhanced language & DSL feature support for coding [Constant & ongoing][Q1-2]Platform​Kubernetes based CI-CD governance setup using Argo stack [Done- Q1]K8s based Grafana observability stack - [Done- Q1]Shift left approach - Technology and infra agnostic, control plane for CI,CD, governance and observability management control plane. [In progress [Q1 - Q2]K8s based stack for common services (FOSS) for authn, authz, notifications etc [on Demand][Q1-2]Other Minor Stories- Core Framework, Platform & Language features​Support for Authentication for dynamic JWT tokens [Q1]Support to call YAML workflows from JS workflows [Q1]Support for using mapping file constants in other mapping file [Q1]Enhancements in Language​Support for validating / formatting inline js/coffee in yaml files [Q-1]Support to show proper error hints in events, workflows and datasources yaml files [Q-1]Help / Tooltip for different kind godspeed functions [Q-1]Support for JS/TS syntax check in workflows/datasources [Q-1]Better navigate between events and workflows and definitions through [Q-1]May pick up​Unified dashboard with SSO for CD and observability.Java flavour of microservice framework (on customer demand)Edit this pagePreviousCustom MiddlewareGodspeed Framework Roadmap Q1 and Q2 - 2023Features Core FrameworkLanguage Features & Debugging VSCode ExtensionPlatformOther Minor Stories- Core Framework, Platform & Language featuresEnhancements in LanguageMay pick upForumDiscordGithubTwitterLinkedIn








Roadmap | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).15. RoadmapVersion: v1On this pageRoadmapGodspeed Framework Roadmap Q1 and Q2 - 2023​Features [Core Framework]​Generative AI based microservice code generation [In progress - Q1]Generative AI based app generation [Q-2]Support to define and handle custom event sources [Done - Q1] Adding capability for defining reusable modules and use them in projects [Q-2]Support for Java, Golang, Python{on prioritisation by partners} [Q-2]Support for GraphQL like subscriptions - For event driven architecture and its varied use cases viz, Dual writes with eventual consistency, fraud detection, anomalies, notifications,any custom actions. [Q-2]Language Features & Debugging VSCode Extension​AI based FAQ & troubleshooting [Q-1]VS code Debugger  for step through debuggability[Q-2]Enhanced language & DSL feature support for coding [Constant & ongoing][Q1-2]Platform​Kubernetes based CI-CD governance setup using Argo stack [Done- Q1]K8s based Grafana observability stack - [Done- Q1]Shift left approach - Technology and infra agnostic, control plane for CI,CD, governance and observability management control plane. [In progress [Q1 - Q2]K8s based stack for common services (FOSS) for authn, authz, notifications etc [on Demand][Q1-2]Other Minor Stories- Core Framework, Platform & Language features​Support for Authentication for dynamic JWT tokens [Q1]Support to call YAML workflows from JS workflows [Q1]Support for using mapping file constants in other mapping file [Q1]Enhancements in Language​Support for validating / formatting inline js/coffee in yaml files [Q-1]Support to show proper error hints in events, workflows and datasources yaml files [Q-1]Help / Tooltip for different kind godspeed functions [Q-1]Support for JS/TS syntax check in workflows/datasources [Q-1]Better navigate between events and workflows and definitions through [Q-1]May pick up​Unified dashboard with SSO for CD and observability.Java flavour of microservice framework (on customer demand)Edit this pagePreviousCustom MiddlewareGodspeed Framework Roadmap Q1 and Q2 - 2023Features Core FrameworkLanguage Features & Debugging VSCode ExtensionPlatformOther Minor Stories- Core Framework, Platform & Language featuresEnhancements in LanguageMay pick upForumDiscordGithubTwitterLinkedIn








Roadmap | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).15. RoadmapVersion: v1On this pageRoadmapGodspeed Framework Roadmap Q1 and Q2 - 2023​Features [Core Framework]​Generative AI based microservice code generation [In progress - Q1]Generative AI based app generation [Q-2]Support to define and handle custom event sources [Done - Q1] Adding capability for defining reusable modules and use them in projects [Q-2]Support for Java, Golang, Python{on prioritisation by partners} [Q-2]Support for GraphQL like subscriptions - For event driven architecture and its varied use cases viz, Dual writes with eventual consistency, fraud detection, anomalies, notifications,any custom actions. [Q-2]Language Features & Debugging VSCode Extension​AI based FAQ & troubleshooting [Q-1]VS code Debugger  for step through debuggability[Q-2]Enhanced language & DSL feature support for coding [Constant & ongoing][Q1-2]Platform​Kubernetes based CI-CD governance setup using Argo stack [Done- Q1]K8s based Grafana observability stack - [Done- Q1]Shift left approach - Technology and infra agnostic, control plane for CI,CD, governance and observability management control plane. [In progress [Q1 - Q2]K8s based stack for common services (FOSS) for authn, authz, notifications etc [on Demand][Q1-2]Other Minor Stories- Core Framework, Platform & Language features​Support for Authentication for dynamic JWT tokens [Q1]Support to call YAML workflows from JS workflows [Q1]Support for using mapping file constants in other mapping file [Q1]Enhancements in Language​Support for validating / formatting inline js/coffee in yaml files [Q-1]Support to show proper error hints in events, workflows and datasources yaml files [Q-1]Help / Tooltip for different kind godspeed functions [Q-1]Support for JS/TS syntax check in workflows/datasources [Q-1]Better navigate between events and workflows and definitions through [Q-1]May pick up​Unified dashboard with SSO for CD and observability.Java flavour of microservice framework (on customer demand)Edit this pagePreviousCustom MiddlewareGodspeed Framework Roadmap Q1 and Q2 - 2023Features Core FrameworkLanguage Features & Debugging VSCode ExtensionPlatformOther Minor Stories- Core Framework, Platform & Language featuresEnhancements in LanguageMay pick upForumDiscordGithubTwitterLinkedIn








Roadmap | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).15. RoadmapVersion: v1On this pageRoadmapGodspeed Framework Roadmap Q1 and Q2 - 2023​Features [Core Framework]​Generative AI based microservice code generation [In progress - Q1]Generative AI based app generation [Q-2]Support to define and handle custom event sources [Done - Q1] Adding capability for defining reusable modules and use them in projects [Q-2]Support for Java, Golang, Python{on prioritisation by partners} [Q-2]Support for GraphQL like subscriptions - For event driven architecture and its varied use cases viz, Dual writes with eventual consistency, fraud detection, anomalies, notifications,any custom actions. [Q-2]Language Features & Debugging VSCode Extension​AI based FAQ & troubleshooting [Q-1]VS code Debugger  for step through debuggability[Q-2]Enhanced language & DSL feature support for coding [Constant & ongoing][Q1-2]Platform​Kubernetes based CI-CD governance setup using Argo stack [Done- Q1]K8s based Grafana observability stack - [Done- Q1]Shift left approach - Technology and infra agnostic, control plane for CI,CD, governance and observability management control plane. [In progress [Q1 - Q2]K8s based stack for common services (FOSS) for authn, authz, notifications etc [on Demand][Q1-2]Other Minor Stories- Core Framework, Platform & Language features​Support for Authentication for dynamic JWT tokens [Q1]Support to call YAML workflows from JS workflows [Q1]Support for using mapping file constants in other mapping file [Q1]Enhancements in Language​Support for validating / formatting inline js/coffee in yaml files [Q-1]Support to show proper error hints in events, workflows and datasources yaml files [Q-1]Help / Tooltip for different kind godspeed functions [Q-1]Support for JS/TS syntax check in workflows/datasources [Q-1]Better navigate between events and workflows and definitions through [Q-1]May pick up​Unified dashboard with SSO for CD and observability.Java flavour of microservice framework (on customer demand)Edit this pagePreviousCustom MiddlewareGodspeed Framework Roadmap Q1 and Q2 - 2023Features Core FrameworkLanguage Features & Debugging VSCode ExtensionPlatformOther Minor Stories- Core Framework, Platform & Language featuresEnhancements in LanguageMay pick upForumDiscordGithubTwitterLinkedIn








Roadmap | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).15. RoadmapVersion: v1On this pageRoadmapGodspeed Framework Roadmap Q1 and Q2 - 2023​Features [Core Framework]​Generative AI based microservice code generation [In progress - Q1]Generative AI based app generation [Q-2]Support to define and handle custom event sources [Done - Q1] Adding capability for defining reusable modules and use them in projects [Q-2]Support for Java, Golang, Python{on prioritisation by partners} [Q-2]Support for GraphQL like subscriptions - For event driven architecture and its varied use cases viz, Dual writes with eventual consistency, fraud detection, anomalies, notifications,any custom actions. [Q-2]Language Features & Debugging VSCode Extension​AI based FAQ & troubleshooting [Q-1]VS code Debugger  for step through debuggability[Q-2]Enhanced language & DSL feature support for coding [Constant & ongoing][Q1-2]Platform​Kubernetes based CI-CD governance setup using Argo stack [Done- Q1]K8s based Grafana observability stack - [Done- Q1]Shift left approach - Technology and infra agnostic, control plane for CI,CD, governance and observability management control plane. [In progress [Q1 - Q2]K8s based stack for common services (FOSS) for authn, authz, notifications etc [on Demand][Q1-2]Other Minor Stories- Core Framework, Platform & Language features​Support for Authentication for dynamic JWT tokens [Q1]Support to call YAML workflows from JS workflows [Q1]Support for using mapping file constants in other mapping file [Q1]Enhancements in Language​Support for validating / formatting inline js/coffee in yaml files [Q-1]Support to show proper error hints in events, workflows and datasources yaml files [Q-1]Help / Tooltip for different kind godspeed functions [Q-1]Support for JS/TS syntax check in workflows/datasources [Q-1]Better navigate between events and workflows and definitions through [Q-1]May pick up​Unified dashboard with SSO for CD and observability.Java flavour of microservice framework (on customer demand)Edit this pagePreviousCustom MiddlewareGodspeed Framework Roadmap Q1 and Q2 - 2023Features Core FrameworkLanguage Features & Debugging VSCode ExtensionPlatformOther Minor Stories- Core Framework, Platform & Language featuresEnhancements in LanguageMay pick upForumDiscordGithubTwitterLinkedIn








Roadmap | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).15. RoadmapVersion: v1On this pageRoadmapGodspeed Framework Roadmap Q1 and Q2 - 2023​Features [Core Framework]​Generative AI based microservice code generation [In progress - Q1]Generative AI based app generation [Q-2]Support to define and handle custom event sources [Done - Q1] Adding capability for defining reusable modules and use them in projects [Q-2]Support for Java, Golang, Python{on prioritisation by partners} [Q-2]Support for GraphQL like subscriptions - For event driven architecture and its varied use cases viz, Dual writes with eventual consistency, fraud detection, anomalies, notifications,any custom actions. [Q-2]Language Features & Debugging VSCode Extension​AI based FAQ & troubleshooting [Q-1]VS code Debugger  for step through debuggability[Q-2]Enhanced language & DSL feature support for coding [Constant & ongoing][Q1-2]Platform​Kubernetes based CI-CD governance setup using Argo stack [Done- Q1]K8s based Grafana observability stack - [Done- Q1]Shift left approach - Technology and infra agnostic, control plane for CI,CD, governance and observability management control plane. [In progress [Q1 - Q2]K8s based stack for common services (FOSS) for authn, authz, notifications etc [on Demand][Q1-2]Other Minor Stories- Core Framework, Platform & Language features​Support for Authentication for dynamic JWT tokens [Q1]Support to call YAML workflows from JS workflows [Q1]Support for using mapping file constants in other mapping file [Q1]Enhancements in Language​Support for validating / formatting inline js/coffee in yaml files [Q-1]Support to show proper error hints in events, workflows and datasources yaml files [Q-1]Help / Tooltip for different kind godspeed functions [Q-1]Support for JS/TS syntax check in workflows/datasources [Q-1]Better navigate between events and workflows and definitions through [Q-1]May pick up​Unified dashboard with SSO for CD and observability.Java flavour of microservice framework (on customer demand)Edit this pagePreviousCustom MiddlewareGodspeed Framework Roadmap Q1 and Q2 - 2023Features Core FrameworkLanguage Features & Debugging VSCode ExtensionPlatformOther Minor Stories- Core Framework, Platform & Language featuresEnhancements in LanguageMay pick upForumDiscordGithubTwitterLinkedIn








Custom Middleware | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).14. Custom MiddlewareVersion: v1On this pageCustom MiddlewareGodspeed provides usage of application level middleware functions. You can add any custom middleware functions which will have access to the request object (req), the response object (res), and the next middleware function in the application’s request-response cycle.14.1 How to add custom middleware in Godspeed​Step 1: Create an index.js/index.ts file in src/middlewares dierctory in your project.   Project structure.├── config└── src    └── middlewares        └── index.tsStep 2: index.ts/index.js should be exporting array of middleware functions with signature (req, res, next)   index.tsimport { uuid } from 'uuidv4';function addUuid(req: any, res: any, next: any) {    // Set data    req.body.uuid = uuid();        // Go to next middleware    next();}function addTitle(req: any, res: any, next: any) {    // Set data    req.body.title = "Title from middleware/ts";        // Go to next middleware    next();}export default [addUuid, addTitle];cautionIf the current middleware function does not end the request-response cycle, it must call next() to pass control to the next middleware function. Otherwise, the request will be left hanging. Sample req object 
Here, two properties uuid and title are added in the body of req object.{  "_events": {},  "_eventsCount": 1,  "httpVersionMajor": 1,  "httpVersionMinor": 1,  "httpVersion": "1.1",  "complete": true,  "rawHeaders": [    "Content-Type",    "application/json",    "User-Agent",    "PostmanRuntime/7.29.2",    "Accept",    "*/*",    "Cache-Control",    "no-cache",    "Postman-Token",    "7ce46b80-61e1-44c4-b91a-8a3c914797e8",    "Host",    "localhost:4901",    "Accept-Encoding",    "gzip, deflate, br",    "Connection",    "keep-alive",    "Content-Length",    "2"  ],  "rawTrailers": [],  "aborted": false,  "upgrade": false,  "url": "/test3",  "method": "POST",  "statusCode": null,  "statusMessage": null,  "_consuming": true,  "_dumped": false,  "baseUrl": "",  "originalUrl": "/test3",  "params": {},  "query": {},  "body": {    "uuid": "cfc5fc7f-cfdf-4fe7-99ad-08993f90f570",    "title": "Title from middleware/ts"  },  "_body": true,  "id": 2,  "log": {},  "route": {    "path": "/test3",    "stack": [      {        "name": "<anonymous>",        "keys": [],        "regexp": {          "fast_star": false,          "fast_slash": false        },        "method": "post"      },      {        "name": "<anonymous>",        "keys": [],        "regexp": {          "fast_star": false,          "fast_slash": false        },        "method": "post"      }    ],    "methods": {      "post": true    }  },  "protocol": "http",  "secure": false,  "ip": "::ffff:192.168.224.1",  "ips": [],  "subdomains": [],  "path": "/test3",  "hostname": "localhost",  "host": "localhost",  "fresh": false,  "stale": true,  "xhr": false,  "files": []}Edit this pagePreviousObservabilityNextRoadmap14.1 How to add custom middleware in GodspeedForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








3.3.3 Static variables | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup3.1 Getting started3.2 Project structure3.3 Configuration3.3.1 Introduction3.3.2 Environment variables3.3.3 Static variables3.3.4 Custom SwaggerSpec Documentation3.4 Tests3.5 Auto watch and build3.6 Debugger in Yaml4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).3. Setup3.3 Configuration3.3.3 Static variablesVersion: v1On this pageStatic variablesThe static variables as well as their values are defined in yaml files under config/ directory. These variables can be replaced as per the business use cases. The default directory structure is given as below:├── config│   ├── default.yamlnoteAny configuration which includes secrets or passwords is recommended to be defined using environment variables only. Avoid using static variables for secrets and passwords.default.yaml​This file contains some predefined variables. Below is a sample file which defines the static variables used in Godspeed.log_level: debuglang: coffeeredact: [] # fields to hide. Sample: ['ns', 'req.headers']server_url: https://api.example.com:8443/v1/apihttpbin: # sample api datasource url  base_url: https://httpbin.orgrequest_body_limit: 50mbfile_size_limit : 50mblog_level is the minimum log level to log. Log messages with a lower limit will not get logged. The default value is 'info'.
The available levels are 'fatal', 'error', 'warn', 'info', 'debug', 'trace' or 'silent'.
lang is the language used for scripting in the workflows. The default value is 'coffee'.
The available values are 'coffee' or 'js'. Refer Coffee/JS scripting for more information.
redact is the list of fields, the values for which, you want to hide from the logs. The default value is blank. Refer Logs field masking for more information.
server_url is the custom server url which you want to use as Servers in swagger specs/auto generated documentation. Refer Custom Server URLrequest_body_limit This variable sets the limit for the request body size. It checks if config.request_body_limit is defined in the application's configuration. If it is, the value from the configuration is used; otherwise, it defaults to 50 1024  1024 bytes (50 megabytes).file_size_limit This variable sets the limit for the file size. Similar to request_body_limit, it checks if config.file_size_limit is defined in the configuration. If it is, the value from the configuration is used; otherwise, it defaults to 50  1024  1024 bytes (50 megabytes).Edit this pagePrevious3.3.2 Environment variablesNext3.3.4 Custom SwaggerSpec Documentationdefault.yamlForumDiscordGithubTwitterLinkedIn








Workflows | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).7. WorkflowsVersion: v1On this pageWorkflowsWorkflows is where the actual computation and flow orchestration happens. The framework supports a YAML based DSL to write workflows and tasks containing the business logic. These workflows can be attached to the events as their handlers, or called from within another workflow.The framework exposes CoffeeScript/JS based expressions for evaluation of dynamic variables or transformation of data from inputs of event, or outputs of previous tasks.Default language for transformations (coffee/js) can be configured in configuration7.1 The structure of workflows​A workflow has the following attributessummary - the titledescription - more detailsid - Recommended for better logging visibilityon_error - Default error handling if any tasks fails. tasks - the tasks (workflows or sub-workflows) to be run in series (sequence, or one by one). The tasks invoke other workflows written in YAML or JS/TS. Other languages support is planned.summary: Hello worlddescription: Hello world example which invokes the com.gs.return workflowid: hello_world # needed for better logging visibilityon_error:  continue: false  log_attributes:  # You can add specific log attributes when an error happens in a task.        error_message: <% outputs.transform_error.message %>        error_type: 'your custom error type'  response:    success: false    code: 500    data: "Default error"tasks: # tasks to be run in sequence (default is sequence)  - id: step1 ## id of this task. Its output will be accessible  # to subsequent tasks at `outputs.step1_switch` location. Like in step2 below.    fn: com.gs.return    args: 'Hello World!' # com.gs.return takes its return value as `args`. Hence the args key.7.2 The tasks within workflows​A workflow has one or more tasks associated with it.
A task has the following attributesid - Needed for better logging visibility. It is compulsory for a task. Importantly, this is also used to access the output of this task in subsequent tasks in the outputs.{task_id} path, as shown in example below.summary - the titledescription - more detailsfn - The handler to be run in this task. It can be one of the framework functions, control functions (like parallel, sequential, switch), developer written functions, or another workflow.You can also use scripting in dynamic evaluation of a function name as given in below example. Refer Coffee/JS scripting for more information.summary: Call an API and transform thetasks:    - id: transform_fn_step1      description: find fn name      fn: com.gs.transform      args: |        <js%          if (inputs.body.fn == 'sum') {            return 'com.jfs.sum_workflow'          } else {            return 'com.jfs.helloworld'          }        %>    - id: call_fn_step2      description: call fn returned in transform_fn_step1      fn: <% outputs.transform_fn_step1.data %>      args:        name: <% inputs.body.name %>args - Every handler fn has its own argument structure, which is kept in the args key. For example,  id: httpbin_step1  fn: com.gs.http  args:    datasource: httpbin    config:      url : /v1/loan-application/<% inputs.params.lender_loan_application_id %>/agreement/esign/initiate      method: post      headers: <% inputs.headers %>on_error - What to do if this task fails?  on_error: #You can find sample usage of this in the examples below. Just search on_error in this page.    continue: false # Whether the next task should be executed, in case this task fails. by default continue is true.    response: <%Coffee/JS expression%> | String # If specified, the output of `response` is returned as the output of this task. If not specified, the error output is the default output of the failed task.    log_attributes:  # You can add specific log attributes when an error happens in a task.      error_message: <% outputs.transform_error.message %>      error_type: 'your custom error type'     tasks: # If specified, the tasks are executed in series/sequence. The output of the last task in these tasks is the default output of the failed task.      - id: transform_error        fn: com.gs.transform        args: <% outputs.httpbin_step1 %>      - id: publish_error        fn: com.gs.kafka        args:          datasource: kafka1          data:            value: <% outputs.transform_error.message %>          config:            topic: publish-producer1The only exception to this is control functions like series, parallel, switch, which don't take the args, for the sake of more readability.retry - Retry logic helps to handle transient failures, internal server errors, and network errors with support for constant, exponential and random types. Currently applied only for com.gs.http workflow.  retry:    max_attempts: 5    type: constant    interval: PT15m  retry:    max_attempts: 5    type: exponential    interval: PT15s  retry:    max_attempts: 5    type: random    min_interval: PT5s    max_interval: PT10sThe output of task & external function​The output of every task and function can be expected in the following format within other tasksuccess: true/false. Default value is truecode:  standard HTTP response codes[1xx, 2xx, 3xx, 4xx, 5xx] Default value is 200message: any string explaining the response. Optionaldata: the actual data returned from the task/function. OptionalNoteIf a task or external JS function returns a value which is not in this JSON structure then framework assumes the output is the data itself & wraps it in this JSON structure with default values.The output of any previously executed task is accesible in following manner outputs.step1.codeExample of multiple task with arguments​summary: Workflow with switch-case and transform taskid: example_switch_functionality_iddescription: |  Run two tasks in series. Both take different arguments. First one is switch case task.  Second is transform task which consumes the output of step1 and shapes the final output of this workflow.tasks: # tasks to be run in sequence (default is sequence)  - id: step1_switch ## id of this switch task. Its output will be accessible    # to subsequent tasks at `outputs.step1_switch` location. Like in step2 below.    fn: com.gs.switch # Switch workflow takes `value` and `cases` as arguments. The cases object specifies another task for every case.    value: <%inputs.body.condition%> # Evaluation of dynamic values happens via <% %>    cases:      FIRST:        id: 1st        fn: com.gs.return        args: "'case - 1'"      SECOND:        id: 2nd        fn: com.gs.return        args: "'case - 2'"      THIRD:        id: 3rd        fn: com.gs.return        args: "'case - 3'"    defaults:      id: default      fn: com.gs.return      args: <%inputs.body.default_return_val%> #coffee/js script for dyanmic evaluation. Wrapped in <% %>. Same as that used elsewhere in workflows for dynamic calculations and variable substitutions. For ex. as used in com.gs.transform and com.gs.return  - id: step2    fn: com.gs.transform    args: | #coffee for dyanmic evaluation. Wrapped in <% %>        <coffee% {          code: 200,              data: outputs['1st']        } %>7.3 Location and fully qualified name (id) of workflows and functions​All the workflows and functions are to be kept in the src/functions folder. Their directory tree path, followed by the file name becomes the workflow's fully qualified name or id, by which it can be referenced in the events or within other workflows.The JS function shown below will be available in workflows under the F.Q.N. com.biz.custom_function. Similarly, com.biz.create_hdfc_account, com.biz.create_parallel etc. are accessible as handlers from within other workflow tasks or events. 7.4 Referencing a workflow within an event or another workflow​A workflow task references and invokes other workflows written in either YAML or JS/TS, via the fn key. In future, other languages will also be supported.
An event definition references the handler yaml workflows by their fully qualified name, via the same fn key.7.5 Use of Coffee/JS for scripting​The framework provides coffee/js forTransformations in com.gs.transform and com.gs.returnDynamic evaluation or workflow or task variables, event variables, datasource variables.You will find its code in <% %> within various examples in this page below.Define language at global level​Default language for transformations (coffee/js) is configured in static configurationDefine language at workflow level​Global configuration for language is overridden by defining specific language inside <coffee/js% %>. For example,    - id: httpbinCof_step2      fn: com.gs.transform      args: |          <coffee% if outputs.httpbinCof_step1.data.json.code == 200 then {              code: 200,              success: true,              data: outputs.httpbinCof_step1.data.json,              headers: outputs.httpbinCof_step1.data.headers          } else {              code: 500,              success: false,              message: 'error in httpbinCof_step1'          } %>    - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: upload documents      fn: com.gs.http      args:        datasource: httpbin        params:        data: |          <js% {            [inputs.body.entity_type + 'id']: inputs.body.entity_id,            _.omit(inputs.body, ['entity_type', 'entity_id'])}          %>Built-in Javascript modules​You can use build-in javascript modules in inline scripting. Only synchronous methods of build-in modules are allowed in inline scripting. For example,summary: upload s3tasks:  - id: step1    description: upload s3    fn: com.gs.aws    args:      datasource: aws_s3      params:  # fs is used directly in scripting in Body        - Bucket: 'godspeedbucket'          Key: 'file4.yml'          Body: <% fs.createReadStream(inputs.files[0].tempFilePath) %>      config:        service: S3        method: putObject7.6 Inbuilt functions​The framework provides the following inbuilt functions7.6.1 com.gs.http​Send HTTP events to other APIs in Axios compatible format.Example 1  summary: agreement esign  id: agreement_esign  tasks:    - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: agreement esign      fn: com.gs.http      params: # query params to be sent in the request        id: 123      args:        datasource: httpbin        config:          url : /v1/loan-application/<% inputs.params.lender_loan_application_id %>/agreement/esign/initiate          method: post      retry:        max_attempts: 5        type: constant        interval: PT15M      on_error:        continue: true    - id: step2      fn: com.gs.transform      args: |          <%if outputs.step1.data.success then outputs.step1.data else {              code: outputs.step1.code,              success : false,              data: {                error_data: outputs.step1.data['error'],                uuid: outputs.step1.data.uuid,                status_code_error: outputs.step1.data.status_code_error,                event: outputs.step1.data.event              }          }%>Example 2  summary: upload documents  id: upload_documents  tasks:    - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: upload documents      fn: com.gs.http      args:        datasource: httpbin        params:        data: |          <js% {            [inputs.body.entity_type + 'id']: inputs.body.entity_id,            _.omit(inputs.body, ['entity_type', 'entity_id'])}          %>        file_key: files        files: <% inputs.files %>        config:          url : /v1/documents          method: post      retry:        max_attempts: 5        type: constant        interval: PT15M      on_error:        continue: false        response: <%'Some error happened in saving' + inputs.body.entity_type%>    - id: step2      fn: com.gs.transform      args: <% delete outputs.step1.headers; outputs.step1 %>7.6.2 com.gs.kafka​Publish events on Kafka.  summary: Publishing incoming event data to a Kafka topic  id: push_to_kafka  tasks:    - id: step1      summary: Publish an event with input event's data, adding to_process = true      fn: com.gs.kafka      args: # similar to Axios format        datasource: kafka1        config:          method: publish          topic: kyc_initiate_recieved          group_id: kyc_domain        data: # Refer https://kafka.js.org/docs/producing#message-structure for information on data attributes.          value: <% inputs %> # Your message content. Evaluation of dynamic values happens via <% %>. The type of scripting is coffee.          key: # Optional - Used for partitioning.          partition: # Optional - Which partition to send the message to.          timestamp: # Optional - The timestamp of when the message was created.          headers: # Optional - Metadata to associate with your message.Refer https://kafka.js.org/docs/producing#message-structure for information on data attributes.7.6.3 com.gs.datastore​The datastore function allows CRUD access to any supported datastore in a format extending Prisma API.summary: Create and read datatasks:  - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key    description: Create entity from REST input data (POST request)    fn: com.gs.datastore    args:      datasource: mongo # Which ds to use.      data: <% inputs.body + {extra_field: its_value} %>      config:        method: <% inputs.params.entity_type %>.create  - id: step2 # the response of this will be accessible within the parent step key, under the step1 sub key    description: test again    fn: com.gs.datastore    args:      datasource: mongo # Adding this knows which ds/model we are talking about here.      config: # Similar approach as Axios        method: <% inputs.params.entity_type %>.findMany7.6.4 com.gs.elasticgraph​The elasticgraph function allows CRUD access to elasticsearch datastore.summary: egtasks:  - id: create_entity1    description: create_entity1    fn: com.gs.elasticgraph    args:      datasource: elasticgraph1      data:        index: <% inputs.params.entity_type + 's' %>        type: '_doc'        body: <% inputs.body %>      config:        method: index    on_error:      continue: false7.6.5 com.gs.transform​This function allows to transform data from one format to another using coffee/js scripting.  summary: Parallel Multiplexing create loan for hdfc api calls  tasks:    - id: parallel      fn: com.gs.parallel      tasks:        - id: 1st          fn: com.gs.return          args: |            'parallel task1'        - id: 2nd          fn: com.gs.return          args: |            'parallel task2'    - id: step2      fn: com.gs.transform      args:        code: 200        data: <% outputs.step1_switch.data %>7.6.6 com.gs.series​control flow functionExecutes the tasks in series.By default every top level workflow executes its task in series. But when invoking subworkflows if you need, you can explicitly use series workflow. Its syntax is same as parallel.  summary: Parallel Multiplexing create loan for hdfc api calls  tasks:    - id: parallel      fn: com.gs.series      tasks:        - id: 1st          fn: com.gs.return          args: |            'parallel task1'        - id: 2nd          fn: com.gs.return          args: |            'parallel task2'    - id: step2      fn: com.gs.transform      args: |        <coffee% {          code: 200,          data: outputs['1st']        } %>7.6.7 com.gs.parallel​control flow functionExecutes the child tasks in parallel.id: return4tasks:  - id: parallel    fn: com.gs.parallel    tasks:      - id: 1st        fn: com.gs.return        args: |          'parallel task1'      - id: 2nd        fn: com.gs.return        args: |          'parallel task2'  - id: output_task    fn: com.gs.return    args: <% outputs.parallel.data %>Output[  {    "code": 200,    "success": true,    "data": "parallel task1"  },  {    "code": 200,    "success": true,    "data": "parallel task2"  }]7.6.8 com.gs.switch​control flow functionThe classic switch-case flow executionThe args of switch-flow are value and cases. value takes a coffee/js expression to be evaluated during runtime. Every case has a task associated with it. The task can invoke another function or a workflow.  summary: create loan application for lender  tasks:      - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key        description: create account in the bank        fn: com.gs.switch        value: <%inputs.headers['lender']%>        cases:          httpbin:            - id: 1st              fn: com.biz.loan_application.httpbin_create_loan_application              args: <%inputs%>7.6.9 com.gs.each_sequential​control flow functionThe classic for-each flow executionThe args is list of values in value field along with associated tasks. For each value in value tasks are executed sequentially. The final output each_sequential is the array of status of the last executed task of each iteration.  summary: For each sample  description: Here we transform the response of for loop  tasks:    - id: each_sequential_step1      description: for each      fn: com.gs.each_sequential      value: [1, 2, 3, 4]      tasks:        - id: each_task1          fn: com.gs.transform          args: <% 'each_task1 ' + task_value %>    - id: each_sequential_step2      description: return the response      fn: com.gs.transform      args: <% outputs.each_sequential_step1 %>on_error handling
You can add on_error at task level as well as at each_sequential loop level.See the below example,If a task gets failed for any task_value then control goes to on_error defined at task level. On continue false, it breaks the loop else it continues the next tasks.If all the tasks are failed in loop then the control goes to on_error defined at loop level.noteon_error at loop level only gets executed when all the tasks are failed. If even one task gets successful then it won't get executed.  summary: For each sample  description: Here we transform the response of for loop  tasks:    - id: each_sequential_step1      description: for each      fn: com.gs.each_sequential      value: [1, 2, 3, 4]      tasks:        - id: each_task1          fn: com.gs.transform          args: <% 'each_task1 ' + task_value %>          on_error: # on_error at task level            continue: false            response: <%Coffee/JS expression%> | String      on_error: # on_error at loop level        continue: true        response: <%Coffee/JS expression%> | String    - id: each_sequential_step2      description: return the response      fn: com.gs.transform      args: <% outputs.each_sequential_step1 %>7.6.10 com.gs.each_parallel​The args is list of values in value field along with associated tasks. For each value in value tasks are executed in parallel. The final output each_parallel is the array of status of the last executed task of each iteration.  summary: For each sample  description: Here we transform the response of for loop  tasks:    - id: each_parallel_step1      description: for each      fn: com.gs.each_parallel      value: [1, 2, 3, 4]      tasks:        - id: each_task1          fn: com.gs.transform          args: <% 'each_task1 ' + task_value %>    - id: each_parallel_step2      description: return the response      fn: com.gs.transform      args: <% outputs.each_parallel_step1 %>on_error handling
You can add on_error at task level as well as at each_parallel loop level.See the below example,If a task gets failed for any task_value then control goes to on_error defined at task level. On continue false, it breaks the execution for the next tasks in tasks for current task_value in value list. For example, in the below workflow, if each_task1 step of task_value 1 gets failed then each_task2 will not get executed on continue false.If all the tasks are failed in loop then the control goes to on_error defined at loop level.noteon_error at loop level only gets executed when all the tasks are failed. If even one task gets successful then it won't get executed.  summary: For each sample  description: Here we transform the response of for loop  tasks:    - id: each_parallel_step1      description: for each      fn: com.gs.each_parallel      value: [1, 2, 3, 4]      tasks:        - id: each_task1          fn: com.gs.transform          args: <% 'each_task1 ' + task_value %>          on_error: # on_error at task level            continue: false            response: <%Coffee/JS expression%> | String        - id: each_task2          fn: com.gs.transform          args: <% 'each_task2 ' + task_value %>      on_error: # on_error at loop level        continue: true        response: <%Coffee/JS expression%> | String    - id: each_parallel_step2      description: return the response      fn: com.gs.transform      args: <% outputs.each_parallel_step1 %>7.6.11 com.gs.return​Return StatementIn typical scenarios, the "return" statement will terminate a workflow. However, when the "return" statement is used within a parallel function, it won't immediately exit the workflow. Instead, it will wait until all the child tasks within the parallel function have completed before exiting the workflow.Checkout return functionality in com.gs.parallelIt returns from the current function to the function caller. The function stops executing when the return statement is called.Example summary: Returning hello worldtasks:  - id: return_hello_word    fn: com.gs.return    args: 'Hello'  - id: return_with_status    fn: com.gs.transform     args: <% outputs.return_hello_word.data + inputs.query.word %>OutputHello7.6.12 com.gs.log​It logs the intermediate inputs/outputs during the workflow execution in pino logging format. The args are level and data. level takes any value from the Pino log levels and data takes a coffee/js expression to be evaluated during runtime or anything (like string, number, etc.) which you want to get logged during the workflow execution.  summary: Summing x + y  description: Here we sum two hardcoded x and y values. Feel free to try using API inputs from body or params!  tasks:    - id: sum_step1      description: add two numbers      fn: com.jfs.sum      args:        x: 1        y: 2    - id: sum_step2      description: log the output in logs      fn: com.gs.log      args:        level: info # log levels: info, debug, error, warn, fatal, silent, trace        data: <% outputs.sum_step1 %>    - id: sum_step3      description: return the response      fn: com.gs.transform      args: <% outputs.sum_step1 %>7.6.13 com.gs.dynamic_fn​It executes the workflow whose name is dynamically returned as the output of its task list. The tasks of this function should return a string output which will be the name of the workflow to be executed. Event DSL '/sum.http.get':  fn: com.jfs.sum_dynamic  summary: A workflow to sum x and y  description: This workflow sums two integers  params:    - name: x      in: query      required: true      allow_empty_value: false      schema:        type: string    - name: y      in: query      required: true      allow_empty_value: false      schema:        type: string com.jfs.sum_dynamic.yaml summary: Dynamic function to call com.jfs.sum_workflow.yamldescription: This function dynamically is taking workflow name and executing it at the runtime.tasks:  - id: sum_dynamic_step1    description: add two numbers    fn: com.gs.dynamic_fn    tasks: # the tasks should return a string value which will the name of the workflow to be executed.    # For example, in below task list, final workflow name will be `com.jfs.sum_workflow`      - id: get_wf_name_step1        fn: com.gs.transform        args: com.jfs.sum_workflow      - id: get_wf_name_step2 # this task is returning a workflow name dynamically        fn: com.gs.transform        args: <% outputs.get_wf_name_step1.data %> com.jfs.sum_workflow.yaml summary: Summing x + ydescription: Here we sum two hardcoded x and y values. Feel free to try using API inputs from body or params!tasks:  - id: sum_step1    description: add two numbers    fn: com.gs.return    args: |     <%       +inputs.query.x + +inputs.query.y     %>7.6.14 com.gs.aws​Interacts with AWS to use its various services and methods. params is the list of params to the AWS service methods. We are using AWS v3 style services.Please refer AWS S3 for AWS S3 methods.summary: upload s3tasks:  - id: step1    description: upload s3    fn: com.gs.aws    args:      datasource: aws_s3      params:        - Bucket: 'godspeedbucket'          Key: 'file4.yml'          Body: <% fs.createReadStream(inputs.files[0].tempFilePath) %>      config:        service: S3        method: putObject7.6.15 com.gs.redis​Developer can read / write to redis datasource using standard redis client functions.summary: demonstration of redis functionsid: accessing_redistasks:  - id: store_value_to_key    description: Writing user info in redis with key user    fn: com.gs.redis    args:      config:        method: set      data:        key: user        value: Adam  - id: retrieve_user_set_in_previous_task    description: Retriving user from redis    fn: com.gs.redis    args:      config:        method: get      data:        key: user7.6.16 com.gs.if, com.gs.elif, com.gs.else​control flow functionThe classic if-else flow executionThe args are condition and tasks. condition takes a coffee/js expression to be evaluated during runtime. The tasks can invoke another function or a workflow.summary: Returning hello worldtasks:  - id: if    fn: com.gs.if    condition: <% inputs.query.status == 'Hello' %>    tasks:      - id: step1        description: Return hello world        fn: com.gs.return        args: 'Hello!'  - id: elif1    description: Return hello world    fn: com.gs.elif    condition: <% inputs.query.status == 'Hell' %>    tasks:      - id: step2        description: Return hello world        fn: com.gs.return        args: 'Hell!'  - id: elif2    description: Return hello world    fn: com.gs.elif    condition: <% inputs.query.status == 'Hel' %>    tasks:      - id: step3        description: Return hello world        fn: com.gs.return        args: 'Hel!'  - id: else    description: Return hello world    fn: com.gs.else    tasks:      - id: step4        description: Return hello world        fn: com.gs.return        args: 'Hi!'7.7 Writing custom JS/TS workflows​Godspeed allows developers to write js/ts workflows.7.7.1 Executing a JS/TS Workflow within a YAML Workflow:​Developer can write functions in JS/TS and kept in src/functions folder at a path, which becomes its fully qualified name. Once it is written, the function can be invoked from within any workflow or sub-workflow, with its fully qualified name and argument structure.  summary: Custom workflow invocation  id: custom_function  tasks:    - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: custom_fn      fn: com.biz.custom_function # Can be JS/TS workflow in src/com/xyz directory with filename being custom.{js|ts}      args:        arg1: 'hello world'        arg2: 'hello again'7.7.2 Executing JS/TS workflow directly from event:​Developer can call JS/TS workflows directly from any event. Check out below event and workflow example for better understanding.Event: (src/events/mongo/create.yaml)​/mongo/category.http.post:  summary: Create a new Category  description: Create Category from database  fn: com.jfs.create # calling js workflow in src/functions/com/jfs folder.  body:    content:      application/json:        schema:          $ref: '#/definitions/mongo/Category'  responses:    content:      application/json:        schema:          type: objectJS Workflow: (src/functions/com/jfs/create.js)​In this JavaScript/TypeScript workflow, a pivotal stage is the creation of arguments encompassing the datasource, data, and configuration. These arguments are then supplied to the executeDatasource function, accompanied by the context and function     name. The workflow manages inputs, constructs appropriate arguments, and executes the 'Category.create' datasource function through executeDatasource. Ultimately, the workflow yields a GSStatus object that signals either success or failure, providing relevant details about the response or encountered error. Framework exported interfaces/functions allow developer with flexibility to write js/ts workflows while empowering them with the frameworks capabilities.CTX:​note (Every function/workflow has access to the ctx object, which is passed as an argument, and furthermore, you can access its properties by destructuring it.)what is CTX ?​CTX includes all the context specific information like tracing information, actor, environment, headers, payload, shared state (if this ctx is shared with other instruction threads, this part can be shared with them), immutable state (personal copy, personal view, for concurrency)Inputs:​Inputs Provide you all the Information you passed to event like headers, params, query params etc.  const {inputs} = ctx;  inputs.body = inputs.data.body;Outputs:​To access outputs of tasks executed before the current task, developer can destruct ctx object just like how inputs and datasources.If we have more then one task, we can access first task outputs in second task with Outputs object. we should access first task output by useing it's id.  const {outputs} = ctx;  const firstTaskOutput = outputs[firstTaskId]config:​you can access any information of config with ctx.    const { config } = ctx;    const mongoConnectionString = config.MONGO_URL;noteEvery workflow response should be in GSStatus. it has the below properties.GSStatus Properties :​    success: boolean;    code?: number;    message?: string;    data?: any;    headers?: {        [key: string]: any;    };const { GSStatus, executeDatasource } = require('#core/interfaces');module.exports = async (ctx, fn) => {  const { inputs } = ctx;  try {    inputs.body = inputs.data.body;    let args = {      datasource: 'mongo',      data: { data: inputs.body },      config: { method: 'Category.create' },    };    const responseData = await executeDatasource(      ctx,      fn['com.gs.datastore'],      args,    );    // return GSStatus response from a workflow    return new GSStatus(true, 200, undefined, responseData, undefined);  } catch (error) {    return new GSStatus(false, 500, undefined, error, undefined);  }};module.exports.id = 'main';In JS/TS workflows, we can utilize fn to access YAML workflows. In the example below, there is a workflow named create.yaml located at the path src/functions/com/biz/mongo/category/create.yaml. When the API is called, this JavaScript workflow is triggered, obtaining the response from the create.yaml workflow and returning it.const { GSStatus, executeDatasource } = require('#core/interfaces');module.exports = async (ctx, fn) => {  const { inputs, datasources } = ctx;  try {    inputs.body = inputs.data.body;    const responseData =  await fn['com.biz.mongo.category.create'](ctx)    return new GSStatus(true, 200, undefined, responseData, undefined);  } catch (error) {    return new GSStatus(false, 500, undefined, error, undefined);  }};module.exports.id = 'main';7.8 Headers defined at workflow level​Headers defined at workflow level are applicable for a single workflow only. You can find the example usage here7.9 File Upload feature​The framework provides file upload feature to upload files. Here is the sample event and workflow spec to upload any file.Event Spec/document.http.post:  fn: com.biz.documents.upload_file  id: '/sendDocuments'  summary: upload document  description: upload document on httpbin  data:    schema:      body:        required: false        content:          multipart/form-data:            schema:              type: object              properties:                fileName:                  type: string                  format: binary7.9.1 Workflow spec to upload files with same file key​  summary: upload file  id: upload_file  tasks:    - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: upload docfileuments      fn: com.gs.http      args:        datasource: httpbin        params:        file_key: files        files: <% inputs.files %>        config:          url : /v1/documents          method: post      retry:        max_attempts: 5        type: constant        interval: PT15MNoteIf file_key is same for all the files then you can use above workflow DSL. In case you have different file_keys for multiple files then you can directly use <% inputs.file_obj %> as given in the below section 6.9.27.9.2 Workflow spec to upload multiple files with different file keys​summary: upload multiple documentstasks:    - id: upload_multiple_files_step1      description: upload multiple documents      fn: com.gs.http      args:        datasource: httpbin        data: <% inputs.body %>        files: <% inputs.file_obj %>        config:          url : /anything          method: post7.9.3 Workflow spec to upload file directly from URL​summary: upload document from urltasks:  - id: upload_url_step1    description: upload document from url    fn: com.gs.http    args:      datasource: httpbin      data: <% inputs.body %>      files:        sample:          url: https://s3.ap-south-1.amazonaws.com/sample.pdf          method: get      config:        url : /anything        method: post        headers:           Content-Type: 'multipart/form-data'Edit this pagePreviousEventsNext8.1 Introduction7.1 The structure of workflows7.2 The tasks within workflowsThe output of task & external functionExample of multiple task with arguments7.3 Location and fully qualified name (id) of workflows and functions7.4 Referencing a workflow within an event or another workflow7.5 Use of Coffee/JS for scriptingDefine language at global levelDefine language at workflow levelBuilt-in Javascript modules7.6 Inbuilt functions7.6.1 com.gs.http7.6.2 com.gs.kafka7.6.3 com.gs.datastore7.6.4 com.gs.elasticgraph7.6.5 com.gs.transform7.6.6 com.gs.series7.6.7 com.gs.parallel7.6.8 com.gs.switch7.6.9 com.gs.each_sequential7.6.10 com.gs.each_parallel7.6.11 com.gs.return7.6.12 com.gs.log7.6.13 com.gs.dynamic_fn7.6.14 com.gs.aws7.6.15 com.gs.redis7.6.16 com.gs.if, com.gs.elif, com.gs.else7.7 Writing custom JS/TS workflows7.7.1 Executing a JS/TS Workflow within a YAML Workflow:7.7.2 Executing JS/TS workflow directly from event:CTX:7.8 Headers defined at workflow level7.9 File Upload feature7.9.1 Workflow spec to upload files with same file key7.9.2 Workflow spec to upload multiple files with different file keys7.9.3 Workflow spec to upload file directly from URLForumDiscordGithubTwitterLinkedIn








Workflows | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).7. WorkflowsVersion: v1On this pageWorkflowsWorkflows is where the actual computation and flow orchestration happens. The framework supports a YAML based DSL to write workflows and tasks containing the business logic. These workflows can be attached to the events as their handlers, or called from within another workflow.The framework exposes CoffeeScript/JS based expressions for evaluation of dynamic variables or transformation of data from inputs of event, or outputs of previous tasks.Default language for transformations (coffee/js) can be configured in configuration7.1 The structure of workflows​A workflow has the following attributessummary - the titledescription - more detailsid - Recommended for better logging visibilityon_error - Default error handling if any tasks fails. tasks - the tasks (workflows or sub-workflows) to be run in series (sequence, or one by one). The tasks invoke other workflows written in YAML or JS/TS. Other languages support is planned.summary: Hello worlddescription: Hello world example which invokes the com.gs.return workflowid: hello_world # needed for better logging visibilityon_error:  continue: false  log_attributes:  # You can add specific log attributes when an error happens in a task.        error_message: <% outputs.transform_error.message %>        error_type: 'your custom error type'  response:    success: false    code: 500    data: "Default error"tasks: # tasks to be run in sequence (default is sequence)  - id: step1 ## id of this task. Its output will be accessible  # to subsequent tasks at `outputs.step1_switch` location. Like in step2 below.    fn: com.gs.return    args: 'Hello World!' # com.gs.return takes its return value as `args`. Hence the args key.7.2 The tasks within workflows​A workflow has one or more tasks associated with it.
A task has the following attributesid - Needed for better logging visibility. It is compulsory for a task. Importantly, this is also used to access the output of this task in subsequent tasks in the outputs.{task_id} path, as shown in example below.summary - the titledescription - more detailsfn - The handler to be run in this task. It can be one of the framework functions, control functions (like parallel, sequential, switch), developer written functions, or another workflow.You can also use scripting in dynamic evaluation of a function name as given in below example. Refer Coffee/JS scripting for more information.summary: Call an API and transform thetasks:    - id: transform_fn_step1      description: find fn name      fn: com.gs.transform      args: |        <js%          if (inputs.body.fn == 'sum') {            return 'com.jfs.sum_workflow'          } else {            return 'com.jfs.helloworld'          }        %>    - id: call_fn_step2      description: call fn returned in transform_fn_step1      fn: <% outputs.transform_fn_step1.data %>      args:        name: <% inputs.body.name %>args - Every handler fn has its own argument structure, which is kept in the args key. For example,  id: httpbin_step1  fn: com.gs.http  args:    datasource: httpbin    config:      url : /v1/loan-application/<% inputs.params.lender_loan_application_id %>/agreement/esign/initiate      method: post      headers: <% inputs.headers %>on_error - What to do if this task fails?  on_error: #You can find sample usage of this in the examples below. Just search on_error in this page.    continue: false # Whether the next task should be executed, in case this task fails. by default continue is true.    response: <%Coffee/JS expression%> | String # If specified, the output of `response` is returned as the output of this task. If not specified, the error output is the default output of the failed task.    log_attributes:  # You can add specific log attributes when an error happens in a task.      error_message: <% outputs.transform_error.message %>      error_type: 'your custom error type'     tasks: # If specified, the tasks are executed in series/sequence. The output of the last task in these tasks is the default output of the failed task.      - id: transform_error        fn: com.gs.transform        args: <% outputs.httpbin_step1 %>      - id: publish_error        fn: com.gs.kafka        args:          datasource: kafka1          data:            value: <% outputs.transform_error.message %>          config:            topic: publish-producer1The only exception to this is control functions like series, parallel, switch, which don't take the args, for the sake of more readability.retry - Retry logic helps to handle transient failures, internal server errors, and network errors with support for constant, exponential and random types. Currently applied only for com.gs.http workflow.  retry:    max_attempts: 5    type: constant    interval: PT15m  retry:    max_attempts: 5    type: exponential    interval: PT15s  retry:    max_attempts: 5    type: random    min_interval: PT5s    max_interval: PT10sThe output of task & external function​The output of every task and function can be expected in the following format within other tasksuccess: true/false. Default value is truecode:  standard HTTP response codes[1xx, 2xx, 3xx, 4xx, 5xx] Default value is 200message: any string explaining the response. Optionaldata: the actual data returned from the task/function. OptionalNoteIf a task or external JS function returns a value which is not in this JSON structure then framework assumes the output is the data itself & wraps it in this JSON structure with default values.The output of any previously executed task is accesible in following manner outputs.step1.codeExample of multiple task with arguments​summary: Workflow with switch-case and transform taskid: example_switch_functionality_iddescription: |  Run two tasks in series. Both take different arguments. First one is switch case task.  Second is transform task which consumes the output of step1 and shapes the final output of this workflow.tasks: # tasks to be run in sequence (default is sequence)  - id: step1_switch ## id of this switch task. Its output will be accessible    # to subsequent tasks at `outputs.step1_switch` location. Like in step2 below.    fn: com.gs.switch # Switch workflow takes `value` and `cases` as arguments. The cases object specifies another task for every case.    value: <%inputs.body.condition%> # Evaluation of dynamic values happens via <% %>    cases:      FIRST:        id: 1st        fn: com.gs.return        args: "'case - 1'"      SECOND:        id: 2nd        fn: com.gs.return        args: "'case - 2'"      THIRD:        id: 3rd        fn: com.gs.return        args: "'case - 3'"    defaults:      id: default      fn: com.gs.return      args: <%inputs.body.default_return_val%> #coffee/js script for dyanmic evaluation. Wrapped in <% %>. Same as that used elsewhere in workflows for dynamic calculations and variable substitutions. For ex. as used in com.gs.transform and com.gs.return  - id: step2    fn: com.gs.transform    args: | #coffee for dyanmic evaluation. Wrapped in <% %>        <coffee% {          code: 200,              data: outputs['1st']        } %>7.3 Location and fully qualified name (id) of workflows and functions​All the workflows and functions are to be kept in the src/functions folder. Their directory tree path, followed by the file name becomes the workflow's fully qualified name or id, by which it can be referenced in the events or within other workflows.The JS function shown below will be available in workflows under the F.Q.N. com.biz.custom_function. Similarly, com.biz.create_hdfc_account, com.biz.create_parallel etc. are accessible as handlers from within other workflow tasks or events. 7.4 Referencing a workflow within an event or another workflow​A workflow task references and invokes other workflows written in either YAML or JS/TS, via the fn key. In future, other languages will also be supported.
An event definition references the handler yaml workflows by their fully qualified name, via the same fn key.7.5 Use of Coffee/JS for scripting​The framework provides coffee/js forTransformations in com.gs.transform and com.gs.returnDynamic evaluation or workflow or task variables, event variables, datasource variables.You will find its code in <% %> within various examples in this page below.Define language at global level​Default language for transformations (coffee/js) is configured in static configurationDefine language at workflow level​Global configuration for language is overridden by defining specific language inside <coffee/js% %>. For example,    - id: httpbinCof_step2      fn: com.gs.transform      args: |          <coffee% if outputs.httpbinCof_step1.data.json.code == 200 then {              code: 200,              success: true,              data: outputs.httpbinCof_step1.data.json,              headers: outputs.httpbinCof_step1.data.headers          } else {              code: 500,              success: false,              message: 'error in httpbinCof_step1'          } %>    - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: upload documents      fn: com.gs.http      args:        datasource: httpbin        params:        data: |          <js% {            [inputs.body.entity_type + 'id']: inputs.body.entity_id,            _.omit(inputs.body, ['entity_type', 'entity_id'])}          %>Built-in Javascript modules​You can use build-in javascript modules in inline scripting. Only synchronous methods of build-in modules are allowed in inline scripting. For example,summary: upload s3tasks:  - id: step1    description: upload s3    fn: com.gs.aws    args:      datasource: aws_s3      params:  # fs is used directly in scripting in Body        - Bucket: 'godspeedbucket'          Key: 'file4.yml'          Body: <% fs.createReadStream(inputs.files[0].tempFilePath) %>      config:        service: S3        method: putObject7.6 Inbuilt functions​The framework provides the following inbuilt functions7.6.1 com.gs.http​Send HTTP events to other APIs in Axios compatible format.Example 1  summary: agreement esign  id: agreement_esign  tasks:    - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: agreement esign      fn: com.gs.http      params: # query params to be sent in the request        id: 123      args:        datasource: httpbin        config:          url : /v1/loan-application/<% inputs.params.lender_loan_application_id %>/agreement/esign/initiate          method: post      retry:        max_attempts: 5        type: constant        interval: PT15M      on_error:        continue: true    - id: step2      fn: com.gs.transform      args: |          <%if outputs.step1.data.success then outputs.step1.data else {              code: outputs.step1.code,              success : false,              data: {                error_data: outputs.step1.data['error'],                uuid: outputs.step1.data.uuid,                status_code_error: outputs.step1.data.status_code_error,                event: outputs.step1.data.event              }          }%>Example 2  summary: upload documents  id: upload_documents  tasks:    - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: upload documents      fn: com.gs.http      args:        datasource: httpbin        params:        data: |          <js% {            [inputs.body.entity_type + 'id']: inputs.body.entity_id,            _.omit(inputs.body, ['entity_type', 'entity_id'])}          %>        file_key: files        files: <% inputs.files %>        config:          url : /v1/documents          method: post      retry:        max_attempts: 5        type: constant        interval: PT15M      on_error:        continue: false        response: <%'Some error happened in saving' + inputs.body.entity_type%>    - id: step2      fn: com.gs.transform      args: <% delete outputs.step1.headers; outputs.step1 %>7.6.2 com.gs.kafka​Publish events on Kafka.  summary: Publishing incoming event data to a Kafka topic  id: push_to_kafka  tasks:    - id: step1      summary: Publish an event with input event's data, adding to_process = true      fn: com.gs.kafka      args: # similar to Axios format        datasource: kafka1        config:          method: publish          topic: kyc_initiate_recieved          group_id: kyc_domain        data: # Refer https://kafka.js.org/docs/producing#message-structure for information on data attributes.          value: <% inputs %> # Your message content. Evaluation of dynamic values happens via <% %>. The type of scripting is coffee.          key: # Optional - Used for partitioning.          partition: # Optional - Which partition to send the message to.          timestamp: # Optional - The timestamp of when the message was created.          headers: # Optional - Metadata to associate with your message.Refer https://kafka.js.org/docs/producing#message-structure for information on data attributes.7.6.3 com.gs.datastore​The datastore function allows CRUD access to any supported datastore in a format extending Prisma API.summary: Create and read datatasks:  - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key    description: Create entity from REST input data (POST request)    fn: com.gs.datastore    args:      datasource: mongo # Which ds to use.      data: <% inputs.body + {extra_field: its_value} %>      config:        method: <% inputs.params.entity_type %>.create  - id: step2 # the response of this will be accessible within the parent step key, under the step1 sub key    description: test again    fn: com.gs.datastore    args:      datasource: mongo # Adding this knows which ds/model we are talking about here.      config: # Similar approach as Axios        method: <% inputs.params.entity_type %>.findMany7.6.4 com.gs.elasticgraph​The elasticgraph function allows CRUD access to elasticsearch datastore.summary: egtasks:  - id: create_entity1    description: create_entity1    fn: com.gs.elasticgraph    args:      datasource: elasticgraph1      data:        index: <% inputs.params.entity_type + 's' %>        type: '_doc'        body: <% inputs.body %>      config:        method: index    on_error:      continue: false7.6.5 com.gs.transform​This function allows to transform data from one format to another using coffee/js scripting.  summary: Parallel Multiplexing create loan for hdfc api calls  tasks:    - id: parallel      fn: com.gs.parallel      tasks:        - id: 1st          fn: com.gs.return          args: |            'parallel task1'        - id: 2nd          fn: com.gs.return          args: |            'parallel task2'    - id: step2      fn: com.gs.transform      args:        code: 200        data: <% outputs.step1_switch.data %>7.6.6 com.gs.series​control flow functionExecutes the tasks in series.By default every top level workflow executes its task in series. But when invoking subworkflows if you need, you can explicitly use series workflow. Its syntax is same as parallel.  summary: Parallel Multiplexing create loan for hdfc api calls  tasks:    - id: parallel      fn: com.gs.series      tasks:        - id: 1st          fn: com.gs.return          args: |            'parallel task1'        - id: 2nd          fn: com.gs.return          args: |            'parallel task2'    - id: step2      fn: com.gs.transform      args: |        <coffee% {          code: 200,          data: outputs['1st']        } %>7.6.7 com.gs.parallel​control flow functionExecutes the child tasks in parallel.id: return4tasks:  - id: parallel    fn: com.gs.parallel    tasks:      - id: 1st        fn: com.gs.return        args: |          'parallel task1'      - id: 2nd        fn: com.gs.return        args: |          'parallel task2'  - id: output_task    fn: com.gs.return    args: <% outputs.parallel.data %>Output[  {    "code": 200,    "success": true,    "data": "parallel task1"  },  {    "code": 200,    "success": true,    "data": "parallel task2"  }]7.6.8 com.gs.switch​control flow functionThe classic switch-case flow executionThe args of switch-flow are value and cases. value takes a coffee/js expression to be evaluated during runtime. Every case has a task associated with it. The task can invoke another function or a workflow.  summary: create loan application for lender  tasks:      - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key        description: create account in the bank        fn: com.gs.switch        value: <%inputs.headers['lender']%>        cases:          httpbin:            - id: 1st              fn: com.biz.loan_application.httpbin_create_loan_application              args: <%inputs%>7.6.9 com.gs.each_sequential​control flow functionThe classic for-each flow executionThe args is list of values in value field along with associated tasks. For each value in value tasks are executed sequentially. The final output each_sequential is the array of status of the last executed task of each iteration.  summary: For each sample  description: Here we transform the response of for loop  tasks:    - id: each_sequential_step1      description: for each      fn: com.gs.each_sequential      value: [1, 2, 3, 4]      tasks:        - id: each_task1          fn: com.gs.transform          args: <% 'each_task1 ' + task_value %>    - id: each_sequential_step2      description: return the response      fn: com.gs.transform      args: <% outputs.each_sequential_step1 %>on_error handling
You can add on_error at task level as well as at each_sequential loop level.See the below example,If a task gets failed for any task_value then control goes to on_error defined at task level. On continue false, it breaks the loop else it continues the next tasks.If all the tasks are failed in loop then the control goes to on_error defined at loop level.noteon_error at loop level only gets executed when all the tasks are failed. If even one task gets successful then it won't get executed.  summary: For each sample  description: Here we transform the response of for loop  tasks:    - id: each_sequential_step1      description: for each      fn: com.gs.each_sequential      value: [1, 2, 3, 4]      tasks:        - id: each_task1          fn: com.gs.transform          args: <% 'each_task1 ' + task_value %>          on_error: # on_error at task level            continue: false            response: <%Coffee/JS expression%> | String      on_error: # on_error at loop level        continue: true        response: <%Coffee/JS expression%> | String    - id: each_sequential_step2      description: return the response      fn: com.gs.transform      args: <% outputs.each_sequential_step1 %>7.6.10 com.gs.each_parallel​The args is list of values in value field along with associated tasks. For each value in value tasks are executed in parallel. The final output each_parallel is the array of status of the last executed task of each iteration.  summary: For each sample  description: Here we transform the response of for loop  tasks:    - id: each_parallel_step1      description: for each      fn: com.gs.each_parallel      value: [1, 2, 3, 4]      tasks:        - id: each_task1          fn: com.gs.transform          args: <% 'each_task1 ' + task_value %>    - id: each_parallel_step2      description: return the response      fn: com.gs.transform      args: <% outputs.each_parallel_step1 %>on_error handling
You can add on_error at task level as well as at each_parallel loop level.See the below example,If a task gets failed for any task_value then control goes to on_error defined at task level. On continue false, it breaks the execution for the next tasks in tasks for current task_value in value list. For example, in the below workflow, if each_task1 step of task_value 1 gets failed then each_task2 will not get executed on continue false.If all the tasks are failed in loop then the control goes to on_error defined at loop level.noteon_error at loop level only gets executed when all the tasks are failed. If even one task gets successful then it won't get executed.  summary: For each sample  description: Here we transform the response of for loop  tasks:    - id: each_parallel_step1      description: for each      fn: com.gs.each_parallel      value: [1, 2, 3, 4]      tasks:        - id: each_task1          fn: com.gs.transform          args: <% 'each_task1 ' + task_value %>          on_error: # on_error at task level            continue: false            response: <%Coffee/JS expression%> | String        - id: each_task2          fn: com.gs.transform          args: <% 'each_task2 ' + task_value %>      on_error: # on_error at loop level        continue: true        response: <%Coffee/JS expression%> | String    - id: each_parallel_step2      description: return the response      fn: com.gs.transform      args: <% outputs.each_parallel_step1 %>7.6.11 com.gs.return​Return StatementIn typical scenarios, the "return" statement will terminate a workflow. However, when the "return" statement is used within a parallel function, it won't immediately exit the workflow. Instead, it will wait until all the child tasks within the parallel function have completed before exiting the workflow.Checkout return functionality in com.gs.parallelIt returns from the current function to the function caller. The function stops executing when the return statement is called.Example summary: Returning hello worldtasks:  - id: return_hello_word    fn: com.gs.return    args: 'Hello'  - id: return_with_status    fn: com.gs.transform     args: <% outputs.return_hello_word.data + inputs.query.word %>OutputHello7.6.12 com.gs.log​It logs the intermediate inputs/outputs during the workflow execution in pino logging format. The args are level and data. level takes any value from the Pino log levels and data takes a coffee/js expression to be evaluated during runtime or anything (like string, number, etc.) which you want to get logged during the workflow execution.  summary: Summing x + y  description: Here we sum two hardcoded x and y values. Feel free to try using API inputs from body or params!  tasks:    - id: sum_step1      description: add two numbers      fn: com.jfs.sum      args:        x: 1        y: 2    - id: sum_step2      description: log the output in logs      fn: com.gs.log      args:        level: info # log levels: info, debug, error, warn, fatal, silent, trace        data: <% outputs.sum_step1 %>    - id: sum_step3      description: return the response      fn: com.gs.transform      args: <% outputs.sum_step1 %>7.6.13 com.gs.dynamic_fn​It executes the workflow whose name is dynamically returned as the output of its task list. The tasks of this function should return a string output which will be the name of the workflow to be executed. Event DSL '/sum.http.get':  fn: com.jfs.sum_dynamic  summary: A workflow to sum x and y  description: This workflow sums two integers  params:    - name: x      in: query      required: true      allow_empty_value: false      schema:        type: string    - name: y      in: query      required: true      allow_empty_value: false      schema:        type: string com.jfs.sum_dynamic.yaml summary: Dynamic function to call com.jfs.sum_workflow.yamldescription: This function dynamically is taking workflow name and executing it at the runtime.tasks:  - id: sum_dynamic_step1    description: add two numbers    fn: com.gs.dynamic_fn    tasks: # the tasks should return a string value which will the name of the workflow to be executed.    # For example, in below task list, final workflow name will be `com.jfs.sum_workflow`      - id: get_wf_name_step1        fn: com.gs.transform        args: com.jfs.sum_workflow      - id: get_wf_name_step2 # this task is returning a workflow name dynamically        fn: com.gs.transform        args: <% outputs.get_wf_name_step1.data %> com.jfs.sum_workflow.yaml summary: Summing x + ydescription: Here we sum two hardcoded x and y values. Feel free to try using API inputs from body or params!tasks:  - id: sum_step1    description: add two numbers    fn: com.gs.return    args: |     <%       +inputs.query.x + +inputs.query.y     %>7.6.14 com.gs.aws​Interacts with AWS to use its various services and methods. params is the list of params to the AWS service methods. We are using AWS v3 style services.Please refer AWS S3 for AWS S3 methods.summary: upload s3tasks:  - id: step1    description: upload s3    fn: com.gs.aws    args:      datasource: aws_s3      params:        - Bucket: 'godspeedbucket'          Key: 'file4.yml'          Body: <% fs.createReadStream(inputs.files[0].tempFilePath) %>      config:        service: S3        method: putObject7.6.15 com.gs.redis​Developer can read / write to redis datasource using standard redis client functions.summary: demonstration of redis functionsid: accessing_redistasks:  - id: store_value_to_key    description: Writing user info in redis with key user    fn: com.gs.redis    args:      config:        method: set      data:        key: user        value: Adam  - id: retrieve_user_set_in_previous_task    description: Retriving user from redis    fn: com.gs.redis    args:      config:        method: get      data:        key: user7.6.16 com.gs.if, com.gs.elif, com.gs.else​control flow functionThe classic if-else flow executionThe args are condition and tasks. condition takes a coffee/js expression to be evaluated during runtime. The tasks can invoke another function or a workflow.summary: Returning hello worldtasks:  - id: if    fn: com.gs.if    condition: <% inputs.query.status == 'Hello' %>    tasks:      - id: step1        description: Return hello world        fn: com.gs.return        args: 'Hello!'  - id: elif1    description: Return hello world    fn: com.gs.elif    condition: <% inputs.query.status == 'Hell' %>    tasks:      - id: step2        description: Return hello world        fn: com.gs.return        args: 'Hell!'  - id: elif2    description: Return hello world    fn: com.gs.elif    condition: <% inputs.query.status == 'Hel' %>    tasks:      - id: step3        description: Return hello world        fn: com.gs.return        args: 'Hel!'  - id: else    description: Return hello world    fn: com.gs.else    tasks:      - id: step4        description: Return hello world        fn: com.gs.return        args: 'Hi!'7.7 Writing custom JS/TS workflows​Godspeed allows developers to write js/ts workflows.7.7.1 Executing a JS/TS Workflow within a YAML Workflow:​Developer can write functions in JS/TS and kept in src/functions folder at a path, which becomes its fully qualified name. Once it is written, the function can be invoked from within any workflow or sub-workflow, with its fully qualified name and argument structure.  summary: Custom workflow invocation  id: custom_function  tasks:    - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: custom_fn      fn: com.biz.custom_function # Can be JS/TS workflow in src/com/xyz directory with filename being custom.{js|ts}      args:        arg1: 'hello world'        arg2: 'hello again'7.7.2 Executing JS/TS workflow directly from event:​Developer can call JS/TS workflows directly from any event. Check out below event and workflow example for better understanding.Event: (src/events/mongo/create.yaml)​/mongo/category.http.post:  summary: Create a new Category  description: Create Category from database  fn: com.jfs.create # calling js workflow in src/functions/com/jfs folder.  body:    content:      application/json:        schema:          $ref: '#/definitions/mongo/Category'  responses:    content:      application/json:        schema:          type: objectJS Workflow: (src/functions/com/jfs/create.js)​In this JavaScript/TypeScript workflow, a pivotal stage is the creation of arguments encompassing the datasource, data, and configuration. These arguments are then supplied to the executeDatasource function, accompanied by the context and function     name. The workflow manages inputs, constructs appropriate arguments, and executes the 'Category.create' datasource function through executeDatasource. Ultimately, the workflow yields a GSStatus object that signals either success or failure, providing relevant details about the response or encountered error. Framework exported interfaces/functions allow developer with flexibility to write js/ts workflows while empowering them with the frameworks capabilities.CTX:​note (Every function/workflow has access to the ctx object, which is passed as an argument, and furthermore, you can access its properties by destructuring it.)what is CTX ?​CTX includes all the context specific information like tracing information, actor, environment, headers, payload, shared state (if this ctx is shared with other instruction threads, this part can be shared with them), immutable state (personal copy, personal view, for concurrency)Inputs:​Inputs Provide you all the Information you passed to event like headers, params, query params etc.  const {inputs} = ctx;  inputs.body = inputs.data.body;Outputs:​To access outputs of tasks executed before the current task, developer can destruct ctx object just like how inputs and datasources.If we have more then one task, we can access first task outputs in second task with Outputs object. we should access first task output by useing it's id.  const {outputs} = ctx;  const firstTaskOutput = outputs[firstTaskId]config:​you can access any information of config with ctx.    const { config } = ctx;    const mongoConnectionString = config.MONGO_URL;noteEvery workflow response should be in GSStatus. it has the below properties.GSStatus Properties :​    success: boolean;    code?: number;    message?: string;    data?: any;    headers?: {        [key: string]: any;    };const { GSStatus, executeDatasource } = require('#core/interfaces');module.exports = async (ctx, fn) => {  const { inputs } = ctx;  try {    inputs.body = inputs.data.body;    let args = {      datasource: 'mongo',      data: { data: inputs.body },      config: { method: 'Category.create' },    };    const responseData = await executeDatasource(      ctx,      fn['com.gs.datastore'],      args,    );    // return GSStatus response from a workflow    return new GSStatus(true, 200, undefined, responseData, undefined);  } catch (error) {    return new GSStatus(false, 500, undefined, error, undefined);  }};module.exports.id = 'main';In JS/TS workflows, we can utilize fn to access YAML workflows. In the example below, there is a workflow named create.yaml located at the path src/functions/com/biz/mongo/category/create.yaml. When the API is called, this JavaScript workflow is triggered, obtaining the response from the create.yaml workflow and returning it.const { GSStatus, executeDatasource } = require('#core/interfaces');module.exports = async (ctx, fn) => {  const { inputs, datasources } = ctx;  try {    inputs.body = inputs.data.body;    const responseData =  await fn['com.biz.mongo.category.create'](ctx)    return new GSStatus(true, 200, undefined, responseData, undefined);  } catch (error) {    return new GSStatus(false, 500, undefined, error, undefined);  }};module.exports.id = 'main';7.8 Headers defined at workflow level​Headers defined at workflow level are applicable for a single workflow only. You can find the example usage here7.9 File Upload feature​The framework provides file upload feature to upload files. Here is the sample event and workflow spec to upload any file.Event Spec/document.http.post:  fn: com.biz.documents.upload_file  id: '/sendDocuments'  summary: upload document  description: upload document on httpbin  data:    schema:      body:        required: false        content:          multipart/form-data:            schema:              type: object              properties:                fileName:                  type: string                  format: binary7.9.1 Workflow spec to upload files with same file key​  summary: upload file  id: upload_file  tasks:    - id: step1 # the response of this will be accessible within the parent step key, under the step1 sub key      description: upload docfileuments      fn: com.gs.http      args:        datasource: httpbin        params:        file_key: files        files: <% inputs.files %>        config:          url : /v1/documents          method: post      retry:        max_attempts: 5        type: constant        interval: PT15MNoteIf file_key is same for all the files then you can use above workflow DSL. In case you have different file_keys for multiple files then you can directly use <% inputs.file_obj %> as given in the below section 6.9.27.9.2 Workflow spec to upload multiple files with different file keys​summary: upload multiple documentstasks:    - id: upload_multiple_files_step1      description: upload multiple documents      fn: com.gs.http      args:        datasource: httpbin        data: <% inputs.body %>        files: <% inputs.file_obj %>        config:          url : /anything          method: post7.9.3 Workflow spec to upload file directly from URL​summary: upload document from urltasks:  - id: upload_url_step1    description: upload document from url    fn: com.gs.http    args:      datasource: httpbin      data: <% inputs.body %>      files:        sample:          url: https://s3.ap-south-1.amazonaws.com/sample.pdf          method: get      config:        url : /anything        method: post        headers:           Content-Type: 'multipart/form-data'Edit this pagePreviousEventsNext8.1 Introduction7.1 The structure of workflows7.2 The tasks within workflowsThe output of task & external functionExample of multiple task with arguments7.3 Location and fully qualified name (id) of workflows and functions7.4 Referencing a workflow within an event or another workflow7.5 Use of Coffee/JS for scriptingDefine language at global levelDefine language at workflow levelBuilt-in Javascript modules7.6 Inbuilt functions7.6.1 com.gs.http7.6.2 com.gs.kafka7.6.3 com.gs.datastore7.6.4 com.gs.elasticgraph7.6.5 com.gs.transform7.6.6 com.gs.series7.6.7 com.gs.parallel7.6.8 com.gs.switch7.6.9 com.gs.each_sequential7.6.10 com.gs.each_parallel7.6.11 com.gs.return7.6.12 com.gs.log7.6.13 com.gs.dynamic_fn7.6.14 com.gs.aws7.6.15 com.gs.redis7.6.16 com.gs.if, com.gs.elif, com.gs.else7.7 Writing custom JS/TS workflows7.7.1 Executing a JS/TS Workflow within a YAML Workflow:7.7.2 Executing JS/TS workflow directly from event:CTX:7.8 Headers defined at workflow level7.9 File Upload feature7.9.1 Workflow spec to upload files with same file key7.9.2 Workflow spec to upload multiple files with different file keys7.9.3 Workflow spec to upload file directly from URLForumDiscordGithubTwitterLinkedIn








3.3.3 Static variables | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup3.1 Getting started3.2 Project structure3.3 Configuration3.3.1 Introduction3.3.2 Environment variables3.3.3 Static variables3.3.4 Custom SwaggerSpec Documentation3.4 Tests3.5 Auto watch and build3.6 Debugger in Yaml4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).3. Setup3.3 Configuration3.3.3 Static variablesVersion: v1On this pageStatic variablesThe static variables as well as their values are defined in yaml files under config/ directory. These variables can be replaced as per the business use cases. The default directory structure is given as below:├── config│   ├── default.yamlnoteAny configuration which includes secrets or passwords is recommended to be defined using environment variables only. Avoid using static variables for secrets and passwords.default.yaml​This file contains some predefined variables. Below is a sample file which defines the static variables used in Godspeed.log_level: debuglang: coffeeredact: [] # fields to hide. Sample: ['ns', 'req.headers']server_url: https://api.example.com:8443/v1/apihttpbin: # sample api datasource url  base_url: https://httpbin.orgrequest_body_limit: 50mbfile_size_limit : 50mblog_level is the minimum log level to log. Log messages with a lower limit will not get logged. The default value is 'info'.
The available levels are 'fatal', 'error', 'warn', 'info', 'debug', 'trace' or 'silent'.
lang is the language used for scripting in the workflows. The default value is 'coffee'.
The available values are 'coffee' or 'js'. Refer Coffee/JS scripting for more information.
redact is the list of fields, the values for which, you want to hide from the logs. The default value is blank. Refer Logs field masking for more information.
server_url is the custom server url which you want to use as Servers in swagger specs/auto generated documentation. Refer Custom Server URLrequest_body_limit This variable sets the limit for the request body size. It checks if config.request_body_limit is defined in the application's configuration. If it is, the value from the configuration is used; otherwise, it defaults to 50 1024  1024 bytes (50 megabytes).file_size_limit This variable sets the limit for the file size. Similar to request_body_limit, it checks if config.file_size_limit is defined in the configuration. If it is, the value from the configuration is used; otherwise, it defaults to 50  1024  1024 bytes (50 megabytes).Edit this pagePrevious3.3.2 Environment variablesNext3.3.4 Custom SwaggerSpec Documentationdefault.yamlForumDiscordGithubTwitterLinkedIn








3.3.3 Static variables | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup3.1 Getting started3.2 Project structure3.3 Configuration3.3.1 Introduction3.3.2 Environment variables3.3.3 Static variables3.3.4 Custom SwaggerSpec Documentation3.4 Tests3.5 Auto watch and build3.6 Debugger in Yaml4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).3. Setup3.3 Configuration3.3.3 Static variablesVersion: v1On this pageStatic variablesThe static variables as well as their values are defined in yaml files under config/ directory. These variables can be replaced as per the business use cases. The default directory structure is given as below:├── config│   ├── default.yamlnoteAny configuration which includes secrets or passwords is recommended to be defined using environment variables only. Avoid using static variables for secrets and passwords.default.yaml​This file contains some predefined variables. Below is a sample file which defines the static variables used in Godspeed.log_level: debuglang: coffeeredact: [] # fields to hide. Sample: ['ns', 'req.headers']server_url: https://api.example.com:8443/v1/apihttpbin: # sample api datasource url  base_url: https://httpbin.orgrequest_body_limit: 50mbfile_size_limit : 50mblog_level is the minimum log level to log. Log messages with a lower limit will not get logged. The default value is 'info'.
The available levels are 'fatal', 'error', 'warn', 'info', 'debug', 'trace' or 'silent'.
lang is the language used for scripting in the workflows. The default value is 'coffee'.
The available values are 'coffee' or 'js'. Refer Coffee/JS scripting for more information.
redact is the list of fields, the values for which, you want to hide from the logs. The default value is blank. Refer Logs field masking for more information.
server_url is the custom server url which you want to use as Servers in swagger specs/auto generated documentation. Refer Custom Server URLrequest_body_limit This variable sets the limit for the request body size. It checks if config.request_body_limit is defined in the application's configuration. If it is, the value from the configuration is used; otherwise, it defaults to 50 1024  1024 bytes (50 megabytes).file_size_limit This variable sets the limit for the file size. Similar to request_body_limit, it checks if config.file_size_limit is defined in the configuration. If it is, the value from the configuration is used; otherwise, it defaults to 50  1024  1024 bytes (50 megabytes).Edit this pagePrevious3.3.2 Environment variablesNext3.3.4 Custom SwaggerSpec Documentationdefault.yamlForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








Observability | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).13. TelemetryVersion: v1On this pageObservability13.1 Introduction​For observability, the framework supports Application Performance Monitoring(APM) abd Business Performance Monitoring(BPM) out of the box. This includes distributed trace context propagation across sync and async channels, logging and basic metrics.For the same, we are leveraging the OpenTelemetry standard and its supporting tech ecosystem. Not even a single request must go untracked!13.1.1 Architecture​Both Traces and Metrics are sent to OTEL Collector directly. Tempo is used as tracing backend for traces and Prometheus is used for metrics with Mimir as its backend.For Logs, a fluent bit daemonset is running on node, which collects logs from various applications on the node. Loki is used as logs aggregation solution.13.2 Goals​Auto application performance monitoring​No code APM across microservices, integrable with standard APM tools and logging backends, without any dev effort.Backend agnostic​Numerous open source and commercial softwares for Observability support OpenTelemetry out of the box, allowing one to switch between them if needed.Complete debuggability​Collect, correlate and debug signals across logs (events), traces and metrics, based on the request id and the attributes defined for the organization. For example, app version, function, DB query, K8s pod, domain, microservice etc.13.3 Configuration​13.3.1 OTEL exporter endpoint​Specify the IP address of your OTEL collector as env variable. Refer OTEL Exporter for more information.$ export OTEL_EXPORTER_OTLP_ENDPOINT=<IP of OTEL collector>:4317For example,export OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:431713.3.2 OTEL service name​Specify the service name by which you want to setup observability and set it as env variable. $ export OTEL_SERVICE_NAME=sample_proj1Let's assume you have setup SigNoz as the exporter then you will see something like this:


In case you have any questions, please reach out to us on our Discord channel.13.3.3 Logging​13.3.3.1 Log level​The minimum level set to log above this level. Please refer Pino log levels for more information. Set log_level in Static variables13.3.3.2 Log fields masking​If you want to hide sensitive information in logs then define the fields which need to be hidden in redact feature in Static variables. Redaction path syntax is standard JSON object lookup.
For example, config/default.yamlredact: ['a.b.c', 'a.b.*', 'req.headers']By specifying the above redaction paths, the objects which have these properties will be masked in the logs.notePlease refer Pino redaction paths for more information. Generic convention 
If you want to mask any field in the objects in all deep nesting levels then you can use **.<field_name> convention instead of specifying each path explicitly.
For example, config/default.yamlredact: ['**.mobileNumber'] By specifying the above redaction path, mobileNumber field will be redacted in logs in all nesting levels.   Sample masked logs:{"Body":"args after evaluation: step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Executing handler step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387896000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn step1 {\"name\":\"ABC\",\"gender\":\"M\",\"age\":25,\"mobileNumber\":\"*****\"}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"step1"}}{"Body":"Result of _executeFn add_mobileNumber_transformation_step2 {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387897000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"add_mobileNumber_transformation_step2"}}{"Body":"this.id: hello_world, output: {\"request_data\":{\"payload\":{\"data\":{\"body\":{\"mobileNumber\":\"*****\"}}}}}","Timestamp":"1684221387898000000","SeverityNumber":5,"SeverityText":"DEBUG","Resource":{"service.name":"unknown_service:node","host.hostname":"4030f41a75cb","process.pid":3593},"Attributes":{"event":"/helloworld.http.get","workflow_name":"helloworld","task_id":"hello_world"}}13.3.3.3 Log format​By default, the logs are dumped in OTEL Logging format when you deploy your service {"Body":"adding body schema for /upload_doc.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_multiple_docs.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"adding body schema for /upload_s3.http.post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /another_workflow post","Timestamp":"1676531763727000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}{"Body":"registering http handler /create/:entity_type post","Timestamp":"1676531763728000000","SeverityNumber":9,"SeverityText":"INFO","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{}}. . . . . . . . . . . {"Body":"args.retry {\"max_attempts\":3,\"type\":\"constant\",\"interval\":5000}","Timestamp":"1676531764656000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Result of _executeFn test_step1 {\"success\":true,\"code\":200,\"data\":{\"args\":{},\"data\":\"{\\\"data\\\":{\\\"lan\\\":\\\"12345\\\"}}\",\"files\":{},\"form\":{},\"headers\":{\"Accept\":\"application/json, text/plain, */*\",\"Content-Length\":\"24\",\"Content-Type\":\"application/json\",\"Host\":\"httpbin.org\",\"Traceparent\":\"00-a58ef2d7ff7725c39f1e058bf22fe724-2f13e28430d61bdb-01\",\"User-Agent\":\"axios/0.25.0\",\"X-Amzn-Trace-Id\":\"Root=1-63edd835-22cff8e60555fa522c8544cf\"},\"json\":{\"data\":{\"lan\":\"12345\"}},\"method\":\"POST\",\"origin\":\"180.188.224.177\",\"url\":\"https://httpbin.org/anything\"},\"message\":\"OK\",\"headers\":{\"date\":\"Thu, 16 Feb 2023 07:16:05 GMT\",\"content-type\":\"application/json\",\"content-length\":\"598\",\"connection\":\"close\",\"server\":\"gunicorn/19.9.0\",\"access-control-allow-origin\":\"*\",\"access-control-allow-credentials\":\"true\"}}","Timestamp":"1676531765810000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"}}{"Body":"Validate Response JSON Schema Success","Timestamp":"1676531765811000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"a58ef2d7ff7725c39f1e058bf22fe724","SpanId":"751bc314bb6286b4","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9537a882ae58","process.pid":61741},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""}} Dev Format 
The dev format is basically a transformation of OTEL log format to increase readability for developers. To set the dev format logs, you need to set NODE_ENV value as dev inside your environment.export NODE_ENV=devThe format is as below:datetime [SeverityText] TraceId SpanId {Attributes} BodySample Logs:16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_doc.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_multiple_docs.http.post16/02/23, 12:44:42 pm [INFO]   {} adding body schema for /upload_s3.http.post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /another_workflow post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /create/:entity_type post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /document post16/02/23, 12:44:42 pm [INFO]   {} registering http handler /fn_script post. . . . . . . . . . 16/02/23, 12:44:43 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} args.retry {"max_attempts":3,"type":"constant","interval":5000}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":"test_step1"} Result of _executeFn test_step1 {"success":true,"code":200,"data":{"args":{},"data":"{\"data\":{\"lan\":\"12345\"}}","files":{},"form":{},"headers":{"Accept":"application/json, text/plain, */*","Content-Length":"24","Content-Type":"application/json","Host":"httpbin.org","Traceparent":"00-f9f61d4940e3a8e5be8bc80faf6e36a2-f6c0a5ce67f5b07c-01","User-Agent":"axios/0.25.0","X-Amzn-Trace-Id":"Root=1-63edd7e4-0b8b6ba319833492520e6b0c"},"json":{"data":{"lan":"12345"}},"method":"POST","origin":"180.188.224.177","url":"https://httpbin.org/anything"},"message":"OK","headers":{"date":"Thu, 16 Feb 2023 07:14:44 GMT","content-type":"application/json","content-length":"598","connection":"close","server":"gunicorn/19.9.0","access-control-allow-origin":"*","access-control-allow-credentials":"true"}}16/02/23, 12:44:44 pm [INFO] f9f61d4940e3a8e5be8bc80faf6e36a2 96e746f5cbbee1ac {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","task_id":""} Validate Response JSON Schema SuccessnoteIf you set any other value in NODE_ENV then the logs are dumped in OTEL format by default.13.3.3.4 Loggin for events​You can add any custom attribute in the OTEL logs whenever any event is triggered on your service. The value for the custom identifier will be picked up from event body, params, query, or headers.   13.3.3.4.1 Custom log attributes for all events​ To enable this feature for common logging attributes across all events ,you need to specify two things: log_attributes variable as environment variable or static variable which contains custom identifiers.For example, this is the sample static configuration:log_attributes:   mobileNumber: "query?.mobileNumber"  id: "params?.id"  lan: "body?.data?.lan"  name: "headers?.name"  gender: <% mappings.Gender %>location of the identifier in the request payload. As specified in the above example, if mobileNumber is present in query params then specify query?.mobileNumber.if id is present in path params then specify params?.id.if lan is present in data field inside body then specify body?.data?.lan.if name is present in headers then specify headers?.name.if gender is present in data field inside mappings then specify <% mappings.Gender %>.notePlease make sure to add ? in case any field is optional like body?.data?.lan so that it works well with undefined values. This will add lan in the logs if it is present else it will not get added. Sample Logs Dev format21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} Processing event /test/:id.http.post21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event inputs {"baseUrl":"","body":{"data":{"lan":"12345"}},"fresh":false,"hostname":"localhost","ip":"::ffff:172.22.0.1","ips":[],"method":"POST","originalUrl":"/test/12?mobileNumber=9878987898","params":{"id":"12"},"path":"/test/12","protocol":"http","query":{"mobileNumber":"9878987898"},"route":{"path":"/test/:id","stack":[{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"},{"name":"<anonymous>","keys":[],"regexp":{"fast_star":false,"fast_slash":false},"method":"post"}],"methods":{"post":true}},"secure":false,"stale":true,"subdomains":[],"xhr":false,"headers":{"content-type":"application/json","user-agent":"PostmanRuntime/7.29.2","accept":"*/*","postman-token":"835edd29-7c36-4e11-9b79-c661bbd911b0","host":"localhost:4000","accept-encoding":"gzip, deflate, br","connection":"keep-alive","content-length":"46"},"files":[]}21/02/23, 11:54:06 am [INFO] 48c894ed7d65caa236e8cc0664ee4e5e 5af2d3d564e86fb6 {"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"} event body and eventSpec existOTEL format{"Body":"Processing event /test/:id.http.post","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event inputs {\"baseUrl\":\"\",\"body\":{\"data\":{\"lan\":\"12345\"}},\"fresh\":false,\"hostname\":\"localhost\",\"ip\":\"::ffff:172.22.0.1\",\"ips\":[],\"method\":\"POST\",\"originalUrl\":\"/test/12?mobileNumber=9878987898\",\"params\":{\"id\":\"12\"},\"path\":\"/test/12\",\"protocol\":\"http\",\"query\":{\"mobileNumber\":\"9878987898\"},\"route\":{\"path\":\"/test/:id\",\"stack\":[{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"},{\"name\":\"<anonymous>\",\"keys\":[],\"regexp\":{\"fast_star\":false,\"fast_slash\":false},\"method\":\"post\"}],\"methods\":{\"post\":true}},\"secure\":false,\"stale\":true,\"subdomains\":[],\"xhr\":false,\"headers\":{\"content-type\":\"application/json\",\"user-agent\":\"PostmanRuntime/7.29.2\",\"accept\":\"*/*\",\"postman-token\":\"9e57df7d-0a75-48b6-bc52-921bd5c045b7\",\"host\":\"localhost:4000\",\"accept-encoding\":\"gzip, deflate, br\",\"connection\":\"keep-alive\",\"content-length\":\"46\"},\"files\":[]}","Timestamp":"1676960742403000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}{"Body":"event body and eventSpec exist","Timestamp":"1676960742404000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"3b66e6f8ec6624f6467af1226503a39e","SpanId":"eb6e7d89ac381e9f","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"5252603e08be","process.pid":828},"Attributes":{"event":"/test/:id.http.post","workflow_name":"com.jfs.test","mobileNumber":"9878987898","id":"12","lan":"12345"}}13.3.3.4.2 Custom log attributes at event level​You can override log attributes at event level also. You can specify customized log attributes for specific event.noteThis will override default custom attributes as defined above 13.3.3.4.1.To enable this feature ,you need to specify:log_attributes on event level which contains custom identifiersFor example, this is the sample static configuration:log_attributes:   msgparameter:    fruit: apple  identifier: 1 Sample Logs OTEL Format{ Body: "return value [] 200 %o"    Timestamp: "1688565778237000000"    SeverityNumber: 9    SeverityText: "INFO"    TraceId: "3fba9b9bd5d10d00b1b730b74c8eba51"    SpanId: "985e8a8d6a18568b"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 13956    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "identifier": 1,      "task_id": ""    }}13.3.3.4.3 Custom on_error logging in workflow/tasks​In case you want to log specific attributes when an error happens in a task, set those values in on_error.log_attributes of that task.For ex.summary: add custom error logs on workflowid: validation_errortasks:    - id: error_transform      fn: com.biz.error_logon_error:    log_attributes:        error_type: "enter your custom error type here"        error_message: "xyz value is required" Sample logs OTEL format    {Timestamp: "1688563866502000000"    SeverityNumber: 17    SeverityText: "ERROR"    TraceId: "7563f0bd1e6c6508e58a4d1de1464635"    SpanId: "c4c65132ef79982f"    TraceFlags: "01"    Resource: {      "service.name": "unknown_service:node",      "host.hostname": "6295f63d9181",      "process.pid": 8455    }    Attributes: {      "event": "/postgres/user/search.http.post",      "workflow_name": "com.biz.postgres.user.search",      "file_name": "com.biz.postgres.user.search",      "msgparameter": {        "fruit": "apple"      },      "task_id": "",      "error": {        "error_type": "enter your custom error type here",        "error_message": "xyz value is required"      }    }}13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions​This feature enables developers to utilize a Logger Instance in custom JS or TS functions. The Logger Instance assists in logging information, warnings, and errors during the execution of the function. The feature ensures robust logging capabilities and facilitates debugging and monitoring of the application. Sample code module.exports = function(args, {childLogger, promClient, tracer}) {    for (let i = 0; i < 1000; i++) {        childLogger.error("print log i: %s", i);    }    return "OK"} Function Parameters:  args:  Represents the arguments passed to the custom JS/TS function. Developers can use this parameter to accept input data and perform necessary computations within the function. {childLogger, promClient, tracer}:  This object contains three properties, which are as follows: childLogger:  A Logger Instance that developers can use to log messages, errors, and other relevant information during the function's execution. promClient:  A library that provides a Prometheus client for collecting metrics and exposing them to Prometheus monitoring system.tracer:  A library used for distributed tracing, which can be beneficial in identifying and resolving issues across microservices.13.4 Custom metrics, traces and logs (BPM)​Custom metrics, traces and logs can be added in the workflow DSL at each task level then these will be available out of the box along with APM.13.4.1 DSL spec for custom metrics​refer https://github.com/siimon/prom-client​metrics:- name: metric_name  type: counter|gauge|histogram|summary  labels:     label1: val1    label2: val2            # following functions depending on the metric type and all of them could be scripts, can use inputs/outputs  inc: 10  dec: 10  set: 100  observe: 2000  timer: true|false(boolean) starts at the beginning of workflow/task and ends at the end of workflow/taskExample spec​In the following example, we are using two custom metrics: httpbin_calls_total: counter type metric, counter is incremented by 1.httpbin_calls_duration: histogram type metric, timer is set to true to record duration.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http               metrics:        - name: httpbin_calls_total          help: 'httpbin_calls_total counter of httpbin requests labeled with: method, status_code'          type: counter          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         inc: 1        - name: httpbin_calls_duration          help: 'httpbin_calls_duration duration histogram of httpbin responses labeled with: method, status_code'          type: histogram          labels:            method: httpbin            status_code: <% outputs.httpbin_step1.code %>                         timer: true                args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.2 DSL spec for custom trace​trace:    name: span_name    attributes:        attribute1: value1        attribute2: value2Example spec​In the following example, we are creating a new span named httpbin_trace with span attributes request and param. This span gets created when the task starts and ended when the task completes its execution.summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      trace:        name: httpbin_trace        attributes:            request: <%inputs.body%>            param: <%inputs.query%>      args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post13.4.3 DSL spec for custom logs​If you want generate a log before or after a task.logs:    before:        level: fatal|error|warn|info|debug|trace # refer pino for levels        message: 'Sample log before'        params:           param1: val1          param2: val2        attributes:          request:            query: <%inputs.query%>    after:        level: info        message: 'Sample log after'        params:        attributes: The logs are dumped in OTEL format. Please refer to OTEL Logging Data model for understanding of fields dumped in the logs.message and params are part of Body field and attributes are part of Attributes field in the log.Example spec​In the following example, we are two additional logs before and after the task execution. summary: Call an API and transform the tasks:    - id: httpbin_step1 # the response of this will be accessible within the parent step key, under the step1 sub key      name: http bin step      description: Hit http bin with some dummy data. It will send back same as response      fn: com.gs.http      logs:        before:          level: error          message: 'Hello'          params:             - key1: v1              key2: v2            - v1          attributes:             request: <%inputs.query%>        after:          level: error          message: 'World'          params:             key1: v1            key2: v2          attributes:             customer_name: <% outputs.httpbin_step1.data.json.customer_name %>       args:        datasource: httpbin        params: <% inputs.query %>        data: <% inputs.body %>        config:          url : /anything          method: post Sample Logs  {"Body":"Hello [{\"key1\":\"v1\",\"key2\":\"v2\"},\"v1\"]","Timestamp":"1676011973016000000","SeverityNumber":9,"SeverityText":"INFO","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"request":{"status":"Hello"},"task_id":"if","workflow_name":"if_else"}}. . . . . . . . . . .{"Body":"World {\"key1\":\"v1\",\"key2\":\"v2\"}","Timestamp":"1676011973019000000","SeverityNumber":17,"SeverityText":"ERROR","TraceId":"afde0bf5bb3533d932c1c04c30d91172","SpanId":"ad477b2cf81ca711","TraceFlags":"01","Resource":{"service.name":"unknown_service:node","host.hostname":"9ce06d358ba7","process.pid":67228},"Attributes":{"customer_name":"Hell!","task_id":"if","workflow_name":"if_else"}}13.5 Observability Stack​The complete observability stack with K8s helm-charts will be made available soon.13.6 Recommended model for telemetry signals​Please find the draft documentation here. This is compiled in one place from various references across the OpenTelemetry documentation. This may require works by the DevOps team as well e.g. K8s related attributes.Edit this pagePreviousAuthentication & AuthorizationNextCustom Middleware13.1 Introduction13.1.1 Architecture13.2 GoalsAuto application performance monitoringBackend agnosticComplete debuggability13.3 Configuration13.3.1 OTEL exporter endpoint13.3.2 OTEL service name13.3.3 Logging13.3.3.1 Log level13.3.3.2 Log fields masking13.3.3.3 Log format13.3.3.4 Loggin for events13.3.3.4.1 Custom log attributes for all events13.3.3.4.2 Custom log attributes at event level13.3.3.4.3 Custom on_error logging in workflow/tasks13.3.3.4.4 Usage of Logger Instance in Custom JS/TS Functions13.4 Custom metrics, traces and logs (BPM)13.4.1 DSL spec for custom metricsrefer https://github.com/siimon/prom-clientExample spec13.4.2 DSL spec for custom traceExample spec13.4.3 DSL spec for custom logsExample spec13.5 Observability Stack13.6 Recommended model for telemetry signalsForumDiscordGithubTwitterLinkedIn








5. Swagger Specs | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).5. Swagger SpecsVersion: v1On this pageIntroductionYou can access autogenerated Swagger API specifications at <domain name>/api-docs url.
For example, http://localhost:3000/api-docsGodspeed also provides a facility to auto-generate OAS 3 documentation using CLI. 5.1 CLI command to generate documentation​You can generate OAS3 documentation using godspeed gen-api-docs CLI command.5.2 Custom Server URL​You can add custom server URL for API documentation in static configuration
By adding the custom server url, your autogenerated documentation or swagger specs will have this url set in the Servers.server_url: https://api.example.com:8443/v1/apiFor example,
Edit this pagePreviousIntroduction to Godspeed CLINextEvents5.1 CLI command to generate documentation5.2 Custom Server URLForumDiscordGithubTwitterLinkedIn








5. Swagger Specs | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).5. Swagger SpecsVersion: v1On this pageIntroductionYou can access autogenerated Swagger API specifications at <domain name>/api-docs url.
For example, http://localhost:3000/api-docsGodspeed also provides a facility to auto-generate OAS 3 documentation using CLI. 5.1 CLI command to generate documentation​You can generate OAS3 documentation using godspeed gen-api-docs CLI command.5.2 Custom Server URL​You can add custom server URL for API documentation in static configuration
By adding the custom server url, your autogenerated documentation or swagger specs will have this url set in the Servers.server_url: https://api.example.com:8443/v1/apiFor example,
Edit this pagePreviousIntroduction to Godspeed CLINextEvents5.1 CLI command to generate documentation5.2 Custom Server URLForumDiscordGithubTwitterLinkedIn








5. Swagger Specs | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).5. Swagger SpecsVersion: v1On this pageIntroductionYou can access autogenerated Swagger API specifications at <domain name>/api-docs url.
For example, http://localhost:3000/api-docsGodspeed also provides a facility to auto-generate OAS 3 documentation using CLI. 5.1 CLI command to generate documentation​You can generate OAS3 documentation using godspeed gen-api-docs CLI command.5.2 Custom Server URL​You can add custom server URL for API documentation in static configuration
By adding the custom server url, your autogenerated documentation or swagger specs will have this url set in the Servers.server_url: https://api.example.com:8443/v1/apiFor example,
Edit this pagePreviousIntroduction to Godspeed CLINextEvents5.1 CLI command to generate documentation5.2 Custom Server URLForumDiscordGithubTwitterLinkedIn








Introduction to Godspeed CLI | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).4. CLIVersion: v1On this pageGodspeed CLIThe CLI is the primary way to interact with your Godspeed project from the command line. It provides a bunch of useful functionalities during the project development lifecycle.4.1 Functionality​Outside the dev container​Creating a new project environment with dev container setup, which includes the folder structure, all the databases, message bus, cache, etc.Open up an existing project in the dev container, add/update a container in the dev environment, based on updated settings.List the versions of gs_service.Change the version of gs_service.Inside the dev container​All Prisma commands including DB push, pull or migration.OAS 3 documentation file generation.Test suite/Postman collection generation.Running test suite.4.2 Installation​npm install -g @mindgrep/godspeedOnce Godspeed CLI is installed, the godspeed command can be called from command line. When called without arguments, it displays its help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.3 Options​--version (-v)​The --version option outputs information about your current godspeed version.$ godspeed -v                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          0.0.26--help (-h)​The --help option displays help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.4 Commands: Outside the dev container​create​The create command creates project structure for any microservice. When called without arguments, it creates project structure with examples.$ godspeed create my_service                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          projectDir:  /home/gurjot/cli-test/my_service projectTemplateDir undefinedproject createdDo you need mongodb? [y/n] [default: n] nDo you need postgresdb? [y/n] [default: n] yPlease enter name of the postgres database [default: test] Do you need kafka? [y/n] [default: n] nDo you need elastisearch? [y/n] [default: n] nPlease enter host port on which you want to run your service [default: 3000] 3100Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13Enter your version [default: latest] 1.0.13Selected version 1.0.13. . . . . . . . Options​$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <existing_project_directory>  existing project template dir  -h, --help                            display help for commandupdate​The update can be executed in the following cases:If you want to launch an existing project (i.e. copied from local/cloned from repo) instead of creating a new one, then execute godspeed update command before launching the project.If you want to reloads the containers with updated project settings. For example, if you have not selected any database during the project creation and you want to include any database in the project later on, then execute godspeed update with the required settings.If there is any change in gs_service image of standard tags (e.g. latest, stable) and you want to fetch the latest code for the same tag, then execute godspeed updatecommand. It fetches the new docker image itself.Please note that the command should be executed from inside the project root directory.noteWhenever you update your project using godspeed update and open the project in VScode dev container after update, then it is mandatory to do godspeed build inside dev container for the first time.$ godspeed update                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Do you need postgresdb? [y/n] [default: n] Do you need kafka? [y/n] [default: n] Do you need elastisearch? [y/n] [default: n] Please enter host port on which you want to run your service [default: 3000] Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.21.0.31.0.4devstableEnter your version [default: latest] Selected version latestRemoving dev_test_devcontainer_node_1                ... . . . . . . . . . .Step 1/9 : FROM adminmindgrep/gs_service:latestlatest: Pulling from adminmindgrep/gs_service824b15f81d65: Already exists325d38bcb229: Already existsd6d638bf61bf: Already exists55daac95cedf: Already exists4c701498752d: Already existsa48b0ae49665: Pulling fs layer4c393fb6deac: Pulling fs layer4f4fb700ef54: Pulling fs layer8992963a9530: Pulling fs layer4f4fb700ef54: Verifying Checksum4f4fb700ef54: Download complete4c393fb6deac: Verifying Checksum4c393fb6deac: Download complete8992963a9530: Verifying Checksum8992963a9530: Download completea48b0ae49665: Verifying Checksuma48b0ae49665: Download completea48b0ae49665: Pull complete4c393fb6deac: Pull complete4f4fb700ef54: Pull complete8992963a9530: Pull completeDigest: sha256:7195b3c921f1278153c911e6e77cbcfb385a84c435bfcb7b8272ffcf9a3278eeStatus: Downloaded newer image for adminmindgrep/gs_service:latest ---> 988917710d1aStep 2/9 : ARG USERNAME=node ---> Running in c70404bb4f3eRemoving intermediate container c70404bb4f3e ---> 47a7406b2473Step 3/9 : ARG USER_UID=1000 ---> Running in 51e68336d8d8Removing intermediate container 51e68336d8d8 ---> ce913f6898bbStep 4/9 : ARG USER_GID=$USER_UID ---> Running in 7cf1c1f2a3ecRemoving intermediate container 7cf1c1f2a3ec ---> 91f045b32e0fStep 5/9 : USER root ---> Running in f338d755a032Removing intermediate container f338d755a032 ---> fa9898eb4c23Step 6/9 : RUN sudo groupmod --gid $USER_GID $USERNAME     && usermod --uid $USER_UID --gid $USER_GID $USERNAME     && chown -R $USER_UID:$USER_GID /workspace/development ---> Running in eba3659fb919Removing intermediate container eba3659fb919 ---> 414f34560b0dStep 7/9 : USER node ---> Running in 23818c5f4882Removing intermediate container 23818c5f4882 ---> 1bd65323ae91Step 8/9 : RUN sudo npm i -g @mindgrep/godspeed ---> Running in a66cb062390d. . . . . . . . . . godspeed update dev_test is done.versions​The versions command lists all the versions available of gs_service.$ godspeed versions                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13version​The version command helps to change the version of gs_service for any microservice. Execute the command from inside the project root directory.$ godspeed version 1.0.13                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Generating prisma modulesStarting test1_devcontainer_postgres_1 ... Starting test1_devcontainer_postgres_1 ... doneCreating test1_devcontainer_node_run   ... Creating test1_devcontainer_node_run   ... doneEnvironment variables loaded from .env. . . . . . . . . .help​The help command displays help and usage for any command.$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <projectTemplateDir>  local project template dir  -h, --help                            display help for command4.5 Commands: Inside the dev container​prisma​You can run all the prisma commands in your project root directory inside the dev container. This command is useful for db migration and introspection. Read more here. $ godspeed prisma <prisma command with args>build​You can build the complete project using this command. It is the first command which you need to run whenever you open your project in VScode Dev container. Refer Open in Dev containergodspeed builddev​You can run your project using dev command.godspeed servegen-api-docs​You can get OAS 3 documentation generated automatically by executing this command in your project root directory inside the dev container.$ godspeed gen-api-docs                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529346164] INFO (GS-logger/7684 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529346190] DEBUG (GS-logger/7684 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529346289] INFO (GS-logger/7684 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Postman collection​step1: After executing $ godspeed gen-api-docs
go to docs under app and right click on api-doc.yaml file and download itstep2: In postman import the downloaded file in collection(collection->import->files->select-file.yaml-> import ) and test your apigen-test-suite​You can get test suite/postman collection generated automatically by executing this command in your project root directory inside the dev container. Now, you can import the collection in postman directly. godspeed gen-test-suite                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-test-suite> npm run gen-api-docs && mkdir -p tests && openapi2postmanv2 -s docs/api-doc.yaml -o tests/test-suite.json -p -O folderStrategy=Tags,includeAuthInfoInExample=false> proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529443249] INFO (GS-logger/8145 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529443273] DEBUG (GS-logger/8145 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529443374] INFO (GS-logger/8145 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Input file:  /workspace/development/app/docs/api-doc.yamlWriting to file:  true /workspace/development/app/tests/test-suite.json { result: true, output: [ { type: 'collection', data: [Object] } ] }Conversion successful, collection written to filegen-crud-api​You can get CRUD API generated automatically for datastores and elasticgraph datasources by executing this command in your project root directory inside the dev container.$ godspeed gen-crud-api                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > eg_test@1.0.0 gen-crud-api> npx godspeed-crud-api-generatorSelect datasource / schema to generate CRUD APIs(x) elasticgraph.yaml( ) For all( ) Canceltest​You can run the test suite generated in above command from the following two ways:Postman: Import the collection in postman and run the test suite.CLI: You can use below command to run the test suite from CLI.Please make sure your service is up and running before running the test suite. godspeed test                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 test> newman run tests/test-suite.jsonnewmanGodspeed: Sample Microservice→ Call another (sub) workflow from main workflow  POST http://localhost:3000/another_workflow?bank_id=<string> [200 OK, 630B, 2.6s]. . . . . . . . help​The help command displays help and usage for any command. Click here to know more4.6 Generating Elasticgraph model from prisma schema​generate-elasticgraph-model​You can convert the prisma schema to elasticgraph model by executing this commmand in your project root directory inside the dev container.$ godspeed generate-elasticgraph-model                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed generate-elasticgraph-model [egClientName]Enter the input path  : Enter the output path :Elasticgraph model generatednote[egClientName] (optional): Specifies the name of the Elasticgraph client to be generated. If not provided, the default name eg-model will be used.If the specified input path does not exist, the CLI will display an error message.If the specified output path does not exist, the folder will be generated with [egClientName].Edit this pagePrevious3.6 Debugger in YamlNext5. Swagger Specs4.1 FunctionalityOutside the dev containerInside the dev container4.2 Installation4.3 Options--version (-v)--help (-h)4.4 Commands: Outside the dev containercreateupdateversionsversionhelp4.5 Commands: Inside the dev containerprismabuilddevgen-api-docsPostman collectiongen-test-suitegen-crud-apitesthelp4.6 Generating Elasticgraph model from prisma schemagenerate-elasticgraph-modelForumDiscordGithubTwitterLinkedIn








Introduction to Godspeed CLI | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).4. CLIVersion: v1On this pageGodspeed CLIThe CLI is the primary way to interact with your Godspeed project from the command line. It provides a bunch of useful functionalities during the project development lifecycle.4.1 Functionality​Outside the dev container​Creating a new project environment with dev container setup, which includes the folder structure, all the databases, message bus, cache, etc.Open up an existing project in the dev container, add/update a container in the dev environment, based on updated settings.List the versions of gs_service.Change the version of gs_service.Inside the dev container​All Prisma commands including DB push, pull or migration.OAS 3 documentation file generation.Test suite/Postman collection generation.Running test suite.4.2 Installation​npm install -g @mindgrep/godspeedOnce Godspeed CLI is installed, the godspeed command can be called from command line. When called without arguments, it displays its help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.3 Options​--version (-v)​The --version option outputs information about your current godspeed version.$ godspeed -v                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          0.0.26--help (-h)​The --help option displays help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.4 Commands: Outside the dev container​create​The create command creates project structure for any microservice. When called without arguments, it creates project structure with examples.$ godspeed create my_service                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          projectDir:  /home/gurjot/cli-test/my_service projectTemplateDir undefinedproject createdDo you need mongodb? [y/n] [default: n] nDo you need postgresdb? [y/n] [default: n] yPlease enter name of the postgres database [default: test] Do you need kafka? [y/n] [default: n] nDo you need elastisearch? [y/n] [default: n] nPlease enter host port on which you want to run your service [default: 3000] 3100Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13Enter your version [default: latest] 1.0.13Selected version 1.0.13. . . . . . . . Options​$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <existing_project_directory>  existing project template dir  -h, --help                            display help for commandupdate​The update can be executed in the following cases:If you want to launch an existing project (i.e. copied from local/cloned from repo) instead of creating a new one, then execute godspeed update command before launching the project.If you want to reloads the containers with updated project settings. For example, if you have not selected any database during the project creation and you want to include any database in the project later on, then execute godspeed update with the required settings.If there is any change in gs_service image of standard tags (e.g. latest, stable) and you want to fetch the latest code for the same tag, then execute godspeed updatecommand. It fetches the new docker image itself.Please note that the command should be executed from inside the project root directory.noteWhenever you update your project using godspeed update and open the project in VScode dev container after update, then it is mandatory to do godspeed build inside dev container for the first time.$ godspeed update                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Do you need postgresdb? [y/n] [default: n] Do you need kafka? [y/n] [default: n] Do you need elastisearch? [y/n] [default: n] Please enter host port on which you want to run your service [default: 3000] Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.21.0.31.0.4devstableEnter your version [default: latest] Selected version latestRemoving dev_test_devcontainer_node_1                ... . . . . . . . . . .Step 1/9 : FROM adminmindgrep/gs_service:latestlatest: Pulling from adminmindgrep/gs_service824b15f81d65: Already exists325d38bcb229: Already existsd6d638bf61bf: Already exists55daac95cedf: Already exists4c701498752d: Already existsa48b0ae49665: Pulling fs layer4c393fb6deac: Pulling fs layer4f4fb700ef54: Pulling fs layer8992963a9530: Pulling fs layer4f4fb700ef54: Verifying Checksum4f4fb700ef54: Download complete4c393fb6deac: Verifying Checksum4c393fb6deac: Download complete8992963a9530: Verifying Checksum8992963a9530: Download completea48b0ae49665: Verifying Checksuma48b0ae49665: Download completea48b0ae49665: Pull complete4c393fb6deac: Pull complete4f4fb700ef54: Pull complete8992963a9530: Pull completeDigest: sha256:7195b3c921f1278153c911e6e77cbcfb385a84c435bfcb7b8272ffcf9a3278eeStatus: Downloaded newer image for adminmindgrep/gs_service:latest ---> 988917710d1aStep 2/9 : ARG USERNAME=node ---> Running in c70404bb4f3eRemoving intermediate container c70404bb4f3e ---> 47a7406b2473Step 3/9 : ARG USER_UID=1000 ---> Running in 51e68336d8d8Removing intermediate container 51e68336d8d8 ---> ce913f6898bbStep 4/9 : ARG USER_GID=$USER_UID ---> Running in 7cf1c1f2a3ecRemoving intermediate container 7cf1c1f2a3ec ---> 91f045b32e0fStep 5/9 : USER root ---> Running in f338d755a032Removing intermediate container f338d755a032 ---> fa9898eb4c23Step 6/9 : RUN sudo groupmod --gid $USER_GID $USERNAME     && usermod --uid $USER_UID --gid $USER_GID $USERNAME     && chown -R $USER_UID:$USER_GID /workspace/development ---> Running in eba3659fb919Removing intermediate container eba3659fb919 ---> 414f34560b0dStep 7/9 : USER node ---> Running in 23818c5f4882Removing intermediate container 23818c5f4882 ---> 1bd65323ae91Step 8/9 : RUN sudo npm i -g @mindgrep/godspeed ---> Running in a66cb062390d. . . . . . . . . . godspeed update dev_test is done.versions​The versions command lists all the versions available of gs_service.$ godspeed versions                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13version​The version command helps to change the version of gs_service for any microservice. Execute the command from inside the project root directory.$ godspeed version 1.0.13                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Generating prisma modulesStarting test1_devcontainer_postgres_1 ... Starting test1_devcontainer_postgres_1 ... doneCreating test1_devcontainer_node_run   ... Creating test1_devcontainer_node_run   ... doneEnvironment variables loaded from .env. . . . . . . . . .help​The help command displays help and usage for any command.$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <projectTemplateDir>  local project template dir  -h, --help                            display help for command4.5 Commands: Inside the dev container​prisma​You can run all the prisma commands in your project root directory inside the dev container. This command is useful for db migration and introspection. Read more here. $ godspeed prisma <prisma command with args>build​You can build the complete project using this command. It is the first command which you need to run whenever you open your project in VScode Dev container. Refer Open in Dev containergodspeed builddev​You can run your project using dev command.godspeed servegen-api-docs​You can get OAS 3 documentation generated automatically by executing this command in your project root directory inside the dev container.$ godspeed gen-api-docs                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529346164] INFO (GS-logger/7684 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529346190] DEBUG (GS-logger/7684 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529346289] INFO (GS-logger/7684 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Postman collection​step1: After executing $ godspeed gen-api-docs
go to docs under app and right click on api-doc.yaml file and download itstep2: In postman import the downloaded file in collection(collection->import->files->select-file.yaml-> import ) and test your apigen-test-suite​You can get test suite/postman collection generated automatically by executing this command in your project root directory inside the dev container. Now, you can import the collection in postman directly. godspeed gen-test-suite                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-test-suite> npm run gen-api-docs && mkdir -p tests && openapi2postmanv2 -s docs/api-doc.yaml -o tests/test-suite.json -p -O folderStrategy=Tags,includeAuthInfoInExample=false> proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529443249] INFO (GS-logger/8145 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529443273] DEBUG (GS-logger/8145 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529443374] INFO (GS-logger/8145 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Input file:  /workspace/development/app/docs/api-doc.yamlWriting to file:  true /workspace/development/app/tests/test-suite.json { result: true, output: [ { type: 'collection', data: [Object] } ] }Conversion successful, collection written to filegen-crud-api​You can get CRUD API generated automatically for datastores and elasticgraph datasources by executing this command in your project root directory inside the dev container.$ godspeed gen-crud-api                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > eg_test@1.0.0 gen-crud-api> npx godspeed-crud-api-generatorSelect datasource / schema to generate CRUD APIs(x) elasticgraph.yaml( ) For all( ) Canceltest​You can run the test suite generated in above command from the following two ways:Postman: Import the collection in postman and run the test suite.CLI: You can use below command to run the test suite from CLI.Please make sure your service is up and running before running the test suite. godspeed test                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 test> newman run tests/test-suite.jsonnewmanGodspeed: Sample Microservice→ Call another (sub) workflow from main workflow  POST http://localhost:3000/another_workflow?bank_id=<string> [200 OK, 630B, 2.6s]. . . . . . . . help​The help command displays help and usage for any command. Click here to know more4.6 Generating Elasticgraph model from prisma schema​generate-elasticgraph-model​You can convert the prisma schema to elasticgraph model by executing this commmand in your project root directory inside the dev container.$ godspeed generate-elasticgraph-model                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed generate-elasticgraph-model [egClientName]Enter the input path  : Enter the output path :Elasticgraph model generatednote[egClientName] (optional): Specifies the name of the Elasticgraph client to be generated. If not provided, the default name eg-model will be used.If the specified input path does not exist, the CLI will display an error message.If the specified output path does not exist, the folder will be generated with [egClientName].Edit this pagePrevious3.6 Debugger in YamlNext5. Swagger Specs4.1 FunctionalityOutside the dev containerInside the dev container4.2 Installation4.3 Options--version (-v)--help (-h)4.4 Commands: Outside the dev containercreateupdateversionsversionhelp4.5 Commands: Inside the dev containerprismabuilddevgen-api-docsPostman collectiongen-test-suitegen-crud-apitesthelp4.6 Generating Elasticgraph model from prisma schemagenerate-elasticgraph-modelForumDiscordGithubTwitterLinkedIn








Introduction to Godspeed CLI | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).4. CLIVersion: v1On this pageGodspeed CLIThe CLI is the primary way to interact with your Godspeed project from the command line. It provides a bunch of useful functionalities during the project development lifecycle.4.1 Functionality​Outside the dev container​Creating a new project environment with dev container setup, which includes the folder structure, all the databases, message bus, cache, etc.Open up an existing project in the dev container, add/update a container in the dev environment, based on updated settings.List the versions of gs_service.Change the version of gs_service.Inside the dev container​All Prisma commands including DB push, pull or migration.OAS 3 documentation file generation.Test suite/Postman collection generation.Running test suite.4.2 Installation​npm install -g @mindgrep/godspeedOnce Godspeed CLI is installed, the godspeed command can be called from command line. When called without arguments, it displays its help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.3 Options​--version (-v)​The --version option outputs information about your current godspeed version.$ godspeed -v                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          0.0.26--help (-h)​The --help option displays help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.4 Commands: Outside the dev container​create​The create command creates project structure for any microservice. When called without arguments, it creates project structure with examples.$ godspeed create my_service                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          projectDir:  /home/gurjot/cli-test/my_service projectTemplateDir undefinedproject createdDo you need mongodb? [y/n] [default: n] nDo you need postgresdb? [y/n] [default: n] yPlease enter name of the postgres database [default: test] Do you need kafka? [y/n] [default: n] nDo you need elastisearch? [y/n] [default: n] nPlease enter host port on which you want to run your service [default: 3000] 3100Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13Enter your version [default: latest] 1.0.13Selected version 1.0.13. . . . . . . . Options​$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <existing_project_directory>  existing project template dir  -h, --help                            display help for commandupdate​The update can be executed in the following cases:If you want to launch an existing project (i.e. copied from local/cloned from repo) instead of creating a new one, then execute godspeed update command before launching the project.If you want to reloads the containers with updated project settings. For example, if you have not selected any database during the project creation and you want to include any database in the project later on, then execute godspeed update with the required settings.If there is any change in gs_service image of standard tags (e.g. latest, stable) and you want to fetch the latest code for the same tag, then execute godspeed updatecommand. It fetches the new docker image itself.Please note that the command should be executed from inside the project root directory.noteWhenever you update your project using godspeed update and open the project in VScode dev container after update, then it is mandatory to do godspeed build inside dev container for the first time.$ godspeed update                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Do you need postgresdb? [y/n] [default: n] Do you need kafka? [y/n] [default: n] Do you need elastisearch? [y/n] [default: n] Please enter host port on which you want to run your service [default: 3000] Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.21.0.31.0.4devstableEnter your version [default: latest] Selected version latestRemoving dev_test_devcontainer_node_1                ... . . . . . . . . . .Step 1/9 : FROM adminmindgrep/gs_service:latestlatest: Pulling from adminmindgrep/gs_service824b15f81d65: Already exists325d38bcb229: Already existsd6d638bf61bf: Already exists55daac95cedf: Already exists4c701498752d: Already existsa48b0ae49665: Pulling fs layer4c393fb6deac: Pulling fs layer4f4fb700ef54: Pulling fs layer8992963a9530: Pulling fs layer4f4fb700ef54: Verifying Checksum4f4fb700ef54: Download complete4c393fb6deac: Verifying Checksum4c393fb6deac: Download complete8992963a9530: Verifying Checksum8992963a9530: Download completea48b0ae49665: Verifying Checksuma48b0ae49665: Download completea48b0ae49665: Pull complete4c393fb6deac: Pull complete4f4fb700ef54: Pull complete8992963a9530: Pull completeDigest: sha256:7195b3c921f1278153c911e6e77cbcfb385a84c435bfcb7b8272ffcf9a3278eeStatus: Downloaded newer image for adminmindgrep/gs_service:latest ---> 988917710d1aStep 2/9 : ARG USERNAME=node ---> Running in c70404bb4f3eRemoving intermediate container c70404bb4f3e ---> 47a7406b2473Step 3/9 : ARG USER_UID=1000 ---> Running in 51e68336d8d8Removing intermediate container 51e68336d8d8 ---> ce913f6898bbStep 4/9 : ARG USER_GID=$USER_UID ---> Running in 7cf1c1f2a3ecRemoving intermediate container 7cf1c1f2a3ec ---> 91f045b32e0fStep 5/9 : USER root ---> Running in f338d755a032Removing intermediate container f338d755a032 ---> fa9898eb4c23Step 6/9 : RUN sudo groupmod --gid $USER_GID $USERNAME     && usermod --uid $USER_UID --gid $USER_GID $USERNAME     && chown -R $USER_UID:$USER_GID /workspace/development ---> Running in eba3659fb919Removing intermediate container eba3659fb919 ---> 414f34560b0dStep 7/9 : USER node ---> Running in 23818c5f4882Removing intermediate container 23818c5f4882 ---> 1bd65323ae91Step 8/9 : RUN sudo npm i -g @mindgrep/godspeed ---> Running in a66cb062390d. . . . . . . . . . godspeed update dev_test is done.versions​The versions command lists all the versions available of gs_service.$ godspeed versions                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13version​The version command helps to change the version of gs_service for any microservice. Execute the command from inside the project root directory.$ godspeed version 1.0.13                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Generating prisma modulesStarting test1_devcontainer_postgres_1 ... Starting test1_devcontainer_postgres_1 ... doneCreating test1_devcontainer_node_run   ... Creating test1_devcontainer_node_run   ... doneEnvironment variables loaded from .env. . . . . . . . . .help​The help command displays help and usage for any command.$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <projectTemplateDir>  local project template dir  -h, --help                            display help for command4.5 Commands: Inside the dev container​prisma​You can run all the prisma commands in your project root directory inside the dev container. This command is useful for db migration and introspection. Read more here. $ godspeed prisma <prisma command with args>build​You can build the complete project using this command. It is the first command which you need to run whenever you open your project in VScode Dev container. Refer Open in Dev containergodspeed builddev​You can run your project using dev command.godspeed servegen-api-docs​You can get OAS 3 documentation generated automatically by executing this command in your project root directory inside the dev container.$ godspeed gen-api-docs                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529346164] INFO (GS-logger/7684 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529346190] DEBUG (GS-logger/7684 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529346289] INFO (GS-logger/7684 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Postman collection​step1: After executing $ godspeed gen-api-docs
go to docs under app and right click on api-doc.yaml file and download itstep2: In postman import the downloaded file in collection(collection->import->files->select-file.yaml-> import ) and test your apigen-test-suite​You can get test suite/postman collection generated automatically by executing this command in your project root directory inside the dev container. Now, you can import the collection in postman directly. godspeed gen-test-suite                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-test-suite> npm run gen-api-docs && mkdir -p tests && openapi2postmanv2 -s docs/api-doc.yaml -o tests/test-suite.json -p -O folderStrategy=Tags,includeAuthInfoInExample=false> proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529443249] INFO (GS-logger/8145 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529443273] DEBUG (GS-logger/8145 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529443374] INFO (GS-logger/8145 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Input file:  /workspace/development/app/docs/api-doc.yamlWriting to file:  true /workspace/development/app/tests/test-suite.json { result: true, output: [ { type: 'collection', data: [Object] } ] }Conversion successful, collection written to filegen-crud-api​You can get CRUD API generated automatically for datastores and elasticgraph datasources by executing this command in your project root directory inside the dev container.$ godspeed gen-crud-api                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > eg_test@1.0.0 gen-crud-api> npx godspeed-crud-api-generatorSelect datasource / schema to generate CRUD APIs(x) elasticgraph.yaml( ) For all( ) Canceltest​You can run the test suite generated in above command from the following two ways:Postman: Import the collection in postman and run the test suite.CLI: You can use below command to run the test suite from CLI.Please make sure your service is up and running before running the test suite. godspeed test                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 test> newman run tests/test-suite.jsonnewmanGodspeed: Sample Microservice→ Call another (sub) workflow from main workflow  POST http://localhost:3000/another_workflow?bank_id=<string> [200 OK, 630B, 2.6s]. . . . . . . . help​The help command displays help and usage for any command. Click here to know more4.6 Generating Elasticgraph model from prisma schema​generate-elasticgraph-model​You can convert the prisma schema to elasticgraph model by executing this commmand in your project root directory inside the dev container.$ godspeed generate-elasticgraph-model                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed generate-elasticgraph-model [egClientName]Enter the input path  : Enter the output path :Elasticgraph model generatednote[egClientName] (optional): Specifies the name of the Elasticgraph client to be generated. If not provided, the default name eg-model will be used.If the specified input path does not exist, the CLI will display an error message.If the specified output path does not exist, the folder will be generated with [egClientName].Edit this pagePrevious3.6 Debugger in YamlNext5. Swagger Specs4.1 FunctionalityOutside the dev containerInside the dev container4.2 Installation4.3 Options--version (-v)--help (-h)4.4 Commands: Outside the dev containercreateupdateversionsversionhelp4.5 Commands: Inside the dev containerprismabuilddevgen-api-docsPostman collectiongen-test-suitegen-crud-apitesthelp4.6 Generating Elasticgraph model from prisma schemagenerate-elasticgraph-modelForumDiscordGithubTwitterLinkedIn








Introduction to Godspeed CLI | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).4. CLIVersion: v1On this pageGodspeed CLIThe CLI is the primary way to interact with your Godspeed project from the command line. It provides a bunch of useful functionalities during the project development lifecycle.4.1 Functionality​Outside the dev container​Creating a new project environment with dev container setup, which includes the folder structure, all the databases, message bus, cache, etc.Open up an existing project in the dev container, add/update a container in the dev environment, based on updated settings.List the versions of gs_service.Change the version of gs_service.Inside the dev container​All Prisma commands including DB push, pull or migration.OAS 3 documentation file generation.Test suite/Postman collection generation.Running test suite.4.2 Installation​npm install -g @mindgrep/godspeedOnce Godspeed CLI is installed, the godspeed command can be called from command line. When called without arguments, it displays its help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.3 Options​--version (-v)​The --version option outputs information about your current godspeed version.$ godspeed -v                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          0.0.26--help (-h)​The --help option displays help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.4 Commands: Outside the dev container​create​The create command creates project structure for any microservice. When called without arguments, it creates project structure with examples.$ godspeed create my_service                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          projectDir:  /home/gurjot/cli-test/my_service projectTemplateDir undefinedproject createdDo you need mongodb? [y/n] [default: n] nDo you need postgresdb? [y/n] [default: n] yPlease enter name of the postgres database [default: test] Do you need kafka? [y/n] [default: n] nDo you need elastisearch? [y/n] [default: n] nPlease enter host port on which you want to run your service [default: 3000] 3100Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13Enter your version [default: latest] 1.0.13Selected version 1.0.13. . . . . . . . Options​$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <existing_project_directory>  existing project template dir  -h, --help                            display help for commandupdate​The update can be executed in the following cases:If you want to launch an existing project (i.e. copied from local/cloned from repo) instead of creating a new one, then execute godspeed update command before launching the project.If you want to reloads the containers with updated project settings. For example, if you have not selected any database during the project creation and you want to include any database in the project later on, then execute godspeed update with the required settings.If there is any change in gs_service image of standard tags (e.g. latest, stable) and you want to fetch the latest code for the same tag, then execute godspeed updatecommand. It fetches the new docker image itself.Please note that the command should be executed from inside the project root directory.noteWhenever you update your project using godspeed update and open the project in VScode dev container after update, then it is mandatory to do godspeed build inside dev container for the first time.$ godspeed update                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Do you need postgresdb? [y/n] [default: n] Do you need kafka? [y/n] [default: n] Do you need elastisearch? [y/n] [default: n] Please enter host port on which you want to run your service [default: 3000] Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.21.0.31.0.4devstableEnter your version [default: latest] Selected version latestRemoving dev_test_devcontainer_node_1                ... . . . . . . . . . .Step 1/9 : FROM adminmindgrep/gs_service:latestlatest: Pulling from adminmindgrep/gs_service824b15f81d65: Already exists325d38bcb229: Already existsd6d638bf61bf: Already exists55daac95cedf: Already exists4c701498752d: Already existsa48b0ae49665: Pulling fs layer4c393fb6deac: Pulling fs layer4f4fb700ef54: Pulling fs layer8992963a9530: Pulling fs layer4f4fb700ef54: Verifying Checksum4f4fb700ef54: Download complete4c393fb6deac: Verifying Checksum4c393fb6deac: Download complete8992963a9530: Verifying Checksum8992963a9530: Download completea48b0ae49665: Verifying Checksuma48b0ae49665: Download completea48b0ae49665: Pull complete4c393fb6deac: Pull complete4f4fb700ef54: Pull complete8992963a9530: Pull completeDigest: sha256:7195b3c921f1278153c911e6e77cbcfb385a84c435bfcb7b8272ffcf9a3278eeStatus: Downloaded newer image for adminmindgrep/gs_service:latest ---> 988917710d1aStep 2/9 : ARG USERNAME=node ---> Running in c70404bb4f3eRemoving intermediate container c70404bb4f3e ---> 47a7406b2473Step 3/9 : ARG USER_UID=1000 ---> Running in 51e68336d8d8Removing intermediate container 51e68336d8d8 ---> ce913f6898bbStep 4/9 : ARG USER_GID=$USER_UID ---> Running in 7cf1c1f2a3ecRemoving intermediate container 7cf1c1f2a3ec ---> 91f045b32e0fStep 5/9 : USER root ---> Running in f338d755a032Removing intermediate container f338d755a032 ---> fa9898eb4c23Step 6/9 : RUN sudo groupmod --gid $USER_GID $USERNAME     && usermod --uid $USER_UID --gid $USER_GID $USERNAME     && chown -R $USER_UID:$USER_GID /workspace/development ---> Running in eba3659fb919Removing intermediate container eba3659fb919 ---> 414f34560b0dStep 7/9 : USER node ---> Running in 23818c5f4882Removing intermediate container 23818c5f4882 ---> 1bd65323ae91Step 8/9 : RUN sudo npm i -g @mindgrep/godspeed ---> Running in a66cb062390d. . . . . . . . . . godspeed update dev_test is done.versions​The versions command lists all the versions available of gs_service.$ godspeed versions                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13version​The version command helps to change the version of gs_service for any microservice. Execute the command from inside the project root directory.$ godspeed version 1.0.13                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Generating prisma modulesStarting test1_devcontainer_postgres_1 ... Starting test1_devcontainer_postgres_1 ... doneCreating test1_devcontainer_node_run   ... Creating test1_devcontainer_node_run   ... doneEnvironment variables loaded from .env. . . . . . . . . .help​The help command displays help and usage for any command.$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <projectTemplateDir>  local project template dir  -h, --help                            display help for command4.5 Commands: Inside the dev container​prisma​You can run all the prisma commands in your project root directory inside the dev container. This command is useful for db migration and introspection. Read more here. $ godspeed prisma <prisma command with args>build​You can build the complete project using this command. It is the first command which you need to run whenever you open your project in VScode Dev container. Refer Open in Dev containergodspeed builddev​You can run your project using dev command.godspeed servegen-api-docs​You can get OAS 3 documentation generated automatically by executing this command in your project root directory inside the dev container.$ godspeed gen-api-docs                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529346164] INFO (GS-logger/7684 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529346190] DEBUG (GS-logger/7684 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529346289] INFO (GS-logger/7684 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Postman collection​step1: After executing $ godspeed gen-api-docs
go to docs under app and right click on api-doc.yaml file and download itstep2: In postman import the downloaded file in collection(collection->import->files->select-file.yaml-> import ) and test your apigen-test-suite​You can get test suite/postman collection generated automatically by executing this command in your project root directory inside the dev container. Now, you can import the collection in postman directly. godspeed gen-test-suite                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-test-suite> npm run gen-api-docs && mkdir -p tests && openapi2postmanv2 -s docs/api-doc.yaml -o tests/test-suite.json -p -O folderStrategy=Tags,includeAuthInfoInExample=false> proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529443249] INFO (GS-logger/8145 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529443273] DEBUG (GS-logger/8145 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529443374] INFO (GS-logger/8145 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Input file:  /workspace/development/app/docs/api-doc.yamlWriting to file:  true /workspace/development/app/tests/test-suite.json { result: true, output: [ { type: 'collection', data: [Object] } ] }Conversion successful, collection written to filegen-crud-api​You can get CRUD API generated automatically for datastores and elasticgraph datasources by executing this command in your project root directory inside the dev container.$ godspeed gen-crud-api                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > eg_test@1.0.0 gen-crud-api> npx godspeed-crud-api-generatorSelect datasource / schema to generate CRUD APIs(x) elasticgraph.yaml( ) For all( ) Canceltest​You can run the test suite generated in above command from the following two ways:Postman: Import the collection in postman and run the test suite.CLI: You can use below command to run the test suite from CLI.Please make sure your service is up and running before running the test suite. godspeed test                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 test> newman run tests/test-suite.jsonnewmanGodspeed: Sample Microservice→ Call another (sub) workflow from main workflow  POST http://localhost:3000/another_workflow?bank_id=<string> [200 OK, 630B, 2.6s]. . . . . . . . help​The help command displays help and usage for any command. Click here to know more4.6 Generating Elasticgraph model from prisma schema​generate-elasticgraph-model​You can convert the prisma schema to elasticgraph model by executing this commmand in your project root directory inside the dev container.$ godspeed generate-elasticgraph-model                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed generate-elasticgraph-model [egClientName]Enter the input path  : Enter the output path :Elasticgraph model generatednote[egClientName] (optional): Specifies the name of the Elasticgraph client to be generated. If not provided, the default name eg-model will be used.If the specified input path does not exist, the CLI will display an error message.If the specified output path does not exist, the folder will be generated with [egClientName].Edit this pagePrevious3.6 Debugger in YamlNext5. Swagger Specs4.1 FunctionalityOutside the dev containerInside the dev container4.2 Installation4.3 Options--version (-v)--help (-h)4.4 Commands: Outside the dev containercreateupdateversionsversionhelp4.5 Commands: Inside the dev containerprismabuilddevgen-api-docsPostman collectiongen-test-suitegen-crud-apitesthelp4.6 Generating Elasticgraph model from prisma schemagenerate-elasticgraph-modelForumDiscordGithubTwitterLinkedIn








Introduction to Godspeed CLI | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).4. CLIVersion: v1On this pageGodspeed CLIThe CLI is the primary way to interact with your Godspeed project from the command line. It provides a bunch of useful functionalities during the project development lifecycle.4.1 Functionality​Outside the dev container​Creating a new project environment with dev container setup, which includes the folder structure, all the databases, message bus, cache, etc.Open up an existing project in the dev container, add/update a container in the dev environment, based on updated settings.List the versions of gs_service.Change the version of gs_service.Inside the dev container​All Prisma commands including DB push, pull or migration.OAS 3 documentation file generation.Test suite/Postman collection generation.Running test suite.4.2 Installation​npm install -g @mindgrep/godspeedOnce Godspeed CLI is installed, the godspeed command can be called from command line. When called without arguments, it displays its help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.3 Options​--version (-v)​The --version option outputs information about your current godspeed version.$ godspeed -v                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          0.0.26--help (-h)​The --help option displays help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.4 Commands: Outside the dev container​create​The create command creates project structure for any microservice. When called without arguments, it creates project structure with examples.$ godspeed create my_service                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          projectDir:  /home/gurjot/cli-test/my_service projectTemplateDir undefinedproject createdDo you need mongodb? [y/n] [default: n] nDo you need postgresdb? [y/n] [default: n] yPlease enter name of the postgres database [default: test] Do you need kafka? [y/n] [default: n] nDo you need elastisearch? [y/n] [default: n] nPlease enter host port on which you want to run your service [default: 3000] 3100Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13Enter your version [default: latest] 1.0.13Selected version 1.0.13. . . . . . . . Options​$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <existing_project_directory>  existing project template dir  -h, --help                            display help for commandupdate​The update can be executed in the following cases:If you want to launch an existing project (i.e. copied from local/cloned from repo) instead of creating a new one, then execute godspeed update command before launching the project.If you want to reloads the containers with updated project settings. For example, if you have not selected any database during the project creation and you want to include any database in the project later on, then execute godspeed update with the required settings.If there is any change in gs_service image of standard tags (e.g. latest, stable) and you want to fetch the latest code for the same tag, then execute godspeed updatecommand. It fetches the new docker image itself.Please note that the command should be executed from inside the project root directory.noteWhenever you update your project using godspeed update and open the project in VScode dev container after update, then it is mandatory to do godspeed build inside dev container for the first time.$ godspeed update                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Do you need postgresdb? [y/n] [default: n] Do you need kafka? [y/n] [default: n] Do you need elastisearch? [y/n] [default: n] Please enter host port on which you want to run your service [default: 3000] Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.21.0.31.0.4devstableEnter your version [default: latest] Selected version latestRemoving dev_test_devcontainer_node_1                ... . . . . . . . . . .Step 1/9 : FROM adminmindgrep/gs_service:latestlatest: Pulling from adminmindgrep/gs_service824b15f81d65: Already exists325d38bcb229: Already existsd6d638bf61bf: Already exists55daac95cedf: Already exists4c701498752d: Already existsa48b0ae49665: Pulling fs layer4c393fb6deac: Pulling fs layer4f4fb700ef54: Pulling fs layer8992963a9530: Pulling fs layer4f4fb700ef54: Verifying Checksum4f4fb700ef54: Download complete4c393fb6deac: Verifying Checksum4c393fb6deac: Download complete8992963a9530: Verifying Checksum8992963a9530: Download completea48b0ae49665: Verifying Checksuma48b0ae49665: Download completea48b0ae49665: Pull complete4c393fb6deac: Pull complete4f4fb700ef54: Pull complete8992963a9530: Pull completeDigest: sha256:7195b3c921f1278153c911e6e77cbcfb385a84c435bfcb7b8272ffcf9a3278eeStatus: Downloaded newer image for adminmindgrep/gs_service:latest ---> 988917710d1aStep 2/9 : ARG USERNAME=node ---> Running in c70404bb4f3eRemoving intermediate container c70404bb4f3e ---> 47a7406b2473Step 3/9 : ARG USER_UID=1000 ---> Running in 51e68336d8d8Removing intermediate container 51e68336d8d8 ---> ce913f6898bbStep 4/9 : ARG USER_GID=$USER_UID ---> Running in 7cf1c1f2a3ecRemoving intermediate container 7cf1c1f2a3ec ---> 91f045b32e0fStep 5/9 : USER root ---> Running in f338d755a032Removing intermediate container f338d755a032 ---> fa9898eb4c23Step 6/9 : RUN sudo groupmod --gid $USER_GID $USERNAME     && usermod --uid $USER_UID --gid $USER_GID $USERNAME     && chown -R $USER_UID:$USER_GID /workspace/development ---> Running in eba3659fb919Removing intermediate container eba3659fb919 ---> 414f34560b0dStep 7/9 : USER node ---> Running in 23818c5f4882Removing intermediate container 23818c5f4882 ---> 1bd65323ae91Step 8/9 : RUN sudo npm i -g @mindgrep/godspeed ---> Running in a66cb062390d. . . . . . . . . . godspeed update dev_test is done.versions​The versions command lists all the versions available of gs_service.$ godspeed versions                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13version​The version command helps to change the version of gs_service for any microservice. Execute the command from inside the project root directory.$ godspeed version 1.0.13                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Generating prisma modulesStarting test1_devcontainer_postgres_1 ... Starting test1_devcontainer_postgres_1 ... doneCreating test1_devcontainer_node_run   ... Creating test1_devcontainer_node_run   ... doneEnvironment variables loaded from .env. . . . . . . . . .help​The help command displays help and usage for any command.$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <projectTemplateDir>  local project template dir  -h, --help                            display help for command4.5 Commands: Inside the dev container​prisma​You can run all the prisma commands in your project root directory inside the dev container. This command is useful for db migration and introspection. Read more here. $ godspeed prisma <prisma command with args>build​You can build the complete project using this command. It is the first command which you need to run whenever you open your project in VScode Dev container. Refer Open in Dev containergodspeed builddev​You can run your project using dev command.godspeed servegen-api-docs​You can get OAS 3 documentation generated automatically by executing this command in your project root directory inside the dev container.$ godspeed gen-api-docs                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529346164] INFO (GS-logger/7684 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529346190] DEBUG (GS-logger/7684 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529346289] INFO (GS-logger/7684 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Postman collection​step1: After executing $ godspeed gen-api-docs
go to docs under app and right click on api-doc.yaml file and download itstep2: In postman import the downloaded file in collection(collection->import->files->select-file.yaml-> import ) and test your apigen-test-suite​You can get test suite/postman collection generated automatically by executing this command in your project root directory inside the dev container. Now, you can import the collection in postman directly. godspeed gen-test-suite                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-test-suite> npm run gen-api-docs && mkdir -p tests && openapi2postmanv2 -s docs/api-doc.yaml -o tests/test-suite.json -p -O folderStrategy=Tags,includeAuthInfoInExample=false> proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529443249] INFO (GS-logger/8145 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529443273] DEBUG (GS-logger/8145 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529443374] INFO (GS-logger/8145 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Input file:  /workspace/development/app/docs/api-doc.yamlWriting to file:  true /workspace/development/app/tests/test-suite.json { result: true, output: [ { type: 'collection', data: [Object] } ] }Conversion successful, collection written to filegen-crud-api​You can get CRUD API generated automatically for datastores and elasticgraph datasources by executing this command in your project root directory inside the dev container.$ godspeed gen-crud-api                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > eg_test@1.0.0 gen-crud-api> npx godspeed-crud-api-generatorSelect datasource / schema to generate CRUD APIs(x) elasticgraph.yaml( ) For all( ) Canceltest​You can run the test suite generated in above command from the following two ways:Postman: Import the collection in postman and run the test suite.CLI: You can use below command to run the test suite from CLI.Please make sure your service is up and running before running the test suite. godspeed test                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 test> newman run tests/test-suite.jsonnewmanGodspeed: Sample Microservice→ Call another (sub) workflow from main workflow  POST http://localhost:3000/another_workflow?bank_id=<string> [200 OK, 630B, 2.6s]. . . . . . . . help​The help command displays help and usage for any command. Click here to know more4.6 Generating Elasticgraph model from prisma schema​generate-elasticgraph-model​You can convert the prisma schema to elasticgraph model by executing this commmand in your project root directory inside the dev container.$ godspeed generate-elasticgraph-model                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed generate-elasticgraph-model [egClientName]Enter the input path  : Enter the output path :Elasticgraph model generatednote[egClientName] (optional): Specifies the name of the Elasticgraph client to be generated. If not provided, the default name eg-model will be used.If the specified input path does not exist, the CLI will display an error message.If the specified output path does not exist, the folder will be generated with [egClientName].Edit this pagePrevious3.6 Debugger in YamlNext5. Swagger Specs4.1 FunctionalityOutside the dev containerInside the dev container4.2 Installation4.3 Options--version (-v)--help (-h)4.4 Commands: Outside the dev containercreateupdateversionsversionhelp4.5 Commands: Inside the dev containerprismabuilddevgen-api-docsPostman collectiongen-test-suitegen-crud-apitesthelp4.6 Generating Elasticgraph model from prisma schemagenerate-elasticgraph-modelForumDiscordGithubTwitterLinkedIn








Introduction to Godspeed CLI | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).4. CLIVersion: v1On this pageGodspeed CLIThe CLI is the primary way to interact with your Godspeed project from the command line. It provides a bunch of useful functionalities during the project development lifecycle.4.1 Functionality​Outside the dev container​Creating a new project environment with dev container setup, which includes the folder structure, all the databases, message bus, cache, etc.Open up an existing project in the dev container, add/update a container in the dev environment, based on updated settings.List the versions of gs_service.Change the version of gs_service.Inside the dev container​All Prisma commands including DB push, pull or migration.OAS 3 documentation file generation.Test suite/Postman collection generation.Running test suite.4.2 Installation​npm install -g @mindgrep/godspeedOnce Godspeed CLI is installed, the godspeed command can be called from command line. When called without arguments, it displays its help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.3 Options​--version (-v)​The --version option outputs information about your current godspeed version.$ godspeed -v                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          0.0.26--help (-h)​The --help option displays help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.4 Commands: Outside the dev container​create​The create command creates project structure for any microservice. When called without arguments, it creates project structure with examples.$ godspeed create my_service                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          projectDir:  /home/gurjot/cli-test/my_service projectTemplateDir undefinedproject createdDo you need mongodb? [y/n] [default: n] nDo you need postgresdb? [y/n] [default: n] yPlease enter name of the postgres database [default: test] Do you need kafka? [y/n] [default: n] nDo you need elastisearch? [y/n] [default: n] nPlease enter host port on which you want to run your service [default: 3000] 3100Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13Enter your version [default: latest] 1.0.13Selected version 1.0.13. . . . . . . . Options​$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <existing_project_directory>  existing project template dir  -h, --help                            display help for commandupdate​The update can be executed in the following cases:If you want to launch an existing project (i.e. copied from local/cloned from repo) instead of creating a new one, then execute godspeed update command before launching the project.If you want to reloads the containers with updated project settings. For example, if you have not selected any database during the project creation and you want to include any database in the project later on, then execute godspeed update with the required settings.If there is any change in gs_service image of standard tags (e.g. latest, stable) and you want to fetch the latest code for the same tag, then execute godspeed updatecommand. It fetches the new docker image itself.Please note that the command should be executed from inside the project root directory.noteWhenever you update your project using godspeed update and open the project in VScode dev container after update, then it is mandatory to do godspeed build inside dev container for the first time.$ godspeed update                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Do you need postgresdb? [y/n] [default: n] Do you need kafka? [y/n] [default: n] Do you need elastisearch? [y/n] [default: n] Please enter host port on which you want to run your service [default: 3000] Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.21.0.31.0.4devstableEnter your version [default: latest] Selected version latestRemoving dev_test_devcontainer_node_1                ... . . . . . . . . . .Step 1/9 : FROM adminmindgrep/gs_service:latestlatest: Pulling from adminmindgrep/gs_service824b15f81d65: Already exists325d38bcb229: Already existsd6d638bf61bf: Already exists55daac95cedf: Already exists4c701498752d: Already existsa48b0ae49665: Pulling fs layer4c393fb6deac: Pulling fs layer4f4fb700ef54: Pulling fs layer8992963a9530: Pulling fs layer4f4fb700ef54: Verifying Checksum4f4fb700ef54: Download complete4c393fb6deac: Verifying Checksum4c393fb6deac: Download complete8992963a9530: Verifying Checksum8992963a9530: Download completea48b0ae49665: Verifying Checksuma48b0ae49665: Download completea48b0ae49665: Pull complete4c393fb6deac: Pull complete4f4fb700ef54: Pull complete8992963a9530: Pull completeDigest: sha256:7195b3c921f1278153c911e6e77cbcfb385a84c435bfcb7b8272ffcf9a3278eeStatus: Downloaded newer image for adminmindgrep/gs_service:latest ---> 988917710d1aStep 2/9 : ARG USERNAME=node ---> Running in c70404bb4f3eRemoving intermediate container c70404bb4f3e ---> 47a7406b2473Step 3/9 : ARG USER_UID=1000 ---> Running in 51e68336d8d8Removing intermediate container 51e68336d8d8 ---> ce913f6898bbStep 4/9 : ARG USER_GID=$USER_UID ---> Running in 7cf1c1f2a3ecRemoving intermediate container 7cf1c1f2a3ec ---> 91f045b32e0fStep 5/9 : USER root ---> Running in f338d755a032Removing intermediate container f338d755a032 ---> fa9898eb4c23Step 6/9 : RUN sudo groupmod --gid $USER_GID $USERNAME     && usermod --uid $USER_UID --gid $USER_GID $USERNAME     && chown -R $USER_UID:$USER_GID /workspace/development ---> Running in eba3659fb919Removing intermediate container eba3659fb919 ---> 414f34560b0dStep 7/9 : USER node ---> Running in 23818c5f4882Removing intermediate container 23818c5f4882 ---> 1bd65323ae91Step 8/9 : RUN sudo npm i -g @mindgrep/godspeed ---> Running in a66cb062390d. . . . . . . . . . godspeed update dev_test is done.versions​The versions command lists all the versions available of gs_service.$ godspeed versions                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13version​The version command helps to change the version of gs_service for any microservice. Execute the command from inside the project root directory.$ godspeed version 1.0.13                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Generating prisma modulesStarting test1_devcontainer_postgres_1 ... Starting test1_devcontainer_postgres_1 ... doneCreating test1_devcontainer_node_run   ... Creating test1_devcontainer_node_run   ... doneEnvironment variables loaded from .env. . . . . . . . . .help​The help command displays help and usage for any command.$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <projectTemplateDir>  local project template dir  -h, --help                            display help for command4.5 Commands: Inside the dev container​prisma​You can run all the prisma commands in your project root directory inside the dev container. This command is useful for db migration and introspection. Read more here. $ godspeed prisma <prisma command with args>build​You can build the complete project using this command. It is the first command which you need to run whenever you open your project in VScode Dev container. Refer Open in Dev containergodspeed builddev​You can run your project using dev command.godspeed servegen-api-docs​You can get OAS 3 documentation generated automatically by executing this command in your project root directory inside the dev container.$ godspeed gen-api-docs                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529346164] INFO (GS-logger/7684 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529346190] DEBUG (GS-logger/7684 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529346289] INFO (GS-logger/7684 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Postman collection​step1: After executing $ godspeed gen-api-docs
go to docs under app and right click on api-doc.yaml file and download itstep2: In postman import the downloaded file in collection(collection->import->files->select-file.yaml-> import ) and test your apigen-test-suite​You can get test suite/postman collection generated automatically by executing this command in your project root directory inside the dev container. Now, you can import the collection in postman directly. godspeed gen-test-suite                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-test-suite> npm run gen-api-docs && mkdir -p tests && openapi2postmanv2 -s docs/api-doc.yaml -o tests/test-suite.json -p -O folderStrategy=Tags,includeAuthInfoInExample=false> proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529443249] INFO (GS-logger/8145 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529443273] DEBUG (GS-logger/8145 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529443374] INFO (GS-logger/8145 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Input file:  /workspace/development/app/docs/api-doc.yamlWriting to file:  true /workspace/development/app/tests/test-suite.json { result: true, output: [ { type: 'collection', data: [Object] } ] }Conversion successful, collection written to filegen-crud-api​You can get CRUD API generated automatically for datastores and elasticgraph datasources by executing this command in your project root directory inside the dev container.$ godspeed gen-crud-api                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > eg_test@1.0.0 gen-crud-api> npx godspeed-crud-api-generatorSelect datasource / schema to generate CRUD APIs(x) elasticgraph.yaml( ) For all( ) Canceltest​You can run the test suite generated in above command from the following two ways:Postman: Import the collection in postman and run the test suite.CLI: You can use below command to run the test suite from CLI.Please make sure your service is up and running before running the test suite. godspeed test                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 test> newman run tests/test-suite.jsonnewmanGodspeed: Sample Microservice→ Call another (sub) workflow from main workflow  POST http://localhost:3000/another_workflow?bank_id=<string> [200 OK, 630B, 2.6s]. . . . . . . . help​The help command displays help and usage for any command. Click here to know more4.6 Generating Elasticgraph model from prisma schema​generate-elasticgraph-model​You can convert the prisma schema to elasticgraph model by executing this commmand in your project root directory inside the dev container.$ godspeed generate-elasticgraph-model                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed generate-elasticgraph-model [egClientName]Enter the input path  : Enter the output path :Elasticgraph model generatednote[egClientName] (optional): Specifies the name of the Elasticgraph client to be generated. If not provided, the default name eg-model will be used.If the specified input path does not exist, the CLI will display an error message.If the specified output path does not exist, the folder will be generated with [egClientName].Edit this pagePrevious3.6 Debugger in YamlNext5. Swagger Specs4.1 FunctionalityOutside the dev containerInside the dev container4.2 Installation4.3 Options--version (-v)--help (-h)4.4 Commands: Outside the dev containercreateupdateversionsversionhelp4.5 Commands: Inside the dev containerprismabuilddevgen-api-docsPostman collectiongen-test-suitegen-crud-apitesthelp4.6 Generating Elasticgraph model from prisma schemagenerate-elasticgraph-modelForumDiscordGithubTwitterLinkedIn








Introduction to Godspeed CLI | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).4. CLIVersion: v1On this pageGodspeed CLIThe CLI is the primary way to interact with your Godspeed project from the command line. It provides a bunch of useful functionalities during the project development lifecycle.4.1 Functionality​Outside the dev container​Creating a new project environment with dev container setup, which includes the folder structure, all the databases, message bus, cache, etc.Open up an existing project in the dev container, add/update a container in the dev environment, based on updated settings.List the versions of gs_service.Change the version of gs_service.Inside the dev container​All Prisma commands including DB push, pull or migration.OAS 3 documentation file generation.Test suite/Postman collection generation.Running test suite.4.2 Installation​npm install -g @mindgrep/godspeedOnce Godspeed CLI is installed, the godspeed command can be called from command line. When called without arguments, it displays its help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.3 Options​--version (-v)​The --version option outputs information about your current godspeed version.$ godspeed -v                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          0.0.26--help (-h)​The --help option displays help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.4 Commands: Outside the dev container​create​The create command creates project structure for any microservice. When called without arguments, it creates project structure with examples.$ godspeed create my_service                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          projectDir:  /home/gurjot/cli-test/my_service projectTemplateDir undefinedproject createdDo you need mongodb? [y/n] [default: n] nDo you need postgresdb? [y/n] [default: n] yPlease enter name of the postgres database [default: test] Do you need kafka? [y/n] [default: n] nDo you need elastisearch? [y/n] [default: n] nPlease enter host port on which you want to run your service [default: 3000] 3100Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13Enter your version [default: latest] 1.0.13Selected version 1.0.13. . . . . . . . Options​$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <existing_project_directory>  existing project template dir  -h, --help                            display help for commandupdate​The update can be executed in the following cases:If you want to launch an existing project (i.e. copied from local/cloned from repo) instead of creating a new one, then execute godspeed update command before launching the project.If you want to reloads the containers with updated project settings. For example, if you have not selected any database during the project creation and you want to include any database in the project later on, then execute godspeed update with the required settings.If there is any change in gs_service image of standard tags (e.g. latest, stable) and you want to fetch the latest code for the same tag, then execute godspeed updatecommand. It fetches the new docker image itself.Please note that the command should be executed from inside the project root directory.noteWhenever you update your project using godspeed update and open the project in VScode dev container after update, then it is mandatory to do godspeed build inside dev container for the first time.$ godspeed update                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Do you need postgresdb? [y/n] [default: n] Do you need kafka? [y/n] [default: n] Do you need elastisearch? [y/n] [default: n] Please enter host port on which you want to run your service [default: 3000] Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.21.0.31.0.4devstableEnter your version [default: latest] Selected version latestRemoving dev_test_devcontainer_node_1                ... . . . . . . . . . .Step 1/9 : FROM adminmindgrep/gs_service:latestlatest: Pulling from adminmindgrep/gs_service824b15f81d65: Already exists325d38bcb229: Already existsd6d638bf61bf: Already exists55daac95cedf: Already exists4c701498752d: Already existsa48b0ae49665: Pulling fs layer4c393fb6deac: Pulling fs layer4f4fb700ef54: Pulling fs layer8992963a9530: Pulling fs layer4f4fb700ef54: Verifying Checksum4f4fb700ef54: Download complete4c393fb6deac: Verifying Checksum4c393fb6deac: Download complete8992963a9530: Verifying Checksum8992963a9530: Download completea48b0ae49665: Verifying Checksuma48b0ae49665: Download completea48b0ae49665: Pull complete4c393fb6deac: Pull complete4f4fb700ef54: Pull complete8992963a9530: Pull completeDigest: sha256:7195b3c921f1278153c911e6e77cbcfb385a84c435bfcb7b8272ffcf9a3278eeStatus: Downloaded newer image for adminmindgrep/gs_service:latest ---> 988917710d1aStep 2/9 : ARG USERNAME=node ---> Running in c70404bb4f3eRemoving intermediate container c70404bb4f3e ---> 47a7406b2473Step 3/9 : ARG USER_UID=1000 ---> Running in 51e68336d8d8Removing intermediate container 51e68336d8d8 ---> ce913f6898bbStep 4/9 : ARG USER_GID=$USER_UID ---> Running in 7cf1c1f2a3ecRemoving intermediate container 7cf1c1f2a3ec ---> 91f045b32e0fStep 5/9 : USER root ---> Running in f338d755a032Removing intermediate container f338d755a032 ---> fa9898eb4c23Step 6/9 : RUN sudo groupmod --gid $USER_GID $USERNAME     && usermod --uid $USER_UID --gid $USER_GID $USERNAME     && chown -R $USER_UID:$USER_GID /workspace/development ---> Running in eba3659fb919Removing intermediate container eba3659fb919 ---> 414f34560b0dStep 7/9 : USER node ---> Running in 23818c5f4882Removing intermediate container 23818c5f4882 ---> 1bd65323ae91Step 8/9 : RUN sudo npm i -g @mindgrep/godspeed ---> Running in a66cb062390d. . . . . . . . . . godspeed update dev_test is done.versions​The versions command lists all the versions available of gs_service.$ godspeed versions                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13version​The version command helps to change the version of gs_service for any microservice. Execute the command from inside the project root directory.$ godspeed version 1.0.13                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Generating prisma modulesStarting test1_devcontainer_postgres_1 ... Starting test1_devcontainer_postgres_1 ... doneCreating test1_devcontainer_node_run   ... Creating test1_devcontainer_node_run   ... doneEnvironment variables loaded from .env. . . . . . . . . .help​The help command displays help and usage for any command.$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <projectTemplateDir>  local project template dir  -h, --help                            display help for command4.5 Commands: Inside the dev container​prisma​You can run all the prisma commands in your project root directory inside the dev container. This command is useful for db migration and introspection. Read more here. $ godspeed prisma <prisma command with args>build​You can build the complete project using this command. It is the first command which you need to run whenever you open your project in VScode Dev container. Refer Open in Dev containergodspeed builddev​You can run your project using dev command.godspeed servegen-api-docs​You can get OAS 3 documentation generated automatically by executing this command in your project root directory inside the dev container.$ godspeed gen-api-docs                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529346164] INFO (GS-logger/7684 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529346190] DEBUG (GS-logger/7684 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529346289] INFO (GS-logger/7684 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Postman collection​step1: After executing $ godspeed gen-api-docs
go to docs under app and right click on api-doc.yaml file and download itstep2: In postman import the downloaded file in collection(collection->import->files->select-file.yaml-> import ) and test your apigen-test-suite​You can get test suite/postman collection generated automatically by executing this command in your project root directory inside the dev container. Now, you can import the collection in postman directly. godspeed gen-test-suite                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-test-suite> npm run gen-api-docs && mkdir -p tests && openapi2postmanv2 -s docs/api-doc.yaml -o tests/test-suite.json -p -O folderStrategy=Tags,includeAuthInfoInExample=false> proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529443249] INFO (GS-logger/8145 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529443273] DEBUG (GS-logger/8145 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529443374] INFO (GS-logger/8145 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Input file:  /workspace/development/app/docs/api-doc.yamlWriting to file:  true /workspace/development/app/tests/test-suite.json { result: true, output: [ { type: 'collection', data: [Object] } ] }Conversion successful, collection written to filegen-crud-api​You can get CRUD API generated automatically for datastores and elasticgraph datasources by executing this command in your project root directory inside the dev container.$ godspeed gen-crud-api                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > eg_test@1.0.0 gen-crud-api> npx godspeed-crud-api-generatorSelect datasource / schema to generate CRUD APIs(x) elasticgraph.yaml( ) For all( ) Canceltest​You can run the test suite generated in above command from the following two ways:Postman: Import the collection in postman and run the test suite.CLI: You can use below command to run the test suite from CLI.Please make sure your service is up and running before running the test suite. godspeed test                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 test> newman run tests/test-suite.jsonnewmanGodspeed: Sample Microservice→ Call another (sub) workflow from main workflow  POST http://localhost:3000/another_workflow?bank_id=<string> [200 OK, 630B, 2.6s]. . . . . . . . help​The help command displays help and usage for any command. Click here to know more4.6 Generating Elasticgraph model from prisma schema​generate-elasticgraph-model​You can convert the prisma schema to elasticgraph model by executing this commmand in your project root directory inside the dev container.$ godspeed generate-elasticgraph-model                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed generate-elasticgraph-model [egClientName]Enter the input path  : Enter the output path :Elasticgraph model generatednote[egClientName] (optional): Specifies the name of the Elasticgraph client to be generated. If not provided, the default name eg-model will be used.If the specified input path does not exist, the CLI will display an error message.If the specified output path does not exist, the folder will be generated with [egClientName].Edit this pagePrevious3.6 Debugger in YamlNext5. Swagger Specs4.1 FunctionalityOutside the dev containerInside the dev container4.2 Installation4.3 Options--version (-v)--help (-h)4.4 Commands: Outside the dev containercreateupdateversionsversionhelp4.5 Commands: Inside the dev containerprismabuilddevgen-api-docsPostman collectiongen-test-suitegen-crud-apitesthelp4.6 Generating Elasticgraph model from prisma schemagenerate-elasticgraph-modelForumDiscordGithubTwitterLinkedIn








Introduction to Godspeed CLI | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).4. CLIVersion: v1On this pageGodspeed CLIThe CLI is the primary way to interact with your Godspeed project from the command line. It provides a bunch of useful functionalities during the project development lifecycle.4.1 Functionality​Outside the dev container​Creating a new project environment with dev container setup, which includes the folder structure, all the databases, message bus, cache, etc.Open up an existing project in the dev container, add/update a container in the dev environment, based on updated settings.List the versions of gs_service.Change the version of gs_service.Inside the dev container​All Prisma commands including DB push, pull or migration.OAS 3 documentation file generation.Test suite/Postman collection generation.Running test suite.4.2 Installation​npm install -g @mindgrep/godspeedOnce Godspeed CLI is installed, the godspeed command can be called from command line. When called without arguments, it displays its help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.3 Options​--version (-v)​The --version option outputs information about your current godspeed version.$ godspeed -v                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          0.0.26--help (-h)​The --help option displays help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.4 Commands: Outside the dev container​create​The create command creates project structure for any microservice. When called without arguments, it creates project structure with examples.$ godspeed create my_service                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          projectDir:  /home/gurjot/cli-test/my_service projectTemplateDir undefinedproject createdDo you need mongodb? [y/n] [default: n] nDo you need postgresdb? [y/n] [default: n] yPlease enter name of the postgres database [default: test] Do you need kafka? [y/n] [default: n] nDo you need elastisearch? [y/n] [default: n] nPlease enter host port on which you want to run your service [default: 3000] 3100Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13Enter your version [default: latest] 1.0.13Selected version 1.0.13. . . . . . . . Options​$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <existing_project_directory>  existing project template dir  -h, --help                            display help for commandupdate​The update can be executed in the following cases:If you want to launch an existing project (i.e. copied from local/cloned from repo) instead of creating a new one, then execute godspeed update command before launching the project.If you want to reloads the containers with updated project settings. For example, if you have not selected any database during the project creation and you want to include any database in the project later on, then execute godspeed update with the required settings.If there is any change in gs_service image of standard tags (e.g. latest, stable) and you want to fetch the latest code for the same tag, then execute godspeed updatecommand. It fetches the new docker image itself.Please note that the command should be executed from inside the project root directory.noteWhenever you update your project using godspeed update and open the project in VScode dev container after update, then it is mandatory to do godspeed build inside dev container for the first time.$ godspeed update                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Do you need postgresdb? [y/n] [default: n] Do you need kafka? [y/n] [default: n] Do you need elastisearch? [y/n] [default: n] Please enter host port on which you want to run your service [default: 3000] Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.21.0.31.0.4devstableEnter your version [default: latest] Selected version latestRemoving dev_test_devcontainer_node_1                ... . . . . . . . . . .Step 1/9 : FROM adminmindgrep/gs_service:latestlatest: Pulling from adminmindgrep/gs_service824b15f81d65: Already exists325d38bcb229: Already existsd6d638bf61bf: Already exists55daac95cedf: Already exists4c701498752d: Already existsa48b0ae49665: Pulling fs layer4c393fb6deac: Pulling fs layer4f4fb700ef54: Pulling fs layer8992963a9530: Pulling fs layer4f4fb700ef54: Verifying Checksum4f4fb700ef54: Download complete4c393fb6deac: Verifying Checksum4c393fb6deac: Download complete8992963a9530: Verifying Checksum8992963a9530: Download completea48b0ae49665: Verifying Checksuma48b0ae49665: Download completea48b0ae49665: Pull complete4c393fb6deac: Pull complete4f4fb700ef54: Pull complete8992963a9530: Pull completeDigest: sha256:7195b3c921f1278153c911e6e77cbcfb385a84c435bfcb7b8272ffcf9a3278eeStatus: Downloaded newer image for adminmindgrep/gs_service:latest ---> 988917710d1aStep 2/9 : ARG USERNAME=node ---> Running in c70404bb4f3eRemoving intermediate container c70404bb4f3e ---> 47a7406b2473Step 3/9 : ARG USER_UID=1000 ---> Running in 51e68336d8d8Removing intermediate container 51e68336d8d8 ---> ce913f6898bbStep 4/9 : ARG USER_GID=$USER_UID ---> Running in 7cf1c1f2a3ecRemoving intermediate container 7cf1c1f2a3ec ---> 91f045b32e0fStep 5/9 : USER root ---> Running in f338d755a032Removing intermediate container f338d755a032 ---> fa9898eb4c23Step 6/9 : RUN sudo groupmod --gid $USER_GID $USERNAME     && usermod --uid $USER_UID --gid $USER_GID $USERNAME     && chown -R $USER_UID:$USER_GID /workspace/development ---> Running in eba3659fb919Removing intermediate container eba3659fb919 ---> 414f34560b0dStep 7/9 : USER node ---> Running in 23818c5f4882Removing intermediate container 23818c5f4882 ---> 1bd65323ae91Step 8/9 : RUN sudo npm i -g @mindgrep/godspeed ---> Running in a66cb062390d. . . . . . . . . . godspeed update dev_test is done.versions​The versions command lists all the versions available of gs_service.$ godspeed versions                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13version​The version command helps to change the version of gs_service for any microservice. Execute the command from inside the project root directory.$ godspeed version 1.0.13                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Generating prisma modulesStarting test1_devcontainer_postgres_1 ... Starting test1_devcontainer_postgres_1 ... doneCreating test1_devcontainer_node_run   ... Creating test1_devcontainer_node_run   ... doneEnvironment variables loaded from .env. . . . . . . . . .help​The help command displays help and usage for any command.$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <projectTemplateDir>  local project template dir  -h, --help                            display help for command4.5 Commands: Inside the dev container​prisma​You can run all the prisma commands in your project root directory inside the dev container. This command is useful for db migration and introspection. Read more here. $ godspeed prisma <prisma command with args>build​You can build the complete project using this command. It is the first command which you need to run whenever you open your project in VScode Dev container. Refer Open in Dev containergodspeed builddev​You can run your project using dev command.godspeed servegen-api-docs​You can get OAS 3 documentation generated automatically by executing this command in your project root directory inside the dev container.$ godspeed gen-api-docs                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529346164] INFO (GS-logger/7684 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529346190] DEBUG (GS-logger/7684 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529346289] INFO (GS-logger/7684 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Postman collection​step1: After executing $ godspeed gen-api-docs
go to docs under app and right click on api-doc.yaml file and download itstep2: In postman import the downloaded file in collection(collection->import->files->select-file.yaml-> import ) and test your apigen-test-suite​You can get test suite/postman collection generated automatically by executing this command in your project root directory inside the dev container. Now, you can import the collection in postman directly. godspeed gen-test-suite                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-test-suite> npm run gen-api-docs && mkdir -p tests && openapi2postmanv2 -s docs/api-doc.yaml -o tests/test-suite.json -p -O folderStrategy=Tags,includeAuthInfoInExample=false> proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529443249] INFO (GS-logger/8145 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529443273] DEBUG (GS-logger/8145 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529443374] INFO (GS-logger/8145 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Input file:  /workspace/development/app/docs/api-doc.yamlWriting to file:  true /workspace/development/app/tests/test-suite.json { result: true, output: [ { type: 'collection', data: [Object] } ] }Conversion successful, collection written to filegen-crud-api​You can get CRUD API generated automatically for datastores and elasticgraph datasources by executing this command in your project root directory inside the dev container.$ godspeed gen-crud-api                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > eg_test@1.0.0 gen-crud-api> npx godspeed-crud-api-generatorSelect datasource / schema to generate CRUD APIs(x) elasticgraph.yaml( ) For all( ) Canceltest​You can run the test suite generated in above command from the following two ways:Postman: Import the collection in postman and run the test suite.CLI: You can use below command to run the test suite from CLI.Please make sure your service is up and running before running the test suite. godspeed test                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 test> newman run tests/test-suite.jsonnewmanGodspeed: Sample Microservice→ Call another (sub) workflow from main workflow  POST http://localhost:3000/another_workflow?bank_id=<string> [200 OK, 630B, 2.6s]. . . . . . . . help​The help command displays help and usage for any command. Click here to know more4.6 Generating Elasticgraph model from prisma schema​generate-elasticgraph-model​You can convert the prisma schema to elasticgraph model by executing this commmand in your project root directory inside the dev container.$ godspeed generate-elasticgraph-model                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed generate-elasticgraph-model [egClientName]Enter the input path  : Enter the output path :Elasticgraph model generatednote[egClientName] (optional): Specifies the name of the Elasticgraph client to be generated. If not provided, the default name eg-model will be used.If the specified input path does not exist, the CLI will display an error message.If the specified output path does not exist, the folder will be generated with [egClientName].Edit this pagePrevious3.6 Debugger in YamlNext5. Swagger Specs4.1 FunctionalityOutside the dev containerInside the dev container4.2 Installation4.3 Options--version (-v)--help (-h)4.4 Commands: Outside the dev containercreateupdateversionsversionhelp4.5 Commands: Inside the dev containerprismabuilddevgen-api-docsPostman collectiongen-test-suitegen-crud-apitesthelp4.6 Generating Elasticgraph model from prisma schemagenerate-elasticgraph-modelForumDiscordGithubTwitterLinkedIn








Introduction to Godspeed CLI | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).4. CLIVersion: v1On this pageGodspeed CLIThe CLI is the primary way to interact with your Godspeed project from the command line. It provides a bunch of useful functionalities during the project development lifecycle.4.1 Functionality​Outside the dev container​Creating a new project environment with dev container setup, which includes the folder structure, all the databases, message bus, cache, etc.Open up an existing project in the dev container, add/update a container in the dev environment, based on updated settings.List the versions of gs_service.Change the version of gs_service.Inside the dev container​All Prisma commands including DB push, pull or migration.OAS 3 documentation file generation.Test suite/Postman collection generation.Running test suite.4.2 Installation​npm install -g @mindgrep/godspeedOnce Godspeed CLI is installed, the godspeed command can be called from command line. When called without arguments, it displays its help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.3 Options​--version (-v)​The --version option outputs information about your current godspeed version.$ godspeed -v                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          0.0.26--help (-h)​The --help option displays help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.4 Commands: Outside the dev container​create​The create command creates project structure for any microservice. When called without arguments, it creates project structure with examples.$ godspeed create my_service                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          projectDir:  /home/gurjot/cli-test/my_service projectTemplateDir undefinedproject createdDo you need mongodb? [y/n] [default: n] nDo you need postgresdb? [y/n] [default: n] yPlease enter name of the postgres database [default: test] Do you need kafka? [y/n] [default: n] nDo you need elastisearch? [y/n] [default: n] nPlease enter host port on which you want to run your service [default: 3000] 3100Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13Enter your version [default: latest] 1.0.13Selected version 1.0.13. . . . . . . . Options​$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <existing_project_directory>  existing project template dir  -h, --help                            display help for commandupdate​The update can be executed in the following cases:If you want to launch an existing project (i.e. copied from local/cloned from repo) instead of creating a new one, then execute godspeed update command before launching the project.If you want to reloads the containers with updated project settings. For example, if you have not selected any database during the project creation and you want to include any database in the project later on, then execute godspeed update with the required settings.If there is any change in gs_service image of standard tags (e.g. latest, stable) and you want to fetch the latest code for the same tag, then execute godspeed updatecommand. It fetches the new docker image itself.Please note that the command should be executed from inside the project root directory.noteWhenever you update your project using godspeed update and open the project in VScode dev container after update, then it is mandatory to do godspeed build inside dev container for the first time.$ godspeed update                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Do you need postgresdb? [y/n] [default: n] Do you need kafka? [y/n] [default: n] Do you need elastisearch? [y/n] [default: n] Please enter host port on which you want to run your service [default: 3000] Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.21.0.31.0.4devstableEnter your version [default: latest] Selected version latestRemoving dev_test_devcontainer_node_1                ... . . . . . . . . . .Step 1/9 : FROM adminmindgrep/gs_service:latestlatest: Pulling from adminmindgrep/gs_service824b15f81d65: Already exists325d38bcb229: Already existsd6d638bf61bf: Already exists55daac95cedf: Already exists4c701498752d: Already existsa48b0ae49665: Pulling fs layer4c393fb6deac: Pulling fs layer4f4fb700ef54: Pulling fs layer8992963a9530: Pulling fs layer4f4fb700ef54: Verifying Checksum4f4fb700ef54: Download complete4c393fb6deac: Verifying Checksum4c393fb6deac: Download complete8992963a9530: Verifying Checksum8992963a9530: Download completea48b0ae49665: Verifying Checksuma48b0ae49665: Download completea48b0ae49665: Pull complete4c393fb6deac: Pull complete4f4fb700ef54: Pull complete8992963a9530: Pull completeDigest: sha256:7195b3c921f1278153c911e6e77cbcfb385a84c435bfcb7b8272ffcf9a3278eeStatus: Downloaded newer image for adminmindgrep/gs_service:latest ---> 988917710d1aStep 2/9 : ARG USERNAME=node ---> Running in c70404bb4f3eRemoving intermediate container c70404bb4f3e ---> 47a7406b2473Step 3/9 : ARG USER_UID=1000 ---> Running in 51e68336d8d8Removing intermediate container 51e68336d8d8 ---> ce913f6898bbStep 4/9 : ARG USER_GID=$USER_UID ---> Running in 7cf1c1f2a3ecRemoving intermediate container 7cf1c1f2a3ec ---> 91f045b32e0fStep 5/9 : USER root ---> Running in f338d755a032Removing intermediate container f338d755a032 ---> fa9898eb4c23Step 6/9 : RUN sudo groupmod --gid $USER_GID $USERNAME     && usermod --uid $USER_UID --gid $USER_GID $USERNAME     && chown -R $USER_UID:$USER_GID /workspace/development ---> Running in eba3659fb919Removing intermediate container eba3659fb919 ---> 414f34560b0dStep 7/9 : USER node ---> Running in 23818c5f4882Removing intermediate container 23818c5f4882 ---> 1bd65323ae91Step 8/9 : RUN sudo npm i -g @mindgrep/godspeed ---> Running in a66cb062390d. . . . . . . . . . godspeed update dev_test is done.versions​The versions command lists all the versions available of gs_service.$ godspeed versions                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13version​The version command helps to change the version of gs_service for any microservice. Execute the command from inside the project root directory.$ godspeed version 1.0.13                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Generating prisma modulesStarting test1_devcontainer_postgres_1 ... Starting test1_devcontainer_postgres_1 ... doneCreating test1_devcontainer_node_run   ... Creating test1_devcontainer_node_run   ... doneEnvironment variables loaded from .env. . . . . . . . . .help​The help command displays help and usage for any command.$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <projectTemplateDir>  local project template dir  -h, --help                            display help for command4.5 Commands: Inside the dev container​prisma​You can run all the prisma commands in your project root directory inside the dev container. This command is useful for db migration and introspection. Read more here. $ godspeed prisma <prisma command with args>build​You can build the complete project using this command. It is the first command which you need to run whenever you open your project in VScode Dev container. Refer Open in Dev containergodspeed builddev​You can run your project using dev command.godspeed servegen-api-docs​You can get OAS 3 documentation generated automatically by executing this command in your project root directory inside the dev container.$ godspeed gen-api-docs                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529346164] INFO (GS-logger/7684 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529346190] DEBUG (GS-logger/7684 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529346289] INFO (GS-logger/7684 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Postman collection​step1: After executing $ godspeed gen-api-docs
go to docs under app and right click on api-doc.yaml file and download itstep2: In postman import the downloaded file in collection(collection->import->files->select-file.yaml-> import ) and test your apigen-test-suite​You can get test suite/postman collection generated automatically by executing this command in your project root directory inside the dev container. Now, you can import the collection in postman directly. godspeed gen-test-suite                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-test-suite> npm run gen-api-docs && mkdir -p tests && openapi2postmanv2 -s docs/api-doc.yaml -o tests/test-suite.json -p -O folderStrategy=Tags,includeAuthInfoInExample=false> proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529443249] INFO (GS-logger/8145 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529443273] DEBUG (GS-logger/8145 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529443374] INFO (GS-logger/8145 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Input file:  /workspace/development/app/docs/api-doc.yamlWriting to file:  true /workspace/development/app/tests/test-suite.json { result: true, output: [ { type: 'collection', data: [Object] } ] }Conversion successful, collection written to filegen-crud-api​You can get CRUD API generated automatically for datastores and elasticgraph datasources by executing this command in your project root directory inside the dev container.$ godspeed gen-crud-api                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > eg_test@1.0.0 gen-crud-api> npx godspeed-crud-api-generatorSelect datasource / schema to generate CRUD APIs(x) elasticgraph.yaml( ) For all( ) Canceltest​You can run the test suite generated in above command from the following two ways:Postman: Import the collection in postman and run the test suite.CLI: You can use below command to run the test suite from CLI.Please make sure your service is up and running before running the test suite. godspeed test                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 test> newman run tests/test-suite.jsonnewmanGodspeed: Sample Microservice→ Call another (sub) workflow from main workflow  POST http://localhost:3000/another_workflow?bank_id=<string> [200 OK, 630B, 2.6s]. . . . . . . . help​The help command displays help and usage for any command. Click here to know more4.6 Generating Elasticgraph model from prisma schema​generate-elasticgraph-model​You can convert the prisma schema to elasticgraph model by executing this commmand in your project root directory inside the dev container.$ godspeed generate-elasticgraph-model                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed generate-elasticgraph-model [egClientName]Enter the input path  : Enter the output path :Elasticgraph model generatednote[egClientName] (optional): Specifies the name of the Elasticgraph client to be generated. If not provided, the default name eg-model will be used.If the specified input path does not exist, the CLI will display an error message.If the specified output path does not exist, the folder will be generated with [egClientName].Edit this pagePrevious3.6 Debugger in YamlNext5. Swagger Specs4.1 FunctionalityOutside the dev containerInside the dev container4.2 Installation4.3 Options--version (-v)--help (-h)4.4 Commands: Outside the dev containercreateupdateversionsversionhelp4.5 Commands: Inside the dev containerprismabuilddevgen-api-docsPostman collectiongen-test-suitegen-crud-apitesthelp4.6 Generating Elasticgraph model from prisma schemagenerate-elasticgraph-modelForumDiscordGithubTwitterLinkedIn








Introduction to Godspeed CLI | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).4. CLIVersion: v1On this pageGodspeed CLIThe CLI is the primary way to interact with your Godspeed project from the command line. It provides a bunch of useful functionalities during the project development lifecycle.4.1 Functionality​Outside the dev container​Creating a new project environment with dev container setup, which includes the folder structure, all the databases, message bus, cache, etc.Open up an existing project in the dev container, add/update a container in the dev environment, based on updated settings.List the versions of gs_service.Change the version of gs_service.Inside the dev container​All Prisma commands including DB push, pull or migration.OAS 3 documentation file generation.Test suite/Postman collection generation.Running test suite.4.2 Installation​npm install -g @mindgrep/godspeedOnce Godspeed CLI is installed, the godspeed command can be called from command line. When called without arguments, it displays its help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.3 Options​--version (-v)​The --version option outputs information about your current godspeed version.$ godspeed -v                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          0.0.26--help (-h)​The --help option displays help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.4 Commands: Outside the dev container​create​The create command creates project structure for any microservice. When called without arguments, it creates project structure with examples.$ godspeed create my_service                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          projectDir:  /home/gurjot/cli-test/my_service projectTemplateDir undefinedproject createdDo you need mongodb? [y/n] [default: n] nDo you need postgresdb? [y/n] [default: n] yPlease enter name of the postgres database [default: test] Do you need kafka? [y/n] [default: n] nDo you need elastisearch? [y/n] [default: n] nPlease enter host port on which you want to run your service [default: 3000] 3100Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13Enter your version [default: latest] 1.0.13Selected version 1.0.13. . . . . . . . Options​$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <existing_project_directory>  existing project template dir  -h, --help                            display help for commandupdate​The update can be executed in the following cases:If you want to launch an existing project (i.e. copied from local/cloned from repo) instead of creating a new one, then execute godspeed update command before launching the project.If you want to reloads the containers with updated project settings. For example, if you have not selected any database during the project creation and you want to include any database in the project later on, then execute godspeed update with the required settings.If there is any change in gs_service image of standard tags (e.g. latest, stable) and you want to fetch the latest code for the same tag, then execute godspeed updatecommand. It fetches the new docker image itself.Please note that the command should be executed from inside the project root directory.noteWhenever you update your project using godspeed update and open the project in VScode dev container after update, then it is mandatory to do godspeed build inside dev container for the first time.$ godspeed update                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Do you need postgresdb? [y/n] [default: n] Do you need kafka? [y/n] [default: n] Do you need elastisearch? [y/n] [default: n] Please enter host port on which you want to run your service [default: 3000] Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.21.0.31.0.4devstableEnter your version [default: latest] Selected version latestRemoving dev_test_devcontainer_node_1                ... . . . . . . . . . .Step 1/9 : FROM adminmindgrep/gs_service:latestlatest: Pulling from adminmindgrep/gs_service824b15f81d65: Already exists325d38bcb229: Already existsd6d638bf61bf: Already exists55daac95cedf: Already exists4c701498752d: Already existsa48b0ae49665: Pulling fs layer4c393fb6deac: Pulling fs layer4f4fb700ef54: Pulling fs layer8992963a9530: Pulling fs layer4f4fb700ef54: Verifying Checksum4f4fb700ef54: Download complete4c393fb6deac: Verifying Checksum4c393fb6deac: Download complete8992963a9530: Verifying Checksum8992963a9530: Download completea48b0ae49665: Verifying Checksuma48b0ae49665: Download completea48b0ae49665: Pull complete4c393fb6deac: Pull complete4f4fb700ef54: Pull complete8992963a9530: Pull completeDigest: sha256:7195b3c921f1278153c911e6e77cbcfb385a84c435bfcb7b8272ffcf9a3278eeStatus: Downloaded newer image for adminmindgrep/gs_service:latest ---> 988917710d1aStep 2/9 : ARG USERNAME=node ---> Running in c70404bb4f3eRemoving intermediate container c70404bb4f3e ---> 47a7406b2473Step 3/9 : ARG USER_UID=1000 ---> Running in 51e68336d8d8Removing intermediate container 51e68336d8d8 ---> ce913f6898bbStep 4/9 : ARG USER_GID=$USER_UID ---> Running in 7cf1c1f2a3ecRemoving intermediate container 7cf1c1f2a3ec ---> 91f045b32e0fStep 5/9 : USER root ---> Running in f338d755a032Removing intermediate container f338d755a032 ---> fa9898eb4c23Step 6/9 : RUN sudo groupmod --gid $USER_GID $USERNAME     && usermod --uid $USER_UID --gid $USER_GID $USERNAME     && chown -R $USER_UID:$USER_GID /workspace/development ---> Running in eba3659fb919Removing intermediate container eba3659fb919 ---> 414f34560b0dStep 7/9 : USER node ---> Running in 23818c5f4882Removing intermediate container 23818c5f4882 ---> 1bd65323ae91Step 8/9 : RUN sudo npm i -g @mindgrep/godspeed ---> Running in a66cb062390d. . . . . . . . . . godspeed update dev_test is done.versions​The versions command lists all the versions available of gs_service.$ godspeed versions                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13version​The version command helps to change the version of gs_service for any microservice. Execute the command from inside the project root directory.$ godspeed version 1.0.13                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Generating prisma modulesStarting test1_devcontainer_postgres_1 ... Starting test1_devcontainer_postgres_1 ... doneCreating test1_devcontainer_node_run   ... Creating test1_devcontainer_node_run   ... doneEnvironment variables loaded from .env. . . . . . . . . .help​The help command displays help and usage for any command.$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <projectTemplateDir>  local project template dir  -h, --help                            display help for command4.5 Commands: Inside the dev container​prisma​You can run all the prisma commands in your project root directory inside the dev container. This command is useful for db migration and introspection. Read more here. $ godspeed prisma <prisma command with args>build​You can build the complete project using this command. It is the first command which you need to run whenever you open your project in VScode Dev container. Refer Open in Dev containergodspeed builddev​You can run your project using dev command.godspeed servegen-api-docs​You can get OAS 3 documentation generated automatically by executing this command in your project root directory inside the dev container.$ godspeed gen-api-docs                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529346164] INFO (GS-logger/7684 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529346190] DEBUG (GS-logger/7684 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529346289] INFO (GS-logger/7684 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Postman collection​step1: After executing $ godspeed gen-api-docs
go to docs under app and right click on api-doc.yaml file and download itstep2: In postman import the downloaded file in collection(collection->import->files->select-file.yaml-> import ) and test your apigen-test-suite​You can get test suite/postman collection generated automatically by executing this command in your project root directory inside the dev container. Now, you can import the collection in postman directly. godspeed gen-test-suite                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-test-suite> npm run gen-api-docs && mkdir -p tests && openapi2postmanv2 -s docs/api-doc.yaml -o tests/test-suite.json -p -O folderStrategy=Tags,includeAuthInfoInExample=false> proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529443249] INFO (GS-logger/8145 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529443273] DEBUG (GS-logger/8145 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529443374] INFO (GS-logger/8145 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Input file:  /workspace/development/app/docs/api-doc.yamlWriting to file:  true /workspace/development/app/tests/test-suite.json { result: true, output: [ { type: 'collection', data: [Object] } ] }Conversion successful, collection written to filegen-crud-api​You can get CRUD API generated automatically for datastores and elasticgraph datasources by executing this command in your project root directory inside the dev container.$ godspeed gen-crud-api                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > eg_test@1.0.0 gen-crud-api> npx godspeed-crud-api-generatorSelect datasource / schema to generate CRUD APIs(x) elasticgraph.yaml( ) For all( ) Canceltest​You can run the test suite generated in above command from the following two ways:Postman: Import the collection in postman and run the test suite.CLI: You can use below command to run the test suite from CLI.Please make sure your service is up and running before running the test suite. godspeed test                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 test> newman run tests/test-suite.jsonnewmanGodspeed: Sample Microservice→ Call another (sub) workflow from main workflow  POST http://localhost:3000/another_workflow?bank_id=<string> [200 OK, 630B, 2.6s]. . . . . . . . help​The help command displays help and usage for any command. Click here to know more4.6 Generating Elasticgraph model from prisma schema​generate-elasticgraph-model​You can convert the prisma schema to elasticgraph model by executing this commmand in your project root directory inside the dev container.$ godspeed generate-elasticgraph-model                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed generate-elasticgraph-model [egClientName]Enter the input path  : Enter the output path :Elasticgraph model generatednote[egClientName] (optional): Specifies the name of the Elasticgraph client to be generated. If not provided, the default name eg-model will be used.If the specified input path does not exist, the CLI will display an error message.If the specified output path does not exist, the folder will be generated with [egClientName].Edit this pagePrevious3.6 Debugger in YamlNext5. Swagger Specs4.1 FunctionalityOutside the dev containerInside the dev container4.2 Installation4.3 Options--version (-v)--help (-h)4.4 Commands: Outside the dev containercreateupdateversionsversionhelp4.5 Commands: Inside the dev containerprismabuilddevgen-api-docsPostman collectiongen-test-suitegen-crud-apitesthelp4.6 Generating Elasticgraph model from prisma schemagenerate-elasticgraph-modelForumDiscordGithubTwitterLinkedIn








Introduction to Godspeed CLI | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).4. CLIVersion: v1On this pageGodspeed CLIThe CLI is the primary way to interact with your Godspeed project from the command line. It provides a bunch of useful functionalities during the project development lifecycle.4.1 Functionality​Outside the dev container​Creating a new project environment with dev container setup, which includes the folder structure, all the databases, message bus, cache, etc.Open up an existing project in the dev container, add/update a container in the dev environment, based on updated settings.List the versions of gs_service.Change the version of gs_service.Inside the dev container​All Prisma commands including DB push, pull or migration.OAS 3 documentation file generation.Test suite/Postman collection generation.Running test suite.4.2 Installation​npm install -g @mindgrep/godspeedOnce Godspeed CLI is installed, the godspeed command can be called from command line. When called without arguments, it displays its help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.3 Options​--version (-v)​The --version option outputs information about your current godspeed version.$ godspeed -v                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          0.0.26--help (-h)​The --help option displays help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.4 Commands: Outside the dev container​create​The create command creates project structure for any microservice. When called without arguments, it creates project structure with examples.$ godspeed create my_service                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          projectDir:  /home/gurjot/cli-test/my_service projectTemplateDir undefinedproject createdDo you need mongodb? [y/n] [default: n] nDo you need postgresdb? [y/n] [default: n] yPlease enter name of the postgres database [default: test] Do you need kafka? [y/n] [default: n] nDo you need elastisearch? [y/n] [default: n] nPlease enter host port on which you want to run your service [default: 3000] 3100Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13Enter your version [default: latest] 1.0.13Selected version 1.0.13. . . . . . . . Options​$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <existing_project_directory>  existing project template dir  -h, --help                            display help for commandupdate​The update can be executed in the following cases:If you want to launch an existing project (i.e. copied from local/cloned from repo) instead of creating a new one, then execute godspeed update command before launching the project.If you want to reloads the containers with updated project settings. For example, if you have not selected any database during the project creation and you want to include any database in the project later on, then execute godspeed update with the required settings.If there is any change in gs_service image of standard tags (e.g. latest, stable) and you want to fetch the latest code for the same tag, then execute godspeed updatecommand. It fetches the new docker image itself.Please note that the command should be executed from inside the project root directory.noteWhenever you update your project using godspeed update and open the project in VScode dev container after update, then it is mandatory to do godspeed build inside dev container for the first time.$ godspeed update                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Do you need postgresdb? [y/n] [default: n] Do you need kafka? [y/n] [default: n] Do you need elastisearch? [y/n] [default: n] Please enter host port on which you want to run your service [default: 3000] Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.21.0.31.0.4devstableEnter your version [default: latest] Selected version latestRemoving dev_test_devcontainer_node_1                ... . . . . . . . . . .Step 1/9 : FROM adminmindgrep/gs_service:latestlatest: Pulling from adminmindgrep/gs_service824b15f81d65: Already exists325d38bcb229: Already existsd6d638bf61bf: Already exists55daac95cedf: Already exists4c701498752d: Already existsa48b0ae49665: Pulling fs layer4c393fb6deac: Pulling fs layer4f4fb700ef54: Pulling fs layer8992963a9530: Pulling fs layer4f4fb700ef54: Verifying Checksum4f4fb700ef54: Download complete4c393fb6deac: Verifying Checksum4c393fb6deac: Download complete8992963a9530: Verifying Checksum8992963a9530: Download completea48b0ae49665: Verifying Checksuma48b0ae49665: Download completea48b0ae49665: Pull complete4c393fb6deac: Pull complete4f4fb700ef54: Pull complete8992963a9530: Pull completeDigest: sha256:7195b3c921f1278153c911e6e77cbcfb385a84c435bfcb7b8272ffcf9a3278eeStatus: Downloaded newer image for adminmindgrep/gs_service:latest ---> 988917710d1aStep 2/9 : ARG USERNAME=node ---> Running in c70404bb4f3eRemoving intermediate container c70404bb4f3e ---> 47a7406b2473Step 3/9 : ARG USER_UID=1000 ---> Running in 51e68336d8d8Removing intermediate container 51e68336d8d8 ---> ce913f6898bbStep 4/9 : ARG USER_GID=$USER_UID ---> Running in 7cf1c1f2a3ecRemoving intermediate container 7cf1c1f2a3ec ---> 91f045b32e0fStep 5/9 : USER root ---> Running in f338d755a032Removing intermediate container f338d755a032 ---> fa9898eb4c23Step 6/9 : RUN sudo groupmod --gid $USER_GID $USERNAME     && usermod --uid $USER_UID --gid $USER_GID $USERNAME     && chown -R $USER_UID:$USER_GID /workspace/development ---> Running in eba3659fb919Removing intermediate container eba3659fb919 ---> 414f34560b0dStep 7/9 : USER node ---> Running in 23818c5f4882Removing intermediate container 23818c5f4882 ---> 1bd65323ae91Step 8/9 : RUN sudo npm i -g @mindgrep/godspeed ---> Running in a66cb062390d. . . . . . . . . . godspeed update dev_test is done.versions​The versions command lists all the versions available of gs_service.$ godspeed versions                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13version​The version command helps to change the version of gs_service for any microservice. Execute the command from inside the project root directory.$ godspeed version 1.0.13                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Generating prisma modulesStarting test1_devcontainer_postgres_1 ... Starting test1_devcontainer_postgres_1 ... doneCreating test1_devcontainer_node_run   ... Creating test1_devcontainer_node_run   ... doneEnvironment variables loaded from .env. . . . . . . . . .help​The help command displays help and usage for any command.$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <projectTemplateDir>  local project template dir  -h, --help                            display help for command4.5 Commands: Inside the dev container​prisma​You can run all the prisma commands in your project root directory inside the dev container. This command is useful for db migration and introspection. Read more here. $ godspeed prisma <prisma command with args>build​You can build the complete project using this command. It is the first command which you need to run whenever you open your project in VScode Dev container. Refer Open in Dev containergodspeed builddev​You can run your project using dev command.godspeed servegen-api-docs​You can get OAS 3 documentation generated automatically by executing this command in your project root directory inside the dev container.$ godspeed gen-api-docs                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529346164] INFO (GS-logger/7684 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529346190] DEBUG (GS-logger/7684 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529346289] INFO (GS-logger/7684 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Postman collection​step1: After executing $ godspeed gen-api-docs
go to docs under app and right click on api-doc.yaml file and download itstep2: In postman import the downloaded file in collection(collection->import->files->select-file.yaml-> import ) and test your apigen-test-suite​You can get test suite/postman collection generated automatically by executing this command in your project root directory inside the dev container. Now, you can import the collection in postman directly. godspeed gen-test-suite                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-test-suite> npm run gen-api-docs && mkdir -p tests && openapi2postmanv2 -s docs/api-doc.yaml -o tests/test-suite.json -p -O folderStrategy=Tags,includeAuthInfoInExample=false> proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529443249] INFO (GS-logger/8145 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529443273] DEBUG (GS-logger/8145 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529443374] INFO (GS-logger/8145 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Input file:  /workspace/development/app/docs/api-doc.yamlWriting to file:  true /workspace/development/app/tests/test-suite.json { result: true, output: [ { type: 'collection', data: [Object] } ] }Conversion successful, collection written to filegen-crud-api​You can get CRUD API generated automatically for datastores and elasticgraph datasources by executing this command in your project root directory inside the dev container.$ godspeed gen-crud-api                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > eg_test@1.0.0 gen-crud-api> npx godspeed-crud-api-generatorSelect datasource / schema to generate CRUD APIs(x) elasticgraph.yaml( ) For all( ) Canceltest​You can run the test suite generated in above command from the following two ways:Postman: Import the collection in postman and run the test suite.CLI: You can use below command to run the test suite from CLI.Please make sure your service is up and running before running the test suite. godspeed test                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 test> newman run tests/test-suite.jsonnewmanGodspeed: Sample Microservice→ Call another (sub) workflow from main workflow  POST http://localhost:3000/another_workflow?bank_id=<string> [200 OK, 630B, 2.6s]. . . . . . . . help​The help command displays help and usage for any command. Click here to know more4.6 Generating Elasticgraph model from prisma schema​generate-elasticgraph-model​You can convert the prisma schema to elasticgraph model by executing this commmand in your project root directory inside the dev container.$ godspeed generate-elasticgraph-model                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed generate-elasticgraph-model [egClientName]Enter the input path  : Enter the output path :Elasticgraph model generatednote[egClientName] (optional): Specifies the name of the Elasticgraph client to be generated. If not provided, the default name eg-model will be used.If the specified input path does not exist, the CLI will display an error message.If the specified output path does not exist, the folder will be generated with [egClientName].Edit this pagePrevious3.6 Debugger in YamlNext5. Swagger Specs4.1 FunctionalityOutside the dev containerInside the dev container4.2 Installation4.3 Options--version (-v)--help (-h)4.4 Commands: Outside the dev containercreateupdateversionsversionhelp4.5 Commands: Inside the dev containerprismabuilddevgen-api-docsPostman collectiongen-test-suitegen-crud-apitesthelp4.6 Generating Elasticgraph model from prisma schemagenerate-elasticgraph-modelForumDiscordGithubTwitterLinkedIn








Introduction to Godspeed CLI | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).4. CLIVersion: v1On this pageGodspeed CLIThe CLI is the primary way to interact with your Godspeed project from the command line. It provides a bunch of useful functionalities during the project development lifecycle.4.1 Functionality​Outside the dev container​Creating a new project environment with dev container setup, which includes the folder structure, all the databases, message bus, cache, etc.Open up an existing project in the dev container, add/update a container in the dev environment, based on updated settings.List the versions of gs_service.Change the version of gs_service.Inside the dev container​All Prisma commands including DB push, pull or migration.OAS 3 documentation file generation.Test suite/Postman collection generation.Running test suite.4.2 Installation​npm install -g @mindgrep/godspeedOnce Godspeed CLI is installed, the godspeed command can be called from command line. When called without arguments, it displays its help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.3 Options​--version (-v)​The --version option outputs information about your current godspeed version.$ godspeed -v                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          0.0.26--help (-h)​The --help option displays help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.4 Commands: Outside the dev container​create​The create command creates project structure for any microservice. When called without arguments, it creates project structure with examples.$ godspeed create my_service                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          projectDir:  /home/gurjot/cli-test/my_service projectTemplateDir undefinedproject createdDo you need mongodb? [y/n] [default: n] nDo you need postgresdb? [y/n] [default: n] yPlease enter name of the postgres database [default: test] Do you need kafka? [y/n] [default: n] nDo you need elastisearch? [y/n] [default: n] nPlease enter host port on which you want to run your service [default: 3000] 3100Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13Enter your version [default: latest] 1.0.13Selected version 1.0.13. . . . . . . . Options​$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <existing_project_directory>  existing project template dir  -h, --help                            display help for commandupdate​The update can be executed in the following cases:If you want to launch an existing project (i.e. copied from local/cloned from repo) instead of creating a new one, then execute godspeed update command before launching the project.If you want to reloads the containers with updated project settings. For example, if you have not selected any database during the project creation and you want to include any database in the project later on, then execute godspeed update with the required settings.If there is any change in gs_service image of standard tags (e.g. latest, stable) and you want to fetch the latest code for the same tag, then execute godspeed updatecommand. It fetches the new docker image itself.Please note that the command should be executed from inside the project root directory.noteWhenever you update your project using godspeed update and open the project in VScode dev container after update, then it is mandatory to do godspeed build inside dev container for the first time.$ godspeed update                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Do you need postgresdb? [y/n] [default: n] Do you need kafka? [y/n] [default: n] Do you need elastisearch? [y/n] [default: n] Please enter host port on which you want to run your service [default: 3000] Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.21.0.31.0.4devstableEnter your version [default: latest] Selected version latestRemoving dev_test_devcontainer_node_1                ... . . . . . . . . . .Step 1/9 : FROM adminmindgrep/gs_service:latestlatest: Pulling from adminmindgrep/gs_service824b15f81d65: Already exists325d38bcb229: Already existsd6d638bf61bf: Already exists55daac95cedf: Already exists4c701498752d: Already existsa48b0ae49665: Pulling fs layer4c393fb6deac: Pulling fs layer4f4fb700ef54: Pulling fs layer8992963a9530: Pulling fs layer4f4fb700ef54: Verifying Checksum4f4fb700ef54: Download complete4c393fb6deac: Verifying Checksum4c393fb6deac: Download complete8992963a9530: Verifying Checksum8992963a9530: Download completea48b0ae49665: Verifying Checksuma48b0ae49665: Download completea48b0ae49665: Pull complete4c393fb6deac: Pull complete4f4fb700ef54: Pull complete8992963a9530: Pull completeDigest: sha256:7195b3c921f1278153c911e6e77cbcfb385a84c435bfcb7b8272ffcf9a3278eeStatus: Downloaded newer image for adminmindgrep/gs_service:latest ---> 988917710d1aStep 2/9 : ARG USERNAME=node ---> Running in c70404bb4f3eRemoving intermediate container c70404bb4f3e ---> 47a7406b2473Step 3/9 : ARG USER_UID=1000 ---> Running in 51e68336d8d8Removing intermediate container 51e68336d8d8 ---> ce913f6898bbStep 4/9 : ARG USER_GID=$USER_UID ---> Running in 7cf1c1f2a3ecRemoving intermediate container 7cf1c1f2a3ec ---> 91f045b32e0fStep 5/9 : USER root ---> Running in f338d755a032Removing intermediate container f338d755a032 ---> fa9898eb4c23Step 6/9 : RUN sudo groupmod --gid $USER_GID $USERNAME     && usermod --uid $USER_UID --gid $USER_GID $USERNAME     && chown -R $USER_UID:$USER_GID /workspace/development ---> Running in eba3659fb919Removing intermediate container eba3659fb919 ---> 414f34560b0dStep 7/9 : USER node ---> Running in 23818c5f4882Removing intermediate container 23818c5f4882 ---> 1bd65323ae91Step 8/9 : RUN sudo npm i -g @mindgrep/godspeed ---> Running in a66cb062390d. . . . . . . . . . godspeed update dev_test is done.versions​The versions command lists all the versions available of gs_service.$ godspeed versions                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13version​The version command helps to change the version of gs_service for any microservice. Execute the command from inside the project root directory.$ godspeed version 1.0.13                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Generating prisma modulesStarting test1_devcontainer_postgres_1 ... Starting test1_devcontainer_postgres_1 ... doneCreating test1_devcontainer_node_run   ... Creating test1_devcontainer_node_run   ... doneEnvironment variables loaded from .env. . . . . . . . . .help​The help command displays help and usage for any command.$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <projectTemplateDir>  local project template dir  -h, --help                            display help for command4.5 Commands: Inside the dev container​prisma​You can run all the prisma commands in your project root directory inside the dev container. This command is useful for db migration and introspection. Read more here. $ godspeed prisma <prisma command with args>build​You can build the complete project using this command. It is the first command which you need to run whenever you open your project in VScode Dev container. Refer Open in Dev containergodspeed builddev​You can run your project using dev command.godspeed servegen-api-docs​You can get OAS 3 documentation generated automatically by executing this command in your project root directory inside the dev container.$ godspeed gen-api-docs                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529346164] INFO (GS-logger/7684 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529346190] DEBUG (GS-logger/7684 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529346289] INFO (GS-logger/7684 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Postman collection​step1: After executing $ godspeed gen-api-docs
go to docs under app and right click on api-doc.yaml file and download itstep2: In postman import the downloaded file in collection(collection->import->files->select-file.yaml-> import ) and test your apigen-test-suite​You can get test suite/postman collection generated automatically by executing this command in your project root directory inside the dev container. Now, you can import the collection in postman directly. godspeed gen-test-suite                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-test-suite> npm run gen-api-docs && mkdir -p tests && openapi2postmanv2 -s docs/api-doc.yaml -o tests/test-suite.json -p -O folderStrategy=Tags,includeAuthInfoInExample=false> proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529443249] INFO (GS-logger/8145 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529443273] DEBUG (GS-logger/8145 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529443374] INFO (GS-logger/8145 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Input file:  /workspace/development/app/docs/api-doc.yamlWriting to file:  true /workspace/development/app/tests/test-suite.json { result: true, output: [ { type: 'collection', data: [Object] } ] }Conversion successful, collection written to filegen-crud-api​You can get CRUD API generated automatically for datastores and elasticgraph datasources by executing this command in your project root directory inside the dev container.$ godspeed gen-crud-api                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > eg_test@1.0.0 gen-crud-api> npx godspeed-crud-api-generatorSelect datasource / schema to generate CRUD APIs(x) elasticgraph.yaml( ) For all( ) Canceltest​You can run the test suite generated in above command from the following two ways:Postman: Import the collection in postman and run the test suite.CLI: You can use below command to run the test suite from CLI.Please make sure your service is up and running before running the test suite. godspeed test                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 test> newman run tests/test-suite.jsonnewmanGodspeed: Sample Microservice→ Call another (sub) workflow from main workflow  POST http://localhost:3000/another_workflow?bank_id=<string> [200 OK, 630B, 2.6s]. . . . . . . . help​The help command displays help and usage for any command. Click here to know more4.6 Generating Elasticgraph model from prisma schema​generate-elasticgraph-model​You can convert the prisma schema to elasticgraph model by executing this commmand in your project root directory inside the dev container.$ godspeed generate-elasticgraph-model                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed generate-elasticgraph-model [egClientName]Enter the input path  : Enter the output path :Elasticgraph model generatednote[egClientName] (optional): Specifies the name of the Elasticgraph client to be generated. If not provided, the default name eg-model will be used.If the specified input path does not exist, the CLI will display an error message.If the specified output path does not exist, the folder will be generated with [egClientName].Edit this pagePrevious3.6 Debugger in YamlNext5. Swagger Specs4.1 FunctionalityOutside the dev containerInside the dev container4.2 Installation4.3 Options--version (-v)--help (-h)4.4 Commands: Outside the dev containercreateupdateversionsversionhelp4.5 Commands: Inside the dev containerprismabuilddevgen-api-docsPostman collectiongen-test-suitegen-crud-apitesthelp4.6 Generating Elasticgraph model from prisma schemagenerate-elasticgraph-modelForumDiscordGithubTwitterLinkedIn








Introduction to Godspeed CLI | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).4. CLIVersion: v1On this pageGodspeed CLIThe CLI is the primary way to interact with your Godspeed project from the command line. It provides a bunch of useful functionalities during the project development lifecycle.4.1 Functionality​Outside the dev container​Creating a new project environment with dev container setup, which includes the folder structure, all the databases, message bus, cache, etc.Open up an existing project in the dev container, add/update a container in the dev environment, based on updated settings.List the versions of gs_service.Change the version of gs_service.Inside the dev container​All Prisma commands including DB push, pull or migration.OAS 3 documentation file generation.Test suite/Postman collection generation.Running test suite.4.2 Installation​npm install -g @mindgrep/godspeedOnce Godspeed CLI is installed, the godspeed command can be called from command line. When called without arguments, it displays its help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.3 Options​--version (-v)​The --version option outputs information about your current godspeed version.$ godspeed -v                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          0.0.26--help (-h)​The --help option displays help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.4 Commands: Outside the dev container​create​The create command creates project structure for any microservice. When called without arguments, it creates project structure with examples.$ godspeed create my_service                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          projectDir:  /home/gurjot/cli-test/my_service projectTemplateDir undefinedproject createdDo you need mongodb? [y/n] [default: n] nDo you need postgresdb? [y/n] [default: n] yPlease enter name of the postgres database [default: test] Do you need kafka? [y/n] [default: n] nDo you need elastisearch? [y/n] [default: n] nPlease enter host port on which you want to run your service [default: 3000] 3100Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13Enter your version [default: latest] 1.0.13Selected version 1.0.13. . . . . . . . Options​$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <existing_project_directory>  existing project template dir  -h, --help                            display help for commandupdate​The update can be executed in the following cases:If you want to launch an existing project (i.e. copied from local/cloned from repo) instead of creating a new one, then execute godspeed update command before launching the project.If you want to reloads the containers with updated project settings. For example, if you have not selected any database during the project creation and you want to include any database in the project later on, then execute godspeed update with the required settings.If there is any change in gs_service image of standard tags (e.g. latest, stable) and you want to fetch the latest code for the same tag, then execute godspeed updatecommand. It fetches the new docker image itself.Please note that the command should be executed from inside the project root directory.noteWhenever you update your project using godspeed update and open the project in VScode dev container after update, then it is mandatory to do godspeed build inside dev container for the first time.$ godspeed update                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Do you need postgresdb? [y/n] [default: n] Do you need kafka? [y/n] [default: n] Do you need elastisearch? [y/n] [default: n] Please enter host port on which you want to run your service [default: 3000] Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.21.0.31.0.4devstableEnter your version [default: latest] Selected version latestRemoving dev_test_devcontainer_node_1                ... . . . . . . . . . .Step 1/9 : FROM adminmindgrep/gs_service:latestlatest: Pulling from adminmindgrep/gs_service824b15f81d65: Already exists325d38bcb229: Already existsd6d638bf61bf: Already exists55daac95cedf: Already exists4c701498752d: Already existsa48b0ae49665: Pulling fs layer4c393fb6deac: Pulling fs layer4f4fb700ef54: Pulling fs layer8992963a9530: Pulling fs layer4f4fb700ef54: Verifying Checksum4f4fb700ef54: Download complete4c393fb6deac: Verifying Checksum4c393fb6deac: Download complete8992963a9530: Verifying Checksum8992963a9530: Download completea48b0ae49665: Verifying Checksuma48b0ae49665: Download completea48b0ae49665: Pull complete4c393fb6deac: Pull complete4f4fb700ef54: Pull complete8992963a9530: Pull completeDigest: sha256:7195b3c921f1278153c911e6e77cbcfb385a84c435bfcb7b8272ffcf9a3278eeStatus: Downloaded newer image for adminmindgrep/gs_service:latest ---> 988917710d1aStep 2/9 : ARG USERNAME=node ---> Running in c70404bb4f3eRemoving intermediate container c70404bb4f3e ---> 47a7406b2473Step 3/9 : ARG USER_UID=1000 ---> Running in 51e68336d8d8Removing intermediate container 51e68336d8d8 ---> ce913f6898bbStep 4/9 : ARG USER_GID=$USER_UID ---> Running in 7cf1c1f2a3ecRemoving intermediate container 7cf1c1f2a3ec ---> 91f045b32e0fStep 5/9 : USER root ---> Running in f338d755a032Removing intermediate container f338d755a032 ---> fa9898eb4c23Step 6/9 : RUN sudo groupmod --gid $USER_GID $USERNAME     && usermod --uid $USER_UID --gid $USER_GID $USERNAME     && chown -R $USER_UID:$USER_GID /workspace/development ---> Running in eba3659fb919Removing intermediate container eba3659fb919 ---> 414f34560b0dStep 7/9 : USER node ---> Running in 23818c5f4882Removing intermediate container 23818c5f4882 ---> 1bd65323ae91Step 8/9 : RUN sudo npm i -g @mindgrep/godspeed ---> Running in a66cb062390d. . . . . . . . . . godspeed update dev_test is done.versions​The versions command lists all the versions available of gs_service.$ godspeed versions                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13version​The version command helps to change the version of gs_service for any microservice. Execute the command from inside the project root directory.$ godspeed version 1.0.13                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Generating prisma modulesStarting test1_devcontainer_postgres_1 ... Starting test1_devcontainer_postgres_1 ... doneCreating test1_devcontainer_node_run   ... Creating test1_devcontainer_node_run   ... doneEnvironment variables loaded from .env. . . . . . . . . .help​The help command displays help and usage for any command.$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <projectTemplateDir>  local project template dir  -h, --help                            display help for command4.5 Commands: Inside the dev container​prisma​You can run all the prisma commands in your project root directory inside the dev container. This command is useful for db migration and introspection. Read more here. $ godspeed prisma <prisma command with args>build​You can build the complete project using this command. It is the first command which you need to run whenever you open your project in VScode Dev container. Refer Open in Dev containergodspeed builddev​You can run your project using dev command.godspeed servegen-api-docs​You can get OAS 3 documentation generated automatically by executing this command in your project root directory inside the dev container.$ godspeed gen-api-docs                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529346164] INFO (GS-logger/7684 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529346190] DEBUG (GS-logger/7684 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529346289] INFO (GS-logger/7684 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Postman collection​step1: After executing $ godspeed gen-api-docs
go to docs under app and right click on api-doc.yaml file and download itstep2: In postman import the downloaded file in collection(collection->import->files->select-file.yaml-> import ) and test your apigen-test-suite​You can get test suite/postman collection generated automatically by executing this command in your project root directory inside the dev container. Now, you can import the collection in postman directly. godspeed gen-test-suite                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-test-suite> npm run gen-api-docs && mkdir -p tests && openapi2postmanv2 -s docs/api-doc.yaml -o tests/test-suite.json -p -O folderStrategy=Tags,includeAuthInfoInExample=false> proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529443249] INFO (GS-logger/8145 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529443273] DEBUG (GS-logger/8145 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529443374] INFO (GS-logger/8145 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Input file:  /workspace/development/app/docs/api-doc.yamlWriting to file:  true /workspace/development/app/tests/test-suite.json { result: true, output: [ { type: 'collection', data: [Object] } ] }Conversion successful, collection written to filegen-crud-api​You can get CRUD API generated automatically for datastores and elasticgraph datasources by executing this command in your project root directory inside the dev container.$ godspeed gen-crud-api                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > eg_test@1.0.0 gen-crud-api> npx godspeed-crud-api-generatorSelect datasource / schema to generate CRUD APIs(x) elasticgraph.yaml( ) For all( ) Canceltest​You can run the test suite generated in above command from the following two ways:Postman: Import the collection in postman and run the test suite.CLI: You can use below command to run the test suite from CLI.Please make sure your service is up and running before running the test suite. godspeed test                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 test> newman run tests/test-suite.jsonnewmanGodspeed: Sample Microservice→ Call another (sub) workflow from main workflow  POST http://localhost:3000/another_workflow?bank_id=<string> [200 OK, 630B, 2.6s]. . . . . . . . help​The help command displays help and usage for any command. Click here to know more4.6 Generating Elasticgraph model from prisma schema​generate-elasticgraph-model​You can convert the prisma schema to elasticgraph model by executing this commmand in your project root directory inside the dev container.$ godspeed generate-elasticgraph-model                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed generate-elasticgraph-model [egClientName]Enter the input path  : Enter the output path :Elasticgraph model generatednote[egClientName] (optional): Specifies the name of the Elasticgraph client to be generated. If not provided, the default name eg-model will be used.If the specified input path does not exist, the CLI will display an error message.If the specified output path does not exist, the folder will be generated with [egClientName].Edit this pagePrevious3.6 Debugger in YamlNext5. Swagger Specs4.1 FunctionalityOutside the dev containerInside the dev container4.2 Installation4.3 Options--version (-v)--help (-h)4.4 Commands: Outside the dev containercreateupdateversionsversionhelp4.5 Commands: Inside the dev containerprismabuilddevgen-api-docsPostman collectiongen-test-suitegen-crud-apitesthelp4.6 Generating Elasticgraph model from prisma schemagenerate-elasticgraph-modelForumDiscordGithubTwitterLinkedIn








Introduction to Godspeed CLI | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).4. CLIVersion: v1On this pageGodspeed CLIThe CLI is the primary way to interact with your Godspeed project from the command line. It provides a bunch of useful functionalities during the project development lifecycle.4.1 Functionality​Outside the dev container​Creating a new project environment with dev container setup, which includes the folder structure, all the databases, message bus, cache, etc.Open up an existing project in the dev container, add/update a container in the dev environment, based on updated settings.List the versions of gs_service.Change the version of gs_service.Inside the dev container​All Prisma commands including DB push, pull or migration.OAS 3 documentation file generation.Test suite/Postman collection generation.Running test suite.4.2 Installation​npm install -g @mindgrep/godspeedOnce Godspeed CLI is installed, the godspeed command can be called from command line. When called without arguments, it displays its help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.3 Options​--version (-v)​The --version option outputs information about your current godspeed version.$ godspeed -v                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          0.0.26--help (-h)​The --help option displays help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.4 Commands: Outside the dev container​create​The create command creates project structure for any microservice. When called without arguments, it creates project structure with examples.$ godspeed create my_service                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          projectDir:  /home/gurjot/cli-test/my_service projectTemplateDir undefinedproject createdDo you need mongodb? [y/n] [default: n] nDo you need postgresdb? [y/n] [default: n] yPlease enter name of the postgres database [default: test] Do you need kafka? [y/n] [default: n] nDo you need elastisearch? [y/n] [default: n] nPlease enter host port on which you want to run your service [default: 3000] 3100Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13Enter your version [default: latest] 1.0.13Selected version 1.0.13. . . . . . . . Options​$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <existing_project_directory>  existing project template dir  -h, --help                            display help for commandupdate​The update can be executed in the following cases:If you want to launch an existing project (i.e. copied from local/cloned from repo) instead of creating a new one, then execute godspeed update command before launching the project.If you want to reloads the containers with updated project settings. For example, if you have not selected any database during the project creation and you want to include any database in the project later on, then execute godspeed update with the required settings.If there is any change in gs_service image of standard tags (e.g. latest, stable) and you want to fetch the latest code for the same tag, then execute godspeed updatecommand. It fetches the new docker image itself.Please note that the command should be executed from inside the project root directory.noteWhenever you update your project using godspeed update and open the project in VScode dev container after update, then it is mandatory to do godspeed build inside dev container for the first time.$ godspeed update                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Do you need postgresdb? [y/n] [default: n] Do you need kafka? [y/n] [default: n] Do you need elastisearch? [y/n] [default: n] Please enter host port on which you want to run your service [default: 3000] Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.21.0.31.0.4devstableEnter your version [default: latest] Selected version latestRemoving dev_test_devcontainer_node_1                ... . . . . . . . . . .Step 1/9 : FROM adminmindgrep/gs_service:latestlatest: Pulling from adminmindgrep/gs_service824b15f81d65: Already exists325d38bcb229: Already existsd6d638bf61bf: Already exists55daac95cedf: Already exists4c701498752d: Already existsa48b0ae49665: Pulling fs layer4c393fb6deac: Pulling fs layer4f4fb700ef54: Pulling fs layer8992963a9530: Pulling fs layer4f4fb700ef54: Verifying Checksum4f4fb700ef54: Download complete4c393fb6deac: Verifying Checksum4c393fb6deac: Download complete8992963a9530: Verifying Checksum8992963a9530: Download completea48b0ae49665: Verifying Checksuma48b0ae49665: Download completea48b0ae49665: Pull complete4c393fb6deac: Pull complete4f4fb700ef54: Pull complete8992963a9530: Pull completeDigest: sha256:7195b3c921f1278153c911e6e77cbcfb385a84c435bfcb7b8272ffcf9a3278eeStatus: Downloaded newer image for adminmindgrep/gs_service:latest ---> 988917710d1aStep 2/9 : ARG USERNAME=node ---> Running in c70404bb4f3eRemoving intermediate container c70404bb4f3e ---> 47a7406b2473Step 3/9 : ARG USER_UID=1000 ---> Running in 51e68336d8d8Removing intermediate container 51e68336d8d8 ---> ce913f6898bbStep 4/9 : ARG USER_GID=$USER_UID ---> Running in 7cf1c1f2a3ecRemoving intermediate container 7cf1c1f2a3ec ---> 91f045b32e0fStep 5/9 : USER root ---> Running in f338d755a032Removing intermediate container f338d755a032 ---> fa9898eb4c23Step 6/9 : RUN sudo groupmod --gid $USER_GID $USERNAME     && usermod --uid $USER_UID --gid $USER_GID $USERNAME     && chown -R $USER_UID:$USER_GID /workspace/development ---> Running in eba3659fb919Removing intermediate container eba3659fb919 ---> 414f34560b0dStep 7/9 : USER node ---> Running in 23818c5f4882Removing intermediate container 23818c5f4882 ---> 1bd65323ae91Step 8/9 : RUN sudo npm i -g @mindgrep/godspeed ---> Running in a66cb062390d. . . . . . . . . . godspeed update dev_test is done.versions​The versions command lists all the versions available of gs_service.$ godspeed versions                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13version​The version command helps to change the version of gs_service for any microservice. Execute the command from inside the project root directory.$ godspeed version 1.0.13                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Generating prisma modulesStarting test1_devcontainer_postgres_1 ... Starting test1_devcontainer_postgres_1 ... doneCreating test1_devcontainer_node_run   ... Creating test1_devcontainer_node_run   ... doneEnvironment variables loaded from .env. . . . . . . . . .help​The help command displays help and usage for any command.$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <projectTemplateDir>  local project template dir  -h, --help                            display help for command4.5 Commands: Inside the dev container​prisma​You can run all the prisma commands in your project root directory inside the dev container. This command is useful for db migration and introspection. Read more here. $ godspeed prisma <prisma command with args>build​You can build the complete project using this command. It is the first command which you need to run whenever you open your project in VScode Dev container. Refer Open in Dev containergodspeed builddev​You can run your project using dev command.godspeed servegen-api-docs​You can get OAS 3 documentation generated automatically by executing this command in your project root directory inside the dev container.$ godspeed gen-api-docs                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529346164] INFO (GS-logger/7684 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529346190] DEBUG (GS-logger/7684 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529346289] INFO (GS-logger/7684 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Postman collection​step1: After executing $ godspeed gen-api-docs
go to docs under app and right click on api-doc.yaml file and download itstep2: In postman import the downloaded file in collection(collection->import->files->select-file.yaml-> import ) and test your apigen-test-suite​You can get test suite/postman collection generated automatically by executing this command in your project root directory inside the dev container. Now, you can import the collection in postman directly. godspeed gen-test-suite                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-test-suite> npm run gen-api-docs && mkdir -p tests && openapi2postmanv2 -s docs/api-doc.yaml -o tests/test-suite.json -p -O folderStrategy=Tags,includeAuthInfoInExample=false> proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529443249] INFO (GS-logger/8145 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529443273] DEBUG (GS-logger/8145 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529443374] INFO (GS-logger/8145 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Input file:  /workspace/development/app/docs/api-doc.yamlWriting to file:  true /workspace/development/app/tests/test-suite.json { result: true, output: [ { type: 'collection', data: [Object] } ] }Conversion successful, collection written to filegen-crud-api​You can get CRUD API generated automatically for datastores and elasticgraph datasources by executing this command in your project root directory inside the dev container.$ godspeed gen-crud-api                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > eg_test@1.0.0 gen-crud-api> npx godspeed-crud-api-generatorSelect datasource / schema to generate CRUD APIs(x) elasticgraph.yaml( ) For all( ) Canceltest​You can run the test suite generated in above command from the following two ways:Postman: Import the collection in postman and run the test suite.CLI: You can use below command to run the test suite from CLI.Please make sure your service is up and running before running the test suite. godspeed test                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 test> newman run tests/test-suite.jsonnewmanGodspeed: Sample Microservice→ Call another (sub) workflow from main workflow  POST http://localhost:3000/another_workflow?bank_id=<string> [200 OK, 630B, 2.6s]. . . . . . . . help​The help command displays help and usage for any command. Click here to know more4.6 Generating Elasticgraph model from prisma schema​generate-elasticgraph-model​You can convert the prisma schema to elasticgraph model by executing this commmand in your project root directory inside the dev container.$ godspeed generate-elasticgraph-model                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed generate-elasticgraph-model [egClientName]Enter the input path  : Enter the output path :Elasticgraph model generatednote[egClientName] (optional): Specifies the name of the Elasticgraph client to be generated. If not provided, the default name eg-model will be used.If the specified input path does not exist, the CLI will display an error message.If the specified output path does not exist, the folder will be generated with [egClientName].Edit this pagePrevious3.6 Debugger in YamlNext5. Swagger Specs4.1 FunctionalityOutside the dev containerInside the dev container4.2 Installation4.3 Options--version (-v)--help (-h)4.4 Commands: Outside the dev containercreateupdateversionsversionhelp4.5 Commands: Inside the dev containerprismabuilddevgen-api-docsPostman collectiongen-test-suitegen-crud-apitesthelp4.6 Generating Elasticgraph model from prisma schemagenerate-elasticgraph-modelForumDiscordGithubTwitterLinkedIn








Introduction to Godspeed CLI | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).4. CLIVersion: v1On this pageGodspeed CLIThe CLI is the primary way to interact with your Godspeed project from the command line. It provides a bunch of useful functionalities during the project development lifecycle.4.1 Functionality​Outside the dev container​Creating a new project environment with dev container setup, which includes the folder structure, all the databases, message bus, cache, etc.Open up an existing project in the dev container, add/update a container in the dev environment, based on updated settings.List the versions of gs_service.Change the version of gs_service.Inside the dev container​All Prisma commands including DB push, pull or migration.OAS 3 documentation file generation.Test suite/Postman collection generation.Running test suite.4.2 Installation​npm install -g @mindgrep/godspeedOnce Godspeed CLI is installed, the godspeed command can be called from command line. When called without arguments, it displays its help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.3 Options​--version (-v)​The --version option outputs information about your current godspeed version.$ godspeed -v                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          0.0.26--help (-h)​The --help option displays help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.4 Commands: Outside the dev container​create​The create command creates project structure for any microservice. When called without arguments, it creates project structure with examples.$ godspeed create my_service                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          projectDir:  /home/gurjot/cli-test/my_service projectTemplateDir undefinedproject createdDo you need mongodb? [y/n] [default: n] nDo you need postgresdb? [y/n] [default: n] yPlease enter name of the postgres database [default: test] Do you need kafka? [y/n] [default: n] nDo you need elastisearch? [y/n] [default: n] nPlease enter host port on which you want to run your service [default: 3000] 3100Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13Enter your version [default: latest] 1.0.13Selected version 1.0.13. . . . . . . . Options​$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <existing_project_directory>  existing project template dir  -h, --help                            display help for commandupdate​The update can be executed in the following cases:If you want to launch an existing project (i.e. copied from local/cloned from repo) instead of creating a new one, then execute godspeed update command before launching the project.If you want to reloads the containers with updated project settings. For example, if you have not selected any database during the project creation and you want to include any database in the project later on, then execute godspeed update with the required settings.If there is any change in gs_service image of standard tags (e.g. latest, stable) and you want to fetch the latest code for the same tag, then execute godspeed updatecommand. It fetches the new docker image itself.Please note that the command should be executed from inside the project root directory.noteWhenever you update your project using godspeed update and open the project in VScode dev container after update, then it is mandatory to do godspeed build inside dev container for the first time.$ godspeed update                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Do you need postgresdb? [y/n] [default: n] Do you need kafka? [y/n] [default: n] Do you need elastisearch? [y/n] [default: n] Please enter host port on which you want to run your service [default: 3000] Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.21.0.31.0.4devstableEnter your version [default: latest] Selected version latestRemoving dev_test_devcontainer_node_1                ... . . . . . . . . . .Step 1/9 : FROM adminmindgrep/gs_service:latestlatest: Pulling from adminmindgrep/gs_service824b15f81d65: Already exists325d38bcb229: Already existsd6d638bf61bf: Already exists55daac95cedf: Already exists4c701498752d: Already existsa48b0ae49665: Pulling fs layer4c393fb6deac: Pulling fs layer4f4fb700ef54: Pulling fs layer8992963a9530: Pulling fs layer4f4fb700ef54: Verifying Checksum4f4fb700ef54: Download complete4c393fb6deac: Verifying Checksum4c393fb6deac: Download complete8992963a9530: Verifying Checksum8992963a9530: Download completea48b0ae49665: Verifying Checksuma48b0ae49665: Download completea48b0ae49665: Pull complete4c393fb6deac: Pull complete4f4fb700ef54: Pull complete8992963a9530: Pull completeDigest: sha256:7195b3c921f1278153c911e6e77cbcfb385a84c435bfcb7b8272ffcf9a3278eeStatus: Downloaded newer image for adminmindgrep/gs_service:latest ---> 988917710d1aStep 2/9 : ARG USERNAME=node ---> Running in c70404bb4f3eRemoving intermediate container c70404bb4f3e ---> 47a7406b2473Step 3/9 : ARG USER_UID=1000 ---> Running in 51e68336d8d8Removing intermediate container 51e68336d8d8 ---> ce913f6898bbStep 4/9 : ARG USER_GID=$USER_UID ---> Running in 7cf1c1f2a3ecRemoving intermediate container 7cf1c1f2a3ec ---> 91f045b32e0fStep 5/9 : USER root ---> Running in f338d755a032Removing intermediate container f338d755a032 ---> fa9898eb4c23Step 6/9 : RUN sudo groupmod --gid $USER_GID $USERNAME     && usermod --uid $USER_UID --gid $USER_GID $USERNAME     && chown -R $USER_UID:$USER_GID /workspace/development ---> Running in eba3659fb919Removing intermediate container eba3659fb919 ---> 414f34560b0dStep 7/9 : USER node ---> Running in 23818c5f4882Removing intermediate container 23818c5f4882 ---> 1bd65323ae91Step 8/9 : RUN sudo npm i -g @mindgrep/godspeed ---> Running in a66cb062390d. . . . . . . . . . godspeed update dev_test is done.versions​The versions command lists all the versions available of gs_service.$ godspeed versions                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13version​The version command helps to change the version of gs_service for any microservice. Execute the command from inside the project root directory.$ godspeed version 1.0.13                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Generating prisma modulesStarting test1_devcontainer_postgres_1 ... Starting test1_devcontainer_postgres_1 ... doneCreating test1_devcontainer_node_run   ... Creating test1_devcontainer_node_run   ... doneEnvironment variables loaded from .env. . . . . . . . . .help​The help command displays help and usage for any command.$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <projectTemplateDir>  local project template dir  -h, --help                            display help for command4.5 Commands: Inside the dev container​prisma​You can run all the prisma commands in your project root directory inside the dev container. This command is useful for db migration and introspection. Read more here. $ godspeed prisma <prisma command with args>build​You can build the complete project using this command. It is the first command which you need to run whenever you open your project in VScode Dev container. Refer Open in Dev containergodspeed builddev​You can run your project using dev command.godspeed servegen-api-docs​You can get OAS 3 documentation generated automatically by executing this command in your project root directory inside the dev container.$ godspeed gen-api-docs                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529346164] INFO (GS-logger/7684 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529346190] DEBUG (GS-logger/7684 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529346289] INFO (GS-logger/7684 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Postman collection​step1: After executing $ godspeed gen-api-docs
go to docs under app and right click on api-doc.yaml file and download itstep2: In postman import the downloaded file in collection(collection->import->files->select-file.yaml-> import ) and test your apigen-test-suite​You can get test suite/postman collection generated automatically by executing this command in your project root directory inside the dev container. Now, you can import the collection in postman directly. godspeed gen-test-suite                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-test-suite> npm run gen-api-docs && mkdir -p tests && openapi2postmanv2 -s docs/api-doc.yaml -o tests/test-suite.json -p -O folderStrategy=Tags,includeAuthInfoInExample=false> proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529443249] INFO (GS-logger/8145 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529443273] DEBUG (GS-logger/8145 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529443374] INFO (GS-logger/8145 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Input file:  /workspace/development/app/docs/api-doc.yamlWriting to file:  true /workspace/development/app/tests/test-suite.json { result: true, output: [ { type: 'collection', data: [Object] } ] }Conversion successful, collection written to filegen-crud-api​You can get CRUD API generated automatically for datastores and elasticgraph datasources by executing this command in your project root directory inside the dev container.$ godspeed gen-crud-api                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > eg_test@1.0.0 gen-crud-api> npx godspeed-crud-api-generatorSelect datasource / schema to generate CRUD APIs(x) elasticgraph.yaml( ) For all( ) Canceltest​You can run the test suite generated in above command from the following two ways:Postman: Import the collection in postman and run the test suite.CLI: You can use below command to run the test suite from CLI.Please make sure your service is up and running before running the test suite. godspeed test                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 test> newman run tests/test-suite.jsonnewmanGodspeed: Sample Microservice→ Call another (sub) workflow from main workflow  POST http://localhost:3000/another_workflow?bank_id=<string> [200 OK, 630B, 2.6s]. . . . . . . . help​The help command displays help and usage for any command. Click here to know more4.6 Generating Elasticgraph model from prisma schema​generate-elasticgraph-model​You can convert the prisma schema to elasticgraph model by executing this commmand in your project root directory inside the dev container.$ godspeed generate-elasticgraph-model                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed generate-elasticgraph-model [egClientName]Enter the input path  : Enter the output path :Elasticgraph model generatednote[egClientName] (optional): Specifies the name of the Elasticgraph client to be generated. If not provided, the default name eg-model will be used.If the specified input path does not exist, the CLI will display an error message.If the specified output path does not exist, the folder will be generated with [egClientName].Edit this pagePrevious3.6 Debugger in YamlNext5. Swagger Specs4.1 FunctionalityOutside the dev containerInside the dev container4.2 Installation4.3 Options--version (-v)--help (-h)4.4 Commands: Outside the dev containercreateupdateversionsversionhelp4.5 Commands: Inside the dev containerprismabuilddevgen-api-docsPostman collectiongen-test-suitegen-crud-apitesthelp4.6 Generating Elasticgraph model from prisma schemagenerate-elasticgraph-modelForumDiscordGithubTwitterLinkedIn








Introduction to Godspeed CLI | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).4. CLIVersion: v1On this pageGodspeed CLIThe CLI is the primary way to interact with your Godspeed project from the command line. It provides a bunch of useful functionalities during the project development lifecycle.4.1 Functionality​Outside the dev container​Creating a new project environment with dev container setup, which includes the folder structure, all the databases, message bus, cache, etc.Open up an existing project in the dev container, add/update a container in the dev environment, based on updated settings.List the versions of gs_service.Change the version of gs_service.Inside the dev container​All Prisma commands including DB push, pull or migration.OAS 3 documentation file generation.Test suite/Postman collection generation.Running test suite.4.2 Installation​npm install -g @mindgrep/godspeedOnce Godspeed CLI is installed, the godspeed command can be called from command line. When called without arguments, it displays its help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.3 Options​--version (-v)​The --version option outputs information about your current godspeed version.$ godspeed -v                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          0.0.26--help (-h)​The --help option displays help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.4 Commands: Outside the dev container​create​The create command creates project structure for any microservice. When called without arguments, it creates project structure with examples.$ godspeed create my_service                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          projectDir:  /home/gurjot/cli-test/my_service projectTemplateDir undefinedproject createdDo you need mongodb? [y/n] [default: n] nDo you need postgresdb? [y/n] [default: n] yPlease enter name of the postgres database [default: test] Do you need kafka? [y/n] [default: n] nDo you need elastisearch? [y/n] [default: n] nPlease enter host port on which you want to run your service [default: 3000] 3100Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13Enter your version [default: latest] 1.0.13Selected version 1.0.13. . . . . . . . Options​$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <existing_project_directory>  existing project template dir  -h, --help                            display help for commandupdate​The update can be executed in the following cases:If you want to launch an existing project (i.e. copied from local/cloned from repo) instead of creating a new one, then execute godspeed update command before launching the project.If you want to reloads the containers with updated project settings. For example, if you have not selected any database during the project creation and you want to include any database in the project later on, then execute godspeed update with the required settings.If there is any change in gs_service image of standard tags (e.g. latest, stable) and you want to fetch the latest code for the same tag, then execute godspeed updatecommand. It fetches the new docker image itself.Please note that the command should be executed from inside the project root directory.noteWhenever you update your project using godspeed update and open the project in VScode dev container after update, then it is mandatory to do godspeed build inside dev container for the first time.$ godspeed update                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Do you need postgresdb? [y/n] [default: n] Do you need kafka? [y/n] [default: n] Do you need elastisearch? [y/n] [default: n] Please enter host port on which you want to run your service [default: 3000] Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.21.0.31.0.4devstableEnter your version [default: latest] Selected version latestRemoving dev_test_devcontainer_node_1                ... . . . . . . . . . .Step 1/9 : FROM adminmindgrep/gs_service:latestlatest: Pulling from adminmindgrep/gs_service824b15f81d65: Already exists325d38bcb229: Already existsd6d638bf61bf: Already exists55daac95cedf: Already exists4c701498752d: Already existsa48b0ae49665: Pulling fs layer4c393fb6deac: Pulling fs layer4f4fb700ef54: Pulling fs layer8992963a9530: Pulling fs layer4f4fb700ef54: Verifying Checksum4f4fb700ef54: Download complete4c393fb6deac: Verifying Checksum4c393fb6deac: Download complete8992963a9530: Verifying Checksum8992963a9530: Download completea48b0ae49665: Verifying Checksuma48b0ae49665: Download completea48b0ae49665: Pull complete4c393fb6deac: Pull complete4f4fb700ef54: Pull complete8992963a9530: Pull completeDigest: sha256:7195b3c921f1278153c911e6e77cbcfb385a84c435bfcb7b8272ffcf9a3278eeStatus: Downloaded newer image for adminmindgrep/gs_service:latest ---> 988917710d1aStep 2/9 : ARG USERNAME=node ---> Running in c70404bb4f3eRemoving intermediate container c70404bb4f3e ---> 47a7406b2473Step 3/9 : ARG USER_UID=1000 ---> Running in 51e68336d8d8Removing intermediate container 51e68336d8d8 ---> ce913f6898bbStep 4/9 : ARG USER_GID=$USER_UID ---> Running in 7cf1c1f2a3ecRemoving intermediate container 7cf1c1f2a3ec ---> 91f045b32e0fStep 5/9 : USER root ---> Running in f338d755a032Removing intermediate container f338d755a032 ---> fa9898eb4c23Step 6/9 : RUN sudo groupmod --gid $USER_GID $USERNAME     && usermod --uid $USER_UID --gid $USER_GID $USERNAME     && chown -R $USER_UID:$USER_GID /workspace/development ---> Running in eba3659fb919Removing intermediate container eba3659fb919 ---> 414f34560b0dStep 7/9 : USER node ---> Running in 23818c5f4882Removing intermediate container 23818c5f4882 ---> 1bd65323ae91Step 8/9 : RUN sudo npm i -g @mindgrep/godspeed ---> Running in a66cb062390d. . . . . . . . . . godspeed update dev_test is done.versions​The versions command lists all the versions available of gs_service.$ godspeed versions                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13version​The version command helps to change the version of gs_service for any microservice. Execute the command from inside the project root directory.$ godspeed version 1.0.13                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Generating prisma modulesStarting test1_devcontainer_postgres_1 ... Starting test1_devcontainer_postgres_1 ... doneCreating test1_devcontainer_node_run   ... Creating test1_devcontainer_node_run   ... doneEnvironment variables loaded from .env. . . . . . . . . .help​The help command displays help and usage for any command.$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <projectTemplateDir>  local project template dir  -h, --help                            display help for command4.5 Commands: Inside the dev container​prisma​You can run all the prisma commands in your project root directory inside the dev container. This command is useful for db migration and introspection. Read more here. $ godspeed prisma <prisma command with args>build​You can build the complete project using this command. It is the first command which you need to run whenever you open your project in VScode Dev container. Refer Open in Dev containergodspeed builddev​You can run your project using dev command.godspeed servegen-api-docs​You can get OAS 3 documentation generated automatically by executing this command in your project root directory inside the dev container.$ godspeed gen-api-docs                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529346164] INFO (GS-logger/7684 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529346190] DEBUG (GS-logger/7684 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529346289] INFO (GS-logger/7684 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Postman collection​step1: After executing $ godspeed gen-api-docs
go to docs under app and right click on api-doc.yaml file and download itstep2: In postman import the downloaded file in collection(collection->import->files->select-file.yaml-> import ) and test your apigen-test-suite​You can get test suite/postman collection generated automatically by executing this command in your project root directory inside the dev container. Now, you can import the collection in postman directly. godspeed gen-test-suite                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-test-suite> npm run gen-api-docs && mkdir -p tests && openapi2postmanv2 -s docs/api-doc.yaml -o tests/test-suite.json -p -O folderStrategy=Tags,includeAuthInfoInExample=false> proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529443249] INFO (GS-logger/8145 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529443273] DEBUG (GS-logger/8145 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529443374] INFO (GS-logger/8145 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Input file:  /workspace/development/app/docs/api-doc.yamlWriting to file:  true /workspace/development/app/tests/test-suite.json { result: true, output: [ { type: 'collection', data: [Object] } ] }Conversion successful, collection written to filegen-crud-api​You can get CRUD API generated automatically for datastores and elasticgraph datasources by executing this command in your project root directory inside the dev container.$ godspeed gen-crud-api                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > eg_test@1.0.0 gen-crud-api> npx godspeed-crud-api-generatorSelect datasource / schema to generate CRUD APIs(x) elasticgraph.yaml( ) For all( ) Canceltest​You can run the test suite generated in above command from the following two ways:Postman: Import the collection in postman and run the test suite.CLI: You can use below command to run the test suite from CLI.Please make sure your service is up and running before running the test suite. godspeed test                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 test> newman run tests/test-suite.jsonnewmanGodspeed: Sample Microservice→ Call another (sub) workflow from main workflow  POST http://localhost:3000/another_workflow?bank_id=<string> [200 OK, 630B, 2.6s]. . . . . . . . help​The help command displays help and usage for any command. Click here to know more4.6 Generating Elasticgraph model from prisma schema​generate-elasticgraph-model​You can convert the prisma schema to elasticgraph model by executing this commmand in your project root directory inside the dev container.$ godspeed generate-elasticgraph-model                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed generate-elasticgraph-model [egClientName]Enter the input path  : Enter the output path :Elasticgraph model generatednote[egClientName] (optional): Specifies the name of the Elasticgraph client to be generated. If not provided, the default name eg-model will be used.If the specified input path does not exist, the CLI will display an error message.If the specified output path does not exist, the folder will be generated with [egClientName].Edit this pagePrevious3.6 Debugger in YamlNext5. Swagger Specs4.1 FunctionalityOutside the dev containerInside the dev container4.2 Installation4.3 Options--version (-v)--help (-h)4.4 Commands: Outside the dev containercreateupdateversionsversionhelp4.5 Commands: Inside the dev containerprismabuilddevgen-api-docsPostman collectiongen-test-suitegen-crud-apitesthelp4.6 Generating Elasticgraph model from prisma schemagenerate-elasticgraph-modelForumDiscordGithubTwitterLinkedIn








Introduction to Godspeed CLI | Godspeed Docs





Skip to main contentGodspeedDocumentationv1v2.0v1Table of Contents1. Preface2. Introduction3. Setup4. CLI5. Swagger Specs6. Events7. Workflows8. Datasources9. Caching10. Mappings11. Plugins12. Authentication & Authorization13. Telemetry14. Custom Middleware15. RoadmapThis is documentation for Godspeed Docs v1, which is no longer actively maintained.For up-to-date documentation, see the latest version (v2.0).4. CLIVersion: v1On this pageGodspeed CLIThe CLI is the primary way to interact with your Godspeed project from the command line. It provides a bunch of useful functionalities during the project development lifecycle.4.1 Functionality​Outside the dev container​Creating a new project environment with dev container setup, which includes the folder structure, all the databases, message bus, cache, etc.Open up an existing project in the dev container, add/update a container in the dev environment, based on updated settings.List the versions of gs_service.Change the version of gs_service.Inside the dev container​All Prisma commands including DB push, pull or migration.OAS 3 documentation file generation.Test suite/Postman collection generation.Running test suite.4.2 Installation​npm install -g @mindgrep/godspeedOnce Godspeed CLI is installed, the godspeed command can be called from command line. When called without arguments, it displays its help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.3 Options​--version (-v)​The --version option outputs information about your current godspeed version.$ godspeed -v                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          0.0.26--help (-h)​The --help option displays help and command usage.$ godspeed                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed [options] [command]Options:  -v, --version                   output the version number  -h, --help                      display help for commandCommands:  create [options] <projectName>  versions                        List all the available versions of gs_service  prepare                         prepare the containers, before launch or after cleaning the containers  version <version>  help [command]                  display help for command4.4 Commands: Outside the dev container​create​The create command creates project structure for any microservice. When called without arguments, it creates project structure with examples.$ godspeed create my_service                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          projectDir:  /home/gurjot/cli-test/my_service projectTemplateDir undefinedproject createdDo you need mongodb? [y/n] [default: n] nDo you need postgresdb? [y/n] [default: n] yPlease enter name of the postgres database [default: test] Do you need kafka? [y/n] [default: n] nDo you need elastisearch? [y/n] [default: n] nPlease enter host port on which you want to run your service [default: 3000] 3100Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13Enter your version [default: latest] 1.0.13Selected version 1.0.13. . . . . . . . Options​$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <existing_project_directory>  existing project template dir  -h, --help                            display help for commandupdate​The update can be executed in the following cases:If you want to launch an existing project (i.e. copied from local/cloned from repo) instead of creating a new one, then execute godspeed update command before launching the project.If you want to reloads the containers with updated project settings. For example, if you have not selected any database during the project creation and you want to include any database in the project later on, then execute godspeed update with the required settings.If there is any change in gs_service image of standard tags (e.g. latest, stable) and you want to fetch the latest code for the same tag, then execute godspeed updatecommand. It fetches the new docker image itself.Please note that the command should be executed from inside the project root directory.noteWhenever you update your project using godspeed update and open the project in VScode dev container after update, then it is mandatory to do godspeed build inside dev container for the first time.$ godspeed update                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Do you need postgresdb? [y/n] [default: n] Do you need kafka? [y/n] [default: n] Do you need elastisearch? [y/n] [default: n] Please enter host port on which you want to run your service [default: 3000] Fetching release version information...Please select release version of gs_service from the available list:latest1.0.01.0.11.0.21.0.31.0.4devstableEnter your version [default: latest] Selected version latestRemoving dev_test_devcontainer_node_1                ... . . . . . . . . . .Step 1/9 : FROM adminmindgrep/gs_service:latestlatest: Pulling from adminmindgrep/gs_service824b15f81d65: Already exists325d38bcb229: Already existsd6d638bf61bf: Already exists55daac95cedf: Already exists4c701498752d: Already existsa48b0ae49665: Pulling fs layer4c393fb6deac: Pulling fs layer4f4fb700ef54: Pulling fs layer8992963a9530: Pulling fs layer4f4fb700ef54: Verifying Checksum4f4fb700ef54: Download complete4c393fb6deac: Verifying Checksum4c393fb6deac: Download complete8992963a9530: Verifying Checksum8992963a9530: Download completea48b0ae49665: Verifying Checksuma48b0ae49665: Download completea48b0ae49665: Pull complete4c393fb6deac: Pull complete4f4fb700ef54: Pull complete8992963a9530: Pull completeDigest: sha256:7195b3c921f1278153c911e6e77cbcfb385a84c435bfcb7b8272ffcf9a3278eeStatus: Downloaded newer image for adminmindgrep/gs_service:latest ---> 988917710d1aStep 2/9 : ARG USERNAME=node ---> Running in c70404bb4f3eRemoving intermediate container c70404bb4f3e ---> 47a7406b2473Step 3/9 : ARG USER_UID=1000 ---> Running in 51e68336d8d8Removing intermediate container 51e68336d8d8 ---> ce913f6898bbStep 4/9 : ARG USER_GID=$USER_UID ---> Running in 7cf1c1f2a3ecRemoving intermediate container 7cf1c1f2a3ec ---> 91f045b32e0fStep 5/9 : USER root ---> Running in f338d755a032Removing intermediate container f338d755a032 ---> fa9898eb4c23Step 6/9 : RUN sudo groupmod --gid $USER_GID $USERNAME     && usermod --uid $USER_UID --gid $USER_GID $USERNAME     && chown -R $USER_UID:$USER_GID /workspace/development ---> Running in eba3659fb919Removing intermediate container eba3659fb919 ---> 414f34560b0dStep 7/9 : USER node ---> Running in 23818c5f4882Removing intermediate container 23818c5f4882 ---> 1bd65323ae91Step 8/9 : RUN sudo npm i -g @mindgrep/godspeed ---> Running in a66cb062390d. . . . . . . . . . godspeed update dev_test is done.versions​The versions command lists all the versions available of gs_service.$ godspeed versions                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          latest1.0.01.0.11.0.101.0.111.0.121.0.131.0.21.0.31.0.41.0.51.0.61.0.71.0.81.0.9basedevv1.0.13version​The version command helps to change the version of gs_service for any microservice. Execute the command from inside the project root directory.$ godspeed version 1.0.13                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Generating prisma modulesStarting test1_devcontainer_postgres_1 ... Starting test1_devcontainer_postgres_1 ... doneCreating test1_devcontainer_node_run   ... Creating test1_devcontainer_node_run   ... doneEnvironment variables loaded from .env. . . . . . . . . .help​The help command displays help and usage for any command.$ godspeed help create                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed create [options] <projectName>Options:  -n, --noexamples                      create blank project without examples  -d, --directory <projectTemplateDir>  local project template dir  -h, --help                            display help for command4.5 Commands: Inside the dev container​prisma​You can run all the prisma commands in your project root directory inside the dev container. This command is useful for db migration and introspection. Read more here. $ godspeed prisma <prisma command with args>build​You can build the complete project using this command. It is the first command which you need to run whenever you open your project in VScode Dev container. Refer Open in Dev containergodspeed builddev​You can run your project using dev command.godspeed servegen-api-docs​You can get OAS 3 documentation generated automatically by executing this command in your project root directory inside the dev container.$ godspeed gen-api-docs                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529346164] INFO (GS-logger/7684 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529346190] DEBUG (GS-logger/7684 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529346289] INFO (GS-logger/7684 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Postman collection​step1: After executing $ godspeed gen-api-docs
go to docs under app and right click on api-doc.yaml file and download itstep2: In postman import the downloaded file in collection(collection->import->files->select-file.yaml-> import ) and test your apigen-test-suite​You can get test suite/postman collection generated automatically by executing this command in your project root directory inside the dev container. Now, you can import the collection in postman directly. godspeed gen-test-suite                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 gen-test-suite> npm run gen-api-docs && mkdir -p tests && openapi2postmanv2 -s docs/api-doc.yaml -o tests/test-suite.json -p -O folderStrategy=Tags,includeAuthInfoInExample=false> proj_upd@1.0.0 gen-api-docs> node ../gs_service/dist/api-specs/api-spec.js | pino-pretty[1657529443249] INFO (GS-logger/8145 on 4c20ee3c4c38): Loading events from /workspace/development/app/src/events[1657529443273] DEBUG (GS-logger/8145 on 4c20ee3c4c38): parsing files: /workspace/development/app/src/events/call_another_workflow.yaml,/workspace/development/app/src/events/create_user_then_show_all.yaml,/workspace/development/app/src/events/cross_db_join.yaml,/workspace/development/app/src/events/document.yaml,/workspace/development/app/src/events/helloworld.yaml,/workspace/development/app/src/events/httpbin_anything_coffee.yaml,/workspace/development/app/src/events/httpbin_anything.yaml,/workspace/development/app/src/events/run_tasks_in_parallel.yaml,/workspace/development/app/src/events/sum.yaml,/workspace/development/app/src/events/switch_case.yaml[1657529443374] INFO (GS-logger/8145 on 4c20ee3c4c38): /workspace/development/app/docs/api-doc.yaml file is saved!Input file:  /workspace/development/app/docs/api-doc.yamlWriting to file:  true /workspace/development/app/tests/test-suite.json { result: true, output: [ { type: 'collection', data: [Object] } ] }Conversion successful, collection written to filegen-crud-api​You can get CRUD API generated automatically for datastores and elasticgraph datasources by executing this command in your project root directory inside the dev container.$ godspeed gen-crud-api                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > eg_test@1.0.0 gen-crud-api> npx godspeed-crud-api-generatorSelect datasource / schema to generate CRUD APIs(x) elasticgraph.yaml( ) For all( ) Canceltest​You can run the test suite generated in above command from the following two ways:Postman: Import the collection in postman and run the test suite.CLI: You can use below command to run the test suite from CLI.Please make sure your service is up and running before running the test suite. godspeed test                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          > proj_upd@1.0.0 test> newman run tests/test-suite.jsonnewmanGodspeed: Sample Microservice→ Call another (sub) workflow from main workflow  POST http://localhost:3000/another_workflow?bank_id=<string> [200 OK, 630B, 2.6s]. . . . . . . . help​The help command displays help and usage for any command. Click here to know more4.6 Generating Elasticgraph model from prisma schema​generate-elasticgraph-model​You can convert the prisma schema to elasticgraph model by executing this commmand in your project root directory inside the dev container.$ godspeed generate-elasticgraph-model                      _                                   _    __ _    ___     __| |  ___   _ __     ___    ___    __| |  / _` |  / _ \   / _` | / __| | '_ \   / _ \  / _ \  / _` | | (_| | | (_) | | (_| | \__ \ | |_) | |  __/ |  __/ | (_| |  \__, |  \___/   \__,_| |___/ | .__/   \___|  \___|  \__,_|  |___/                        |_|                          Usage: godspeed generate-elasticgraph-model [egClientName]Enter the input path  : Enter the output path :Elasticgraph model generatednote[egClientName] (optional): Specifies the name of the Elasticgraph client to be generated. If not provided, the default name eg-model will be used.If the specified input path does not exist, the CLI will display an error message.If the specified output path does not exist, the folder will be generated with [egClientName].Edit this pagePrevious3.6 Debugger in YamlNext5. Swagger Specs4.1 FunctionalityOutside the dev containerInside the dev container4.2 Installation4.3 Options--version (-v)--help (-h)4.4 Commands: Outside the dev containercreateupdateversionsversionhelp4.5 Commands: Inside the dev containerprismabuilddevgen-api-docsPostman collectiongen-test-suitegen-crud-apitesthelp4.6 Generating Elasticgraph model from prisma schemagenerate-elasticgraph-modelForumDiscordGithubTwitterLinkedIn



